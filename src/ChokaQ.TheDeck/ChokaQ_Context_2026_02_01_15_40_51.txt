================================================================================
PROJECT CONTEXT EXPORT: ChokaQ
TIMESTAMP: 2026_02_01_15_40_51
================================================================================

STRUCTURE:
  [ ] ChokaQ\ChokaQ.sln
  [ ] ChokaQ\README.md
  [ ] ChokaQ\samples\ChokaQ.Sample.Bus\appsettings.Development.json
  [ ] ChokaQ\samples\ChokaQ.Sample.Bus\appsettings.json
  [ ] ChokaQ\samples\ChokaQ.Sample.Bus\ChokaQ.Sample.Bus.csproj
  [ ] ChokaQ\samples\ChokaQ.Sample.Bus\Program.cs
  [ ] ChokaQ\samples\ChokaQ.Sample.Bus\Components\App.razor
  [ ] ChokaQ\samples\ChokaQ.Sample.Bus\Components\Routes.razor
  [ ] ChokaQ\samples\ChokaQ.Sample.Bus\Components\_Imports.razor
  [ ] ChokaQ\samples\ChokaQ.Sample.Bus\Components\Layout\MainLayout.razor
  [ ] ChokaQ\samples\ChokaQ.Sample.Bus\Components\Layout\MainLayout.razor.css
  [ ] ChokaQ\samples\ChokaQ.Sample.Bus\Components\Layout\ReconnectModal.razor
  [ ] ChokaQ\samples\ChokaQ.Sample.Bus\Components\Layout\ReconnectModal.razor.css
  [ ] ChokaQ\samples\ChokaQ.Sample.Bus\Components\Layout\ReconnectModal.razor.js
  [ ] ChokaQ\samples\ChokaQ.Sample.Bus\Components\Pages\Error.razor
  [ ] ChokaQ\samples\ChokaQ.Sample.Bus\Components\Pages\Home.razor
  [ ] ChokaQ\samples\ChokaQ.Sample.Bus\Components\Pages\NotFound.razor
  [ ] ChokaQ\samples\ChokaQ.Sample.Bus\Jobs\MailingJobs.cs
  [ ] ChokaQ\samples\ChokaQ.Sample.Bus\Jobs\ReportingJobs.cs
  [ ] ChokaQ\samples\ChokaQ.Sample.Bus\Jobs\SystemJobs.cs
  [ ] ChokaQ\samples\ChokaQ.Sample.Bus\Profiles\MailingProfile.cs
  [ ] ChokaQ\samples\ChokaQ.Sample.Bus\Profiles\ReportingProfile.cs
  [ ] ChokaQ\samples\ChokaQ.Sample.Bus\Profiles\SystemProfile.cs
  [ ] ChokaQ\samples\ChokaQ.Sample.Bus\Properties\launchSettings.json
  [ ] ChokaQ\samples\ChokaQ.Sample.Bus\wwwroot\app.css
  [ ] ChokaQ\samples\ChokaQ.Sample.Pipe\appsettings.Development.json
  [ ] ChokaQ\samples\ChokaQ.Sample.Pipe\appsettings.json
  [ ] ChokaQ\samples\ChokaQ.Sample.Pipe\ChokaQ.Sample.Pipe.csproj
  [ ] ChokaQ\samples\ChokaQ.Sample.Pipe\Program.cs
  [ ] ChokaQ\samples\ChokaQ.Sample.Pipe\Components\App.razor
  [ ] ChokaQ\samples\ChokaQ.Sample.Pipe\Components\Routes.razor
  [ ] ChokaQ\samples\ChokaQ.Sample.Pipe\Components\_Imports.razor
  [ ] ChokaQ\samples\ChokaQ.Sample.Pipe\Components\Layout\MainLayout.razor
  [ ] ChokaQ\samples\ChokaQ.Sample.Pipe\Components\Layout\MainLayout.razor.css
  [ ] ChokaQ\samples\ChokaQ.Sample.Pipe\Components\Layout\ReconnectModal.razor
  [ ] ChokaQ\samples\ChokaQ.Sample.Pipe\Components\Layout\ReconnectModal.razor.css
  [ ] ChokaQ\samples\ChokaQ.Sample.Pipe\Components\Layout\ReconnectModal.razor.js
  [ ] ChokaQ\samples\ChokaQ.Sample.Pipe\Components\Pages\Error.razor
  [ ] ChokaQ\samples\ChokaQ.Sample.Pipe\Components\Pages\Home.razor
  [ ] ChokaQ\samples\ChokaQ.Sample.Pipe\Components\Pages\Home.razor.cs
  [ ] ChokaQ\samples\ChokaQ.Sample.Pipe\Components\Pages\NotFound.razor
  [ ] ChokaQ\samples\ChokaQ.Sample.Pipe\Jobs\PipeContracts.cs
  [ ] ChokaQ\samples\ChokaQ.Sample.Pipe\Properties\launchSettings.json
  [ ] ChokaQ\samples\ChokaQ.Sample.Pipe\Services\GlobalPipeHandler.cs
  [ ] ChokaQ\samples\ChokaQ.Sample.Pipe\wwwroot\app.css
  [ ] ChokaQ\src\ChokaQ.Abstractions\ChokaQ.Abstractions.csproj
  [ ] ChokaQ\src\ChokaQ.Abstractions\Contexts\IJobContext.cs
  [ ] ChokaQ\src\ChokaQ.Abstractions\DTOs\CircuitStatsDto.cs
  [ ] ChokaQ\src\ChokaQ.Abstractions\DTOs\JobDataUpdateDto.cs
  [ ] ChokaQ\src\ChokaQ.Abstractions\DTOs\JobUpdateDto.cs
  [ ] ChokaQ\src\ChokaQ.Abstractions\Entities\JobArchiveEntity.cs
  [ ] ChokaQ\src\ChokaQ.Abstractions\Entities\JobDLQEntity.cs
  [ ] ChokaQ\src\ChokaQ.Abstractions\Entities\JobHotEntity.cs
  [ ] ChokaQ\src\ChokaQ.Abstractions\Entities\QueueEntity.cs
  [ ] ChokaQ\src\ChokaQ.Abstractions\Entities\StatsSummaryEntity.cs
  [ ] ChokaQ\src\ChokaQ.Abstractions\Enums\CircuitStatus.cs
  [ ] ChokaQ\src\ChokaQ.Abstractions\Enums\FailureReason.cs
  [ ] ChokaQ\src\ChokaQ.Abstractions\Enums\JobStatus.cs
  [ ] ChokaQ\src\ChokaQ.Abstractions\Jobs\ChokaQBaseJob.cs
  [ ] ChokaQ\src\ChokaQ.Abstractions\Jobs\ChokaQJobProfile.cs
  [ ] ChokaQ\src\ChokaQ.Abstractions\Jobs\IChokaQJob.cs
  [ ] ChokaQ\src\ChokaQ.Abstractions\Jobs\IChokaQJobHandler.cs
  [ ] ChokaQ\src\ChokaQ.Abstractions\Jobs\IChokaQPipeHandler.cs
  [ ] ChokaQ\src\ChokaQ.Abstractions\Jobs\JobRegistration.cs
  [ ] ChokaQ\src\ChokaQ.Abstractions\Notifications\IChokaQNotifier.cs
  [ ] ChokaQ\src\ChokaQ.Abstractions\Resilience\ICircuitBreaker.cs
  [ ] ChokaQ\src\ChokaQ.Abstractions\Resilience\IDeduplicator.cs
  [ ] ChokaQ\src\ChokaQ.Abstractions\Storage\IChokaQQueue.cs
  [ ] ChokaQ\src\ChokaQ.Abstractions\Storage\IJobStorage.cs
  [ ] ChokaQ\src\ChokaQ.Abstractions\Workers\IWorkerManager.cs
  [ ] ChokaQ\src\ChokaQ.Core\ChokaQ.Core.csproj
  [ ] ChokaQ\src\ChokaQ.Core\ChokaQOptions.cs
  [ ] ChokaQ\src\ChokaQ.Core\Concurrency\ElasticSemaphore.cs
  [ ] ChokaQ\src\ChokaQ.Core\Contexts\JobContext.cs
  [ ] ChokaQ\src\ChokaQ.Core\Defaults\InMemoryCircuitBreaker.cs
  [ ] ChokaQ\src\ChokaQ.Core\Defaults\InMemoryDeduplicator.cs
  [ ] ChokaQ\src\ChokaQ.Core\Defaults\InMemoryJobStorage.cs
  [ ] ChokaQ\src\ChokaQ.Core\Defaults\InMemoryQueue.cs
  [ ] ChokaQ\src\ChokaQ.Core\Defaults\InMemoryStorageOptions.cs
  [ ] ChokaQ\src\ChokaQ.Core\Defaults\NullNotifier.cs
  [ ] ChokaQ\src\ChokaQ.Core\Execution\BusJobDispatcher.cs
  [ ] ChokaQ\src\ChokaQ.Core\Execution\IJobDispatcher.cs
  [ ] ChokaQ\src\ChokaQ.Core\Execution\JobTypeRegistry.cs
  [ ] ChokaQ\src\ChokaQ.Core\Execution\PipeJobDispatcher.cs
  [ ] ChokaQ\src\ChokaQ.Core\Extensions\ChokaQCoreExtensions.cs
  [ ] ChokaQ\src\ChokaQ.Core\Processing\IJobProcessor.cs
  [ ] ChokaQ\src\ChokaQ.Core\Processing\JobProcessor.cs
  [ ] ChokaQ\src\ChokaQ.Core\Resilience\ZombieRescueService.cs
  [ ] ChokaQ\src\ChokaQ.Core\State\IJobStateManager.cs
  [ ] ChokaQ\src\ChokaQ.Core\State\JobStateManager.cs
  [ ] ChokaQ\src\ChokaQ.Core\Workers\JobWorker.cs
  [ ] ChokaQ\src\ChokaQ.Storage.SqlServer\ChokaQ.Storage.SqlServer.csproj
  [ ] ChokaQ\src\ChokaQ.Storage.SqlServer\ChokaQSqlServerExtensions.cs
  [ ] ChokaQ\src\ChokaQ.Storage.SqlServer\DbMigrationWorker.cs
  [ ] ChokaQ\src\ChokaQ.Storage.SqlServer\SqlInitializer.cs
  [ ] ChokaQ\src\ChokaQ.Storage.SqlServer\SqlJobStorage.cs
  [ ] ChokaQ\src\ChokaQ.Storage.SqlServer\SqlJobStorageOptions.cs
  [ ] ChokaQ\src\ChokaQ.Storage.SqlServer\SqlJobWorker.cs
  [ ] ChokaQ\src\ChokaQ.Storage.SqlServer\DataEngine\ParameterBuilder.cs
  [ ] ChokaQ\src\ChokaQ.Storage.SqlServer\DataEngine\Queries.cs
  [ ] ChokaQ\src\ChokaQ.Storage.SqlServer\DataEngine\SqlMapper.cs
  [ ] ChokaQ\src\ChokaQ.Storage.SqlServer\DataEngine\TypeMapper.cs
  [ ] ChokaQ\src\ChokaQ.Storage.SqlServer\Scripts\CleanupProcTemplate.sql
  [ ] ChokaQ\src\ChokaQ.Storage.SqlServer\Scripts\SchemaTemplate.sql
  [ ] ChokaQ\src\ChokaQ.TheDeck\ChokaQ.TheDeck.csproj
  [ ] ChokaQ\src\ChokaQ.TheDeck\ChokaQTheDeckOptions.cs
  [ ] ChokaQ\src\ChokaQ.TheDeck\_Imports.razor
  [ ] ChokaQ\src\ChokaQ.TheDeck\Extensions\ChokaQTheDeckExtensions.cs
  [ ] ChokaQ\src\ChokaQ.TheDeck\Hubs\ChokaQHub.cs
  [ ] ChokaQ\src\ChokaQ.TheDeck\Models\JobViewModel.cs
  [ ] ChokaQ\src\ChokaQ.TheDeck\Models\LogEntry.cs
  [ ] ChokaQ\src\ChokaQ.TheDeck\Services\ChokaQSignalRNotifier.cs
  [ ] ChokaQ\src\ChokaQ.TheDeck\UI\Components\Circuits\Circuits.razor
  [ ] ChokaQ\src\ChokaQ.TheDeck\UI\Components\Circuits\Circuits.razor.cs
  [ ] ChokaQ\src\ChokaQ.TheDeck\UI\Components\Circuits\Circuits.razor.css
  [ ] ChokaQ\src\ChokaQ.TheDeck\UI\Components\ConsoleLog\ConsoleLog.razor
  [ ] ChokaQ\src\ChokaQ.TheDeck\UI\Components\ConsoleLog\ConsoleLog.razor.cs
  [ ] ChokaQ\src\ChokaQ.TheDeck\UI\Components\ConsoleLog\ConsoleLog.razor.css
  [ ] ChokaQ\src\ChokaQ.TheDeck\UI\Components\HeaderLeft\HeaderLeft.razor
  [ ] ChokaQ\src\ChokaQ.TheDeck\UI\Components\HeaderLeft\HeaderLeft.razor.cs
  [ ] ChokaQ\src\ChokaQ.TheDeck\UI\Components\HeaderLeft\HeaderLeft.razor.css
  [ ] ChokaQ\src\ChokaQ.TheDeck\UI\Components\HeaderRight\HeaderRight.razor
  [ ] ChokaQ\src\ChokaQ.TheDeck\UI\Components\HeaderRight\HeaderRight.razor.cs
  [ ] ChokaQ\src\ChokaQ.TheDeck\UI\Components\HeaderRight\HeaderRight.razor.css
  [ ] ChokaQ\src\ChokaQ.TheDeck\UI\Components\JobMatrix\JobMatrix.razor
  [ ] ChokaQ\src\ChokaQ.TheDeck\UI\Components\JobMatrix\JobMatrix.razor.cs
  [ ] ChokaQ\src\ChokaQ.TheDeck\UI\Components\JobMatrix\JobRow\JobRow.razor
  [ ] ChokaQ\src\ChokaQ.TheDeck\UI\Components\OpsPanel\OpsPanel.razor
  [ ] ChokaQ\src\ChokaQ.TheDeck\UI\Components\OpsPanel\JobInspector\JobInspector.razor
  [ ] ChokaQ\src\ChokaQ.TheDeck\UI\Components\Queues\Queues.razor
  [ ] ChokaQ\src\ChokaQ.TheDeck\UI\Components\Settings\Settings.razor
  [ ] ChokaQ\src\ChokaQ.TheDeck\UI\Components\Settings\Settings.razor.cs
  [ ] ChokaQ\src\ChokaQ.TheDeck\UI\Components\Settings\Settings.razor.css
  [ ] ChokaQ\src\ChokaQ.TheDeck\UI\Components\Stats\Stats.razor
  [ ] ChokaQ\src\ChokaQ.TheDeck\UI\Components\Stats\Stats.razor.cs
  [ ] ChokaQ\src\ChokaQ.TheDeck\UI\Components\Stats\Stats.razor.css
  [ ] ChokaQ\src\ChokaQ.TheDeck\UI\Layout\TheDeckHost.razor
  [ ] ChokaQ\src\ChokaQ.TheDeck\UI\Layout\TheDeckHost.razor.cs
  [ ] ChokaQ\src\ChokaQ.TheDeck\UI\Pages\TheDeck.razor
  [ ] ChokaQ\src\ChokaQ.TheDeck\UI\Pages\TheDeck.razor.cs
  [ ] ChokaQ\src\ChokaQ.TheDeck\UI\Pages\TheDeck.razor.css
  [ ] ChokaQ\src\ChokaQ.TheDeck\wwwroot\css\deck.css
  [ ] ChokaQ\src\ChokaQ.TheDeck\wwwroot\css\skins\blueprint.css
  [ ] ChokaQ\src\ChokaQ.TheDeck\wwwroot\css\skins\carbon.css
  [ ] ChokaQ\src\ChokaQ.TheDeck\wwwroot\js\deck.js

================================================================================

>>> FILE: ChokaQ\ChokaQ.sln

Microsoft Visual Studio Solution File, Format Version 12.00
# Visual Studio Version 18
VisualStudioVersion = 18.1.11312.151
MinimumVisualStudioVersion = 10.0.40219.1
Project("{2150E333-8FDC-42A3-9474-1A3956D46DE8}") = "src", "src", "{827E0CD3-B72D-47B6-A68D-7590B98EB39B}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "ChokaQ.Abstractions", "src\ChokaQ.Abstractions\ChokaQ.Abstractions.csproj", "{518C2F40-CD8D-4C10-868D-E3C2358236C0}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "ChokaQ.Core", "src\ChokaQ.Core\ChokaQ.Core.csproj", "{7D1999CE-A88B-4A76-BD74-700FAFBC6269}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "ChokaQ.Storage.SqlServer", "src\ChokaQ.Storage.SqlServer\ChokaQ.Storage.SqlServer.csproj", "{C52276C9-BA0A-46DA-8648-005710893A6A}"
EndProject
Project("{2150E333-8FDC-42A3-9474-1A3956D46DE8}") = "samples", "samples", "{5D20AA90-6969-D8BD-9DCD-8634F4692FDA}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "ChokaQ.Sample.Bus", "samples\ChokaQ.Sample.Bus\ChokaQ.Sample.Bus.csproj", "{AFB4A785-3598-45D2-93EA-D8E6CDBC0E0E}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "ChokaQ.Sample.Pipe", "samples\ChokaQ.Sample.Pipe\ChokaQ.Sample.Pipe.csproj", "{0DB3D4E8-EB1A-44DC-A42D-BB18593583F7}"
EndProject
Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "ChokaQ.TheDeck", "src\ChokaQ.TheDeck\ChokaQ.TheDeck.csproj", "{6B614F37-F8F4-452E-927B-95DFDCE4E436}"
EndProject
Global
	GlobalSection(SolutionConfigurationPlatforms) = preSolution
		Debug|Any CPU = Debug|Any CPU
		Debug|x64 = Debug|x64
		Debug|x86 = Debug|x86
		Release|Any CPU = Release|Any CPU
		Release|x64 = Release|x64
		Release|x86 = Release|x86
	EndGlobalSection
	GlobalSection(ProjectConfigurationPlatforms) = postSolution
		{518C2F40-CD8D-4C10-868D-E3C2358236C0}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{518C2F40-CD8D-4C10-868D-E3C2358236C0}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{518C2F40-CD8D-4C10-868D-E3C2358236C0}.Debug|x64.ActiveCfg = Debug|Any CPU
		{518C2F40-CD8D-4C10-868D-E3C2358236C0}.Debug|x64.Build.0 = Debug|Any CPU
		{518C2F40-CD8D-4C10-868D-E3C2358236C0}.Debug|x86.ActiveCfg = Debug|Any CPU
		{518C2F40-CD8D-4C10-868D-E3C2358236C0}.Debug|x86.Build.0 = Debug|Any CPU
		{518C2F40-CD8D-4C10-868D-E3C2358236C0}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{518C2F40-CD8D-4C10-868D-E3C2358236C0}.Release|Any CPU.Build.0 = Release|Any CPU
		{518C2F40-CD8D-4C10-868D-E3C2358236C0}.Release|x64.ActiveCfg = Release|Any CPU
		{518C2F40-CD8D-4C10-868D-E3C2358236C0}.Release|x64.Build.0 = Release|Any CPU
		{518C2F40-CD8D-4C10-868D-E3C2358236C0}.Release|x86.ActiveCfg = Release|Any CPU
		{518C2F40-CD8D-4C10-868D-E3C2358236C0}.Release|x86.Build.0 = Release|Any CPU
		{7D1999CE-A88B-4A76-BD74-700FAFBC6269}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{7D1999CE-A88B-4A76-BD74-700FAFBC6269}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{7D1999CE-A88B-4A76-BD74-700FAFBC6269}.Debug|x64.ActiveCfg = Debug|Any CPU
		{7D1999CE-A88B-4A76-BD74-700FAFBC6269}.Debug|x64.Build.0 = Debug|Any CPU
		{7D1999CE-A88B-4A76-BD74-700FAFBC6269}.Debug|x86.ActiveCfg = Debug|Any CPU
		{7D1999CE-A88B-4A76-BD74-700FAFBC6269}.Debug|x86.Build.0 = Debug|Any CPU
		{7D1999CE-A88B-4A76-BD74-700FAFBC6269}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{7D1999CE-A88B-4A76-BD74-700FAFBC6269}.Release|Any CPU.Build.0 = Release|Any CPU
		{7D1999CE-A88B-4A76-BD74-700FAFBC6269}.Release|x64.ActiveCfg = Release|Any CPU
		{7D1999CE-A88B-4A76-BD74-700FAFBC6269}.Release|x64.Build.0 = Release|Any CPU
		{7D1999CE-A88B-4A76-BD74-700FAFBC6269}.Release|x86.ActiveCfg = Release|Any CPU
		{7D1999CE-A88B-4A76-BD74-700FAFBC6269}.Release|x86.Build.0 = Release|Any CPU
		{C52276C9-BA0A-46DA-8648-005710893A6A}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{C52276C9-BA0A-46DA-8648-005710893A6A}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{C52276C9-BA0A-46DA-8648-005710893A6A}.Debug|x64.ActiveCfg = Debug|Any CPU
		{C52276C9-BA0A-46DA-8648-005710893A6A}.Debug|x64.Build.0 = Debug|Any CPU
		{C52276C9-BA0A-46DA-8648-005710893A6A}.Debug|x86.ActiveCfg = Debug|Any CPU
		{C52276C9-BA0A-46DA-8648-005710893A6A}.Debug|x86.Build.0 = Debug|Any CPU
		{C52276C9-BA0A-46DA-8648-005710893A6A}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{C52276C9-BA0A-46DA-8648-005710893A6A}.Release|Any CPU.Build.0 = Release|Any CPU
		{C52276C9-BA0A-46DA-8648-005710893A6A}.Release|x64.ActiveCfg = Release|Any CPU
		{C52276C9-BA0A-46DA-8648-005710893A6A}.Release|x64.Build.0 = Release|Any CPU
		{C52276C9-BA0A-46DA-8648-005710893A6A}.Release|x86.ActiveCfg = Release|Any CPU
		{C52276C9-BA0A-46DA-8648-005710893A6A}.Release|x86.Build.0 = Release|Any CPU
		{AFB4A785-3598-45D2-93EA-D8E6CDBC0E0E}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{AFB4A785-3598-45D2-93EA-D8E6CDBC0E0E}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{AFB4A785-3598-45D2-93EA-D8E6CDBC0E0E}.Debug|x64.ActiveCfg = Debug|Any CPU
		{AFB4A785-3598-45D2-93EA-D8E6CDBC0E0E}.Debug|x64.Build.0 = Debug|Any CPU
		{AFB4A785-3598-45D2-93EA-D8E6CDBC0E0E}.Debug|x86.ActiveCfg = Debug|Any CPU
		{AFB4A785-3598-45D2-93EA-D8E6CDBC0E0E}.Debug|x86.Build.0 = Debug|Any CPU
		{AFB4A785-3598-45D2-93EA-D8E6CDBC0E0E}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{AFB4A785-3598-45D2-93EA-D8E6CDBC0E0E}.Release|Any CPU.Build.0 = Release|Any CPU
		{AFB4A785-3598-45D2-93EA-D8E6CDBC0E0E}.Release|x64.ActiveCfg = Release|Any CPU
		{AFB4A785-3598-45D2-93EA-D8E6CDBC0E0E}.Release|x64.Build.0 = Release|Any CPU
		{AFB4A785-3598-45D2-93EA-D8E6CDBC0E0E}.Release|x86.ActiveCfg = Release|Any CPU
		{AFB4A785-3598-45D2-93EA-D8E6CDBC0E0E}.Release|x86.Build.0 = Release|Any CPU
		{0DB3D4E8-EB1A-44DC-A42D-BB18593583F7}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{0DB3D4E8-EB1A-44DC-A42D-BB18593583F7}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{0DB3D4E8-EB1A-44DC-A42D-BB18593583F7}.Debug|x64.ActiveCfg = Debug|Any CPU
		{0DB3D4E8-EB1A-44DC-A42D-BB18593583F7}.Debug|x64.Build.0 = Debug|Any CPU
		{0DB3D4E8-EB1A-44DC-A42D-BB18593583F7}.Debug|x86.ActiveCfg = Debug|Any CPU
		{0DB3D4E8-EB1A-44DC-A42D-BB18593583F7}.Debug|x86.Build.0 = Debug|Any CPU
		{0DB3D4E8-EB1A-44DC-A42D-BB18593583F7}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{0DB3D4E8-EB1A-44DC-A42D-BB18593583F7}.Release|Any CPU.Build.0 = Release|Any CPU
		{0DB3D4E8-EB1A-44DC-A42D-BB18593583F7}.Release|x64.ActiveCfg = Release|Any CPU
		{0DB3D4E8-EB1A-44DC-A42D-BB18593583F7}.Release|x64.Build.0 = Release|Any CPU
		{0DB3D4E8-EB1A-44DC-A42D-BB18593583F7}.Release|x86.ActiveCfg = Release|Any CPU
		{0DB3D4E8-EB1A-44DC-A42D-BB18593583F7}.Release|x86.Build.0 = Release|Any CPU
		{6B614F37-F8F4-452E-927B-95DFDCE4E436}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
		{6B614F37-F8F4-452E-927B-95DFDCE4E436}.Debug|Any CPU.Build.0 = Debug|Any CPU
		{6B614F37-F8F4-452E-927B-95DFDCE4E436}.Debug|x64.ActiveCfg = Debug|Any CPU
		{6B614F37-F8F4-452E-927B-95DFDCE4E436}.Debug|x64.Build.0 = Debug|Any CPU
		{6B614F37-F8F4-452E-927B-95DFDCE4E436}.Debug|x86.ActiveCfg = Debug|Any CPU
		{6B614F37-F8F4-452E-927B-95DFDCE4E436}.Debug|x86.Build.0 = Debug|Any CPU
		{6B614F37-F8F4-452E-927B-95DFDCE4E436}.Release|Any CPU.ActiveCfg = Release|Any CPU
		{6B614F37-F8F4-452E-927B-95DFDCE4E436}.Release|Any CPU.Build.0 = Release|Any CPU
		{6B614F37-F8F4-452E-927B-95DFDCE4E436}.Release|x64.ActiveCfg = Release|Any CPU
		{6B614F37-F8F4-452E-927B-95DFDCE4E436}.Release|x64.Build.0 = Release|Any CPU
		{6B614F37-F8F4-452E-927B-95DFDCE4E436}.Release|x86.ActiveCfg = Release|Any CPU
		{6B614F37-F8F4-452E-927B-95DFDCE4E436}.Release|x86.Build.0 = Release|Any CPU
	EndGlobalSection
	GlobalSection(SolutionProperties) = preSolution
		HideSolutionNode = FALSE
	EndGlobalSection
	GlobalSection(NestedProjects) = preSolution
		{518C2F40-CD8D-4C10-868D-E3C2358236C0} = {827E0CD3-B72D-47B6-A68D-7590B98EB39B}
		{7D1999CE-A88B-4A76-BD74-700FAFBC6269} = {827E0CD3-B72D-47B6-A68D-7590B98EB39B}
		{C52276C9-BA0A-46DA-8648-005710893A6A} = {827E0CD3-B72D-47B6-A68D-7590B98EB39B}
		{AFB4A785-3598-45D2-93EA-D8E6CDBC0E0E} = {5D20AA90-6969-D8BD-9DCD-8634F4692FDA}
		{0DB3D4E8-EB1A-44DC-A42D-BB18593583F7} = {5D20AA90-6969-D8BD-9DCD-8634F4692FDA}
		{6B614F37-F8F4-452E-927B-95DFDCE4E436} = {827E0CD3-B72D-47B6-A68D-7590B98EB39B}
	EndGlobalSection
	GlobalSection(ExtensibilityGlobals) = postSolution
		SolutionGuid = {EEEE70CD-D064-49B8-85E2-B78F05D78A5B}
	EndGlobalSection
EndGlobal

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\README.md
# 🍫 ChokaQ

![.NET 10](https://img.shields.io/badge/.NET-10.0%20-blue)
![License](https://img.shields.io/badge/license-MIT-green)
![Status](https://img.shields.io/badge/status-Active%20Development-orange)

**Current Status:** Work in Progress / Proof of Concept

**ChokaQ** is a lightweight, high-performance background job engine designed for .NET 10.
It bridges the gap between simple in-memory `Channel<T>` implementations and complex Enterprise Service Bus solutions.

**Zero Dependencies Policy:**
* The **Core** engine is strictly dependency-free.
* The optional **SQL Storage** provider utilizes **Dapper** (micro-ORM) for maximum performance and efficiency.

---

## 🧠 Architecture: The 2x2 Matrix

ChokaQ is built upon a modular architecture. You select the **Processing Strategy** (The Brain) and the **Storage Strategy** (The Memory).
While you may mix these as required, we have curated two reference modes for optimal performance.

| | **In-Memory Storage** (Volatile) | **SQL Server Storage** (Persistent) |
| :--- | :--- | :--- |
| **Pipe Strategy**<br>*(Raw JSON / Events)* | 🚀 **Rocket Mode**<br>Logs, metrics, fire-and-forget.<br>Maximum throughput; data resides in RAM. | **Integration Mode**<br>Collection of raw events into an external database for analytics. |
| **Bus Strategy**<br>*(Typed Jobs / Profiles)* | **Dev Sandbox**<br>Development of business logic without database infrastructure. | 🚌 **Enterprise Mode**<br>Business transactions, reports, notifications.<br>High reliability: retries, history, and resilience to restarts. |

---

## 🚀 Quick Start (Samples)

The `/samples` directory contains two complete projects demonstrating best practices.

### 1. Rocket Mode (`ChokaQ.Sample.Pipe`)
*Ideal for: Logs, metrics, and notifications where minor data loss is acceptable.*

* **Type:** Pipe (Raw Payloads)
* **Storage:** RAM (System.Threading.Channels)
* **Feature:** Zero database dependency. Instant startup and execution.

**How to Run:**
1.  Open `ChokaQ.sln`.
2.  Set `ChokaQ.Sample.Pipe` as the startup project.
3.  Press **F5**.
4.  The launcher will open in your browser. Click "Fire Into Pipe".
5.  The Dashboard is available via the button or at `/chokaq`.

---

### 2. Enterprise Mode (`ChokaQ.Sample.Bus`)
*Ideal for: Critical workloads, billing, and report generation.*

* **Type:** Bus (Typed DTOs + Profiles)
* **Storage:** SQL Server (Dapper + Polling)
* **Feature:** Complete reliability. Data is persisted in SQL. The database schema is automatically managed.

**How to Run:**
1.  Ensure a SQL Server instance is available (LocalDB or Docker).
2.  Create an **empty** database named `ChokaQDb`:
    ```sql
    CREATE DATABASE [ChokaQDb];
    ```
3.  Verify the connection string in the `appsettings.json` file of the `ChokaQ.Sample.Bus` project.
4.  Press **F5**.
    * The application will automatically create the `chokaq` schema, tables, and indexes.
    * Workers will commence polling.
5.  Generate jobs via the UI, stop the application, and restart it to verify that pending jobs resume execution.

---

## ⚙️ Configuration in Code

### Option A: Rocket Mode (Pipe + Memory)
In `Program.cs`:
```csharp
// 1. Register Pipe with the Global Handler
builder.Services.AddChokaQ(options => 
{
    options.UsePipe<GlobalPipeHandler>();
    // Memory is configured by default, but limits can be adjusted
    options.ConfigureInMemory(mem => mem.MaxCapacity = 50_000); 
});

// 2. Add Dashboard
builder.Services.AddChokaQDashboard();
```

### Option B: Enterprise Mode (Bus + SQL)
In `Program.cs`:
```csharp
// 1. Register Bus and Profiles
builder.Services.AddChokaQ(options =>
{
    options.AddProfile<MailingProfile>();
    options.AddProfile<ReportingProfile>();
});

// 2. Configure SQL Storage
builder.Services.UseSqlServer(options =>
{
    options.ConnectionString = "...";
    options.SchemaName = "chokaq"; // Isolate tables in a separate schema
    options.AutoCreateSqlTable = true; // Auto-migrations on startup
});

// 3. Add Dashboard
builder.Services.AddChokaQDashboard();
```

---

## 📊 Dashboard

The Dashboard functions out-of-the-box in any mode.
* **Real-time:** Updates via SignalR.
* **Search:** Filtering by ID, type, and content.
* **Control:** Jobs can be retried or canceled directly.
* **Stats:** Accurate statistics across the entire database (utilizing optimized SQL aggregations or in-memory counters).

Mapping:
```csharp
app.MapChokaQDashboard(); // Default path: /chokaq
```

---

## 🏗️ Project Structure

* `src/ChokaQ.Abstractions` — Contracts, DTOs, Interfaces.
* `src/ChokaQ.Core` — Dispatch logic, In-Memory provider, Workers.
* `src/ChokaQ.Storage.SqlServer` — Persistence implementation using Dapper.
* `src/ChokaQ.Dashboard` — Blazor UI (RCL).

## Author

Created by **Sergei Seivach**.

## License

MIT.

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Bus\appsettings.Development.json
{
  "Logging": {
    "LogLevel": {
      "Default": "Information",
      "Microsoft.AspNetCore": "Warning"
    }
  }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Bus\appsettings.json
{
  "Logging": {
    "LogLevel": {
      "Default": "Information",
      "Microsoft.AspNetCore": "Warning"
    }
  },
  "AllowedHosts": "*",
  "ConnectionStrings": {
    // Connection string for local Docker SQL Server
    "ChokaQDb": "Server=localhost,1433;Database=ChokaQDb;User Id=sa;Password=ChokaQ_Rul3z_2026!;TrustServerCertificate=True;"
  }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Bus\ChokaQ.Sample.Bus.csproj
<Project Sdk="Microsoft.NET.Sdk.Web">

  <ItemGroup>
    <ProjectReference Include="..\..\src\ChokaQ.Core\ChokaQ.Core.csproj" />
    <ProjectReference Include="..\..\src\ChokaQ.Storage.SqlServer\ChokaQ.Storage.SqlServer.csproj" />
    <ProjectReference Include="..\..\src\ChokaQ.TheDeck\ChokaQ.TheDeck.csproj" />
  </ItemGroup>

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <Nullable>enable</Nullable>
    <ImplicitUsings>enable</ImplicitUsings>
    <BlazorDisableThrowNavigationException>true</BlazorDisableThrowNavigationException>
  </PropertyGroup>

</Project>

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Bus\Program.cs
using ChokaQ.Core.Extensions;
using ChokaQ.Sample.Bus.Components;
using ChokaQ.Sample.Bus.Profiles;
using ChokaQ.Storage.SqlServer;
using ChokaQ.TheDeck.Extensions;

var builder = WebApplication.CreateBuilder(args);

builder.Services.AddRazorComponents()
    .AddInteractiveServerComponents();

// --- CHOKAQ CONFIGURATION ---
builder.Services.AddChokaQ(options =>
{
    // Register separate profiles for logical separation
    options.AddProfile<MailingProfile>();
    options.AddProfile<ReportingProfile>();
    options.AddProfile<SystemProfile>();
});

builder.Services.UseSqlServer(options =>
{
    options.ConnectionString = builder.Configuration.GetConnectionString("ChokaQDb")
        ?? throw new InvalidOperationException("Conn string not found");
    options.SchemaName = "chokaq";
    options.AutoCreateSqlTable = builder.Environment.IsDevelopment();
});

builder.Services.AddChokaQTheDeck(options =>
{
    options.RoutePrefix = "/chokaq";
});

var app = builder.Build();

if (!app.Environment.IsDevelopment())
{
    app.UseExceptionHandler("/Error", createScopeForErrors: true);
    app.UseHsts();
}

app.UseHttpsRedirection();
app.UseStaticFiles();
app.UseAntiforgery();

app.MapRazorComponents<App>()
    .AddInteractiveServerRenderMode();

app.MapChokaQTheDeck();

app.Run();

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Bus\Components\App.razor
<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <base href="/" />
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="ChokaQ.Sample.Bus.styles.css" rel="stylesheet" />
    <HeadOutlet />
</head>

<body>
    <Routes />
    <script src="_framework/blazor.web.js"></script>
</body>

</html>

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Bus\Components\Routes.razor
<Router AppAssembly="typeof(Program).Assembly" NotFoundPage="typeof(Pages.NotFound)">
    <Found Context="routeData">
        <RouteView RouteData="routeData" DefaultLayout="typeof(Layout.MainLayout)" />
        <FocusOnNavigate RouteData="routeData" Selector="h1" />
    </Found>
</Router>

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Bus\Components\_Imports.razor
@using System.Net.Http
@using System.Net.Http.Json
@using Microsoft.AspNetCore.Components.Forms
@using Microsoft.AspNetCore.Components.Routing
@using Microsoft.AspNetCore.Components.Web
@using static Microsoft.AspNetCore.Components.Web.RenderMode
@using Microsoft.AspNetCore.Components.Web.Virtualization
@using Microsoft.JSInterop
@using ChokaQ.Sample.Bus
@using ChokaQ.Sample.Bus.Components
@using ChokaQ.Sample.Bus.Components.Layout

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Bus\Components\Layout\MainLayout.razor
@inherits LayoutComponentBase

@Body

<div id="blazor-error-ui" data-nosnippet>
    An unhandled error has occurred.
    <a href="." class="reload">Reload</a>
    <span class="dismiss">🗙</span>
</div>

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Bus\Components\Layout\MainLayout.razor.css
#blazor-error-ui {
    color-scheme: light only;
    background: lightyellow;
    bottom: 0;
    box-shadow: 0 -1px 2px rgba(0, 0, 0, 0.2);
    box-sizing: border-box;
    display: none;
    left: 0;
    padding: 0.6rem 1.25rem 0.7rem 1.25rem;
    position: fixed;
    width: 100%;
    z-index: 1000;
}

    #blazor-error-ui .dismiss {
        cursor: pointer;
        position: absolute;
        right: 0.75rem;
        top: 0.5rem;
    }

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Bus\Components\Layout\ReconnectModal.razor
<script type="module" src="@Assets["Components/Layout/ReconnectModal.razor.js"]"></script>

<dialog id="components-reconnect-modal" data-nosnippet>
    <div class="components-reconnect-container">
        <div class="components-rejoining-animation" aria-hidden="true">
            <div></div>
            <div></div>
        </div>
        <p class="components-reconnect-first-attempt-visible">
            Rejoining the server...
        </p>
        <p class="components-reconnect-repeated-attempt-visible">
            Rejoin failed... trying again in <span id="components-seconds-to-next-attempt"></span> seconds.
        </p>
        <p class="components-reconnect-failed-visible">
            Failed to rejoin.<br />Please retry or reload the page.
        </p>
        <button id="components-reconnect-button" class="components-reconnect-failed-visible">
            Retry
        </button>
        <p class="components-pause-visible">
            The session has been paused by the server.
        </p>
        <button id="components-resume-button" class="components-pause-visible">
            Resume
        </button>
        <p class="components-resume-failed-visible">
            Failed to resume the session.<br />Please reload the page.
        </p>
    </div>
</dialog>

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Bus\Components\Layout\ReconnectModal.razor.css
.components-reconnect-first-attempt-visible,
.components-reconnect-repeated-attempt-visible,
.components-reconnect-failed-visible,
.components-pause-visible,
.components-resume-failed-visible,
.components-rejoining-animation {
    display: none;
}

#components-reconnect-modal.components-reconnect-show .components-reconnect-first-attempt-visible,
#components-reconnect-modal.components-reconnect-show .components-rejoining-animation,
#components-reconnect-modal.components-reconnect-paused .components-pause-visible,
#components-reconnect-modal.components-reconnect-resume-failed .components-resume-failed-visible,
#components-reconnect-modal.components-reconnect-retrying,
#components-reconnect-modal.components-reconnect-retrying .components-reconnect-repeated-attempt-visible,
#components-reconnect-modal.components-reconnect-retrying .components-rejoining-animation,
#components-reconnect-modal.components-reconnect-failed,
#components-reconnect-modal.components-reconnect-failed .components-reconnect-failed-visible {
    display: block;
}


#components-reconnect-modal {
    background-color: white;
    width: 20rem;
    margin: 20vh auto;
    padding: 2rem;
    border: 0;
    border-radius: 0.5rem;
    box-shadow: 0 3px 6px 2px rgba(0, 0, 0, 0.3);
    opacity: 0;
    transition: display 0.5s allow-discrete, overlay 0.5s allow-discrete;
    animation: components-reconnect-modal-fadeOutOpacity 0.5s both;
    &[open]

{
    animation: components-reconnect-modal-slideUp 1.5s cubic-bezier(.05, .89, .25, 1.02) 0.3s, components-reconnect-modal-fadeInOpacity 0.5s ease-in-out 0.3s;
    animation-fill-mode: both;
}

}

#components-reconnect-modal::backdrop {
    background-color: rgba(0, 0, 0, 0.4);
    animation: components-reconnect-modal-fadeInOpacity 0.5s ease-in-out;
    opacity: 1;
}

@keyframes components-reconnect-modal-slideUp {
    0% {
        transform: translateY(30px) scale(0.95);
    }

    100% {
        transform: translateY(0);
    }
}

@keyframes components-reconnect-modal-fadeInOpacity {
    0% {
        opacity: 0;
    }

    100% {
        opacity: 1;
    }
}

@keyframes components-reconnect-modal-fadeOutOpacity {
    0% {
        opacity: 1;
    }

    100% {
        opacity: 0;
    }
}

.components-reconnect-container {
    display: flex;
    flex-direction: column;
    align-items: center;
    gap: 1rem;
}

#components-reconnect-modal p {
    margin: 0;
    text-align: center;
}

#components-reconnect-modal button {
    border: 0;
    background-color: #6b9ed2;
    color: white;
    padding: 4px 24px;
    border-radius: 4px;
}

    #components-reconnect-modal button:hover {
        background-color: #3b6ea2;
    }

    #components-reconnect-modal button:active {
        background-color: #6b9ed2;
    }

.components-rejoining-animation {
    position: relative;
    width: 80px;
    height: 80px;
}

    .components-rejoining-animation div {
        position: absolute;
        border: 3px solid #0087ff;
        opacity: 1;
        border-radius: 50%;
        animation: components-rejoining-animation 1.5s cubic-bezier(0, 0.2, 0.8, 1) infinite;
    }

        .components-rejoining-animation div:nth-child(2) {
            animation-delay: -0.5s;
        }

@keyframes components-rejoining-animation {
    0% {
        top: 40px;
        left: 40px;
        width: 0;
        height: 0;
        opacity: 0;
    }

    4.9% {
        top: 40px;
        left: 40px;
        width: 0;
        height: 0;
        opacity: 0;
    }

    5% {
        top: 40px;
        left: 40px;
        width: 0;
        height: 0;
        opacity: 1;
    }

    100% {
        top: 0px;
        left: 0px;
        width: 80px;
        height: 80px;
        opacity: 0;
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Bus\Components\Layout\ReconnectModal.razor.js
// Set up event handlers
const reconnectModal = document.getElementById("components-reconnect-modal");
reconnectModal.addEventListener("components-reconnect-state-changed", handleReconnectStateChanged);

const retryButton = document.getElementById("components-reconnect-button");
retryButton.addEventListener("click", retry);

const resumeButton = document.getElementById("components-resume-button");
resumeButton.addEventListener("click", resume);

function handleReconnectStateChanged(event) {
    if (event.detail.state === "show") {
        reconnectModal.showModal();
    } else if (event.detail.state === "hide") {
        reconnectModal.close();
    } else if (event.detail.state === "failed") {
        document.addEventListener("visibilitychange", retryWhenDocumentBecomesVisible);
    } else if (event.detail.state === "rejected") {
        location.reload();
    }
}

async function retry() {
    document.removeEventListener("visibilitychange", retryWhenDocumentBecomesVisible);

    try {
        // Reconnect will asynchronously return:
        // - true to mean success
        // - false to mean we reached the server, but it rejected the connection (e.g., unknown circuit ID)
        // - exception to mean we didn't reach the server (this can be sync or async)
        const successful = await Blazor.reconnect();
        if (!successful) {
            // We have been able to reach the server, but the circuit is no longer available.
            // We'll reload the page so the user can continue using the app as quickly as possible.
            const resumeSuccessful = await Blazor.resumeCircuit();
            if (!resumeSuccessful) {
                location.reload();
            } else {
                reconnectModal.close();
            }
        }
    } catch (err) {
        // We got an exception, server is currently unavailable
        document.addEventListener("visibilitychange", retryWhenDocumentBecomesVisible);
    }
}

async function resume() {
    try {
        const successful = await Blazor.resumeCircuit();
        if (!successful) {
            location.reload();
        }
    } catch {
        location.reload();
    }
}

async function retryWhenDocumentBecomesVisible() {
    if (document.visibilityState === "visible") {
        await retry();
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Bus\Components\Pages\Error.razor
@page "/Error"
@using System.Diagnostics

<PageTitle>Error</PageTitle>

<h1 class="text-danger">Error.</h1>
<h2 class="text-danger">An error occurred while processing your request.</h2>

@if (ShowRequestId)
{
    <p>
        <strong>Request ID:</strong> <code>@RequestId</code>
    </p>
}

<h3>Development Mode</h3>
<p>
    Swapping to <strong>Development</strong> environment will display more detailed information about the error that occurred.
</p>
<p>
    <strong>The Development environment shouldn't be enabled for deployed applications.</strong>
    It can result in displaying sensitive information from exceptions to end users.
    For local debugging, enable the <strong>Development</strong> environment by setting the <strong>ASPNETCORE_ENVIRONMENT</strong> environment variable to <strong>Development</strong>
    and restarting the app.
</p>

@code{
    [CascadingParameter]
    private HttpContext? HttpContext { get; set; }

    private string? RequestId { get; set; }
    private bool ShowRequestId => !string.IsNullOrEmpty(RequestId);

    protected override void OnInitialized() =>
        RequestId = Activity.Current?.Id ?? HttpContext?.TraceIdentifier;
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Bus\Components\Pages\Home.razor
@page "/"
@rendermode InteractiveServer
@using ChokaQ.Abstractions
@using ChokaQ.Abstractions.Jobs
@using ChokaQ.Abstractions.Storage
@using ChokaQ.Sample.Bus.Jobs
@inject IChokaQQueue Queue

<PageTitle>ChokaQ Launcher</PageTitle>

<div class="container py-5">
    <div class="row justify-content-center">
        <div class="col-md-8">

            <div class="text-center mb-5">
                <h1 class="display-5 fw-bold text-primary">ChokaQ Launcher</h1>
                <p class="lead text-muted">Generate load and monitor results in real-time.</p>
            </div>

            <div class="card shadow-sm mb-4">
                <div class="card-header bg-white py-3">
                    <h5 class="mb-0 fw-bold">🚀 Job Generator</h5>
                </div>
                <div class="card-body p-4">

                    <div class="row g-3 mb-4">

                        <div class="col-md-12">
                            <label class="form-label fw-bold small">Job Type</label>
                            <select class="form-select" @bind="selectedJobType">
                                <optgroup label="Mailing (Chaos Testing 🧨)">
                                    <option value="email">Send Email (70% Crash Chance)</option>
                                    <option value="sms">Send SMS</option>
                                </optgroup>
                                <optgroup label="Reporting">
                                    <option value="rep_emp">Employee Report</option>
                                    <option value="rep_sales">Sales Report</option>
                                    <option value="rep_exp">Expense Report</option>
                                </optgroup>
                                <optgroup label="System Maintenance">
                                    <option value="health">Health Check</option>
                                    <option value="cleanup">Data Cleanup</option>
                                </optgroup>
                            </select>
                        </div>

                        <div class="col-md-6">
                            <label class="form-label fw-bold small">Job Count</label>
                            <input type="number" class="form-control" @bind="count" min="1" max="10000" />
                        </div>
                        <div class="col-md-6">
                            <label class="form-label fw-bold small">Priority (0-100)</label>
                            <input type="number" class="form-control" @bind="priority" />
                        </div>
                    </div>

                    <div class="d-grid gap-2">
                        <button class="btn btn-primary btn-lg fw-bold" @onclick="Launch" disabled="@isLoading">
                            @if (isLoading)
                            {
                                <span class="spinner-border spinner-border-sm me-2" role="status" aria-hidden="true"></span>
                                <span>Generating...</span>
                            }
                            else
                            {
                                <span>🔥 FIRE JOBS</span>
                            }
                        </button>
                    </div>

                    @if (!string.IsNullOrEmpty(statusMessage))
                    {
                        <div class="alert alert-success mt-3 mb-0 text-center">
                            @statusMessage
                        </div>
                    }
                </div>
            </div>

            <div class="text-center">
                <a href="/chokaq" target="_blank" class="btn btn-outline-dark px-4 py-2">
                    📊 Open Dashboard in New Tab
                </a>
            </div>

        </div>
    </div>
</div>

@code {
    private string selectedJobType = "email"; // Default to a real business job
    private int count = 1;
    private int priority = 10;
    private bool isLoading = false;
    private string? statusMessage;

    private async Task Launch()
    {
        isLoading = true;
        statusMessage = null;

        await Task.Run(async () =>
        {
            var tasks = new List<Task>();
            for (int i = 0; i < count; i++)
            {
                IChokaQJob job = selectedJobType switch
                {
                    // Mailing
                    "email" => new EmailJob($"user{i}@test.com", "Weekly Update"),
                    "sms" => new SmsJob("+15550009999", "Your code is 1234"),

                    // Reporting
                    "rep_emp" => new EmployeeReportJob("IT_Dept"),
                    "rep_sales" => new SalesReportJob(2026, 1),
                    "rep_exp" => new ExpenseReportJob("Travel"),

                    // System Maintenance
                    "health" => new HealthCheckJob("PaymentGateway"),
                    "cleanup" => new CleanupJob(30),

                    _ => throw new InvalidOperationException($"Unknown Job Type: {selectedJobType}")
                };

                // Auto-route to specific queues based on category
                string queue = selectedJobType switch
                {
                    "email" or "sms" => "emails",
                    "health" or "cleanup" => "critical",
                    "rep_emp" or "rep_sales" or "rep_exp" => "background",
                    _ => "default"
                };

                tasks.Add(Queue.EnqueueAsync(job, priority, queue, "Launcher"));
            }

            await Task.WhenAll(tasks);
        });

        isLoading = false;
        statusMessage = $"Enqueued {count} jobs ({selectedJobType})!";
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Bus\Components\Pages\NotFound.razor
@page "/not-found"
@layout MainLayout

<h3>Not Found</h3>
<p>Sorry, the content you are looking for does not exist.</p>

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Bus\Jobs\MailingJobs.cs
using ChokaQ.Abstractions.Jobs;

namespace ChokaQ.Sample.Bus.Jobs;

public record EmailJob(string To, string Subject) : ChokaQBaseJob;
public record SmsJob(string PhoneNumber, string Message) : ChokaQBaseJob;

public class EmailJobHandler : IChokaQJobHandler<EmailJob>
{
    private readonly ILogger<EmailJobHandler> _logger;

    public EmailJobHandler(ILogger<EmailJobHandler> logger) => _logger = logger;

    public async Task HandleAsync(EmailJob job, CancellationToken ct)
    {
        // Simulate heavy processing / network latency
        await Task.Delay(500, ct);

        // Generate a random number between 0 and 9
        var roll = Random.Shared.Next(0, 10);

        // In 70% of cases (0..6), simulate an SMTP server failure
        if (roll < 7)
        {
            var errors = new[] { "SMTP Timeout", "Connection Refused", "Greylisting active", "Auth failed" };
            var error = errors[Random.Shared.Next(errors.Length)];

            _logger.LogError("🧨 Oops! Failed to send email to {To}. Reason: {Error}", job.To, error);

            // THROW EXCEPTION -> THIS TRIGGERS SMART RETRY
            throw new Exception($"Simulated SMTP Error: {error}");
        }

        // In 30% of cases, success
        _logger.LogInformation("✅ Email successfully sent to {To}: {Subject}", job.To, job.Subject);
    }
}

public class SmsJobHandler : IChokaQJobHandler<SmsJob>
{
    private readonly ILogger<SmsJobHandler> _logger;
    public SmsJobHandler(ILogger<SmsJobHandler> logger) => _logger = logger;

    public async Task HandleAsync(SmsJob job, CancellationToken ct)
    {
        _logger.LogInformation("Sending SMS to {Phone}: {Msg}", job.PhoneNumber, job.Message);
        await Task.Delay(100, ct); // Simulate Gateway
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Bus\Jobs\ReportingJobs.cs
using ChokaQ.Abstractions.Contexts;
using ChokaQ.Abstractions.Jobs;

namespace ChokaQ.Sample.Bus.Jobs;

// --- DTOs ---
public record EmployeeReportJob(string DeptId) : ChokaQBaseJob;
public record SalesReportJob(int Year, int Month) : ChokaQBaseJob;
public record ExpenseReportJob(string CostCenter) : ChokaQBaseJob;

// --- HANDLERS ---
public class ReportingHandler<T> : IChokaQJobHandler<T> where T : IChokaQJob
{
    private readonly ILogger<ReportingHandler<T>> _logger;
    private readonly IJobContext _context;

    public ReportingHandler(ILogger<ReportingHandler<T>> logger, IJobContext context)
    {
        _logger = logger;
        _context = context;
    }

    public async Task HandleAsync(T job, CancellationToken ct)
    {
        var reportName = typeof(T).Name.Replace("Job", "");
        _logger.LogInformation("Generating {Report}...", reportName);

        // Simulate heavy work with progress
        for (int i = 0; i <= 100; i += 20)
        {
            await Task.Delay(200, ct);
            await _context.ReportProgressAsync(i);
        }

        _logger.LogInformation("{Report} saved to storage.", reportName);
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Bus\Jobs\SystemJobs.cs
using ChokaQ.Abstractions.Jobs;

namespace ChokaQ.Sample.Bus.Jobs;

// --- DTOs ---
public record HealthCheckJob(string TargetService) : ChokaQBaseJob;
public record CleanupJob(int RetentionDays) : ChokaQBaseJob;

// --- HANDLERS ---
public class HealthCheckHandler : IChokaQJobHandler<HealthCheckJob>
{
    private readonly ILogger<HealthCheckHandler> _logger;
    public HealthCheckHandler(ILogger<HealthCheckHandler> logger) => _logger = logger;

    public async Task HandleAsync(HealthCheckJob job, CancellationToken ct)
    {
        _logger.LogInformation("Checking health of {Service}...", job.TargetService);
        await Task.Delay(50, ct);
    }
}

public class CleanupJobHandler : IChokaQJobHandler<CleanupJob>
{
    private readonly ILogger<CleanupJobHandler> _logger;
    public CleanupJobHandler(ILogger<CleanupJobHandler> logger) => _logger = logger;

    public async Task HandleAsync(CleanupJob job, CancellationToken ct)
    {
        _logger.LogWarning("Cleaning up data older than {Days} days...", job.RetentionDays);
        await Task.Delay(1000, ct);
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Bus\Profiles\MailingProfile.cs
using ChokaQ.Abstractions.Jobs;
using ChokaQ.Sample.Bus.Jobs;

namespace ChokaQ.Sample.Bus.Profiles;

public class MailingProfile : ChokaQJobProfile
{
    public MailingProfile()
    {
        CreateJob<EmailJob, EmailJobHandler>("mail_email_v1");
        CreateJob<SmsJob, SmsJobHandler>("mail_sms_v1");
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Bus\Profiles\ReportingProfile.cs
using ChokaQ.Abstractions.Jobs;
using ChokaQ.Sample.Bus.Jobs;

namespace ChokaQ.Sample.Bus.Profiles;

public class ReportingProfile : ChokaQJobProfile
{
    public ReportingProfile()
    {
        CreateJob<EmployeeReportJob, ReportingHandler<EmployeeReportJob>>("rep_employee");
        CreateJob<SalesReportJob, ReportingHandler<SalesReportJob>>("rep_sales");
        CreateJob<ExpenseReportJob, ReportingHandler<ExpenseReportJob>>("rep_expenses");
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Bus\Profiles\SystemProfile.cs
using ChokaQ.Abstractions.Jobs;
using ChokaQ.Sample.Bus.Jobs;

namespace ChokaQ.Sample.Bus.Profiles;

public class SystemProfile : ChokaQJobProfile
{
    public SystemProfile()
    {
        CreateJob<HealthCheckJob, HealthCheckHandler>("sys_health_check");
        CreateJob<CleanupJob, CleanupJobHandler>("sys_cleanup");
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Bus\Properties\launchSettings.json
{
  "$schema": "https://json.schemastore.org/launchsettings.json",
    "profiles": {
      "http": {
        "commandName": "Project",
        "dotnetRunMessages": true,
        "launchBrowser": true,
        "applicationUrl": "http://localhost:5299",
        "environmentVariables": {
          "ASPNETCORE_ENVIRONMENT": "Development"
        }
      },
      "https": {
        "commandName": "Project",
        "dotnetRunMessages": true,
        "launchBrowser": true,
        "applicationUrl": "https://localhost:7164;http://localhost:5299",
        "environmentVariables": {
          "ASPNETCORE_ENVIRONMENT": "Development"
        }
      }
    }
  }

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Bus\wwwroot\app.css
h1:focus {
    outline: none;
}

.valid.modified:not([type=checkbox]) {
    outline: 1px solid #26b050;
}

.invalid {
    outline: 1px solid #e50000;
}

.validation-message {
    color: #e50000;
}

.blazor-error-boundary {
    background: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNTYiIGhlaWdodD0iNDkiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkveGxpbmsiIG92ZXJmbG93PSJoaWRkZW4iPjxkZWZzPjxjbGlwUGF0aCBpZD0iY2xpcDAiPjxyZWN0IHg9IjIzNSIgeT0iNTEiIHdpZHRoPSI1NiIgaGVpZ2h0PSI0OSIvPjwvY2xpcFBhdGg+PC9kZWZzPjxnIGNsaXAtcGF0aD0idXJsKCNjbGlwMCkiIHRyYW5zZm9ybT0idHJhbnNsYXRlKC0yMzUgLTUxKSI+PHBhdGggZD0iTTI2My41MDYgNTFDMjY0LjcxNyA1MSAyNjUuODEzIDUxLjQ4MzcgMjY2LjYwNiA1Mi4yNjU4TDI2Ny4wNTIgNTIuNzk4NyAyNjcuNTM5IDUzLjYyODMgMjkwLjE4NSA5Mi4xODMxIDI5MC41NDUgOTIuNzk1IDI5MC42NTYgOTIuOTk2QzI5MC44NzcgOTMuNTEzIDI5MSA5NC4wODE1IDI5MSA5NC42NzgyIDI5MSA5Ny4wNjUxIDI4OS4wMzggOTkgMjg2LjYxNyA5OUwyNDAuMzgzIDk5QzIzNy45NjMgOTkgMjM2IDk3LjA2NTEgMjM2IDk0LjY3ODIgMjM2IDk0LjM3OTkgMjM2LjAzMSA5NC4wODg2IDIzNi4wODkgOTMuODA3MkwyMzYuMzM4IDkzLjAxNjIgMjM2Ljg1OCA5Mi4xMzE0IDI1OS40NzMgNTMuNjI5NCAyNTkuOTYxIDUyLjc5ODUgMjYwLjQwNyA1Mi4yNjU4QzI2MS4yIDUxLjQ4MzcgMjYyLjI5NiA1MSAyNjMuNTA2IDUxWk0yNjMuNTg2IDY2LjAxODNDMjYwLjczNyA2Ni4wMTgzIDI1OS4zMTMgNjcuMTI0NSAyNTkuMzEzIDY5LjMzNyAyNTkuMzEzIDY5LjYxMDIgMjU5LjMzMiA2OS44NjA4IDI1OS4zNzEgNzAuMDg4N0wyNjEuNzk1IDg0LjAxNjEgMjY1LjM4IDg0LjAxNjEgMjY3LjgyMSA2OS43NDc1QzI2Ny44NiA2OS43MzA5IDI2Ny44NzkgNjkuNTg3NyAyNjcuODc5IDY5LjMxNzkgMjY3Ljg3OSA2Ny4xMTgyIDI2Ni40NDggNjYuMDE4MyAyNjMuNTg2IDY2LjAxODNaTTI2My41NzYgODYuMDU0N0MyNjEuMDQ5IDg2LjA1NDcgMjU5Ljc4NiA4Ny4zMDA1IDI1OS43ODYgODkuNzkyMSAyNTkuNzg2IDkyLjI4MzcgMjYxLjA0OSA5My41Mjk1IDI2My41NzYgOTMuNTI5NSAyNjYuMTE2IDkzLjUyOTUgMjY3LjM4NyA5Mi4yODM3IDI2Ny4zODcgODkuNzkyMSAyNjcuMzg3IDg3LjMwMDUgMjY2LjExNiA4Ni4wNTQ3IDI2My41NzYgODYuMDU0N1oiIGZpbGw9IiNGRkU1MDAiIGZpbGwtcnVsZT0iZXZlbm9kZCIvPjwvZz48L3N2Zz4=) no-repeat 1rem/1.8rem, #b32121;
    padding: 1rem 1rem 1rem 3.7rem;
    color: white;
}

    .blazor-error-boundary::after {
        content: "An error has occurred."
    }

.darker-border-checkbox.form-check-input {
    border-color: #929292;
}

.form-floating > .form-control-plaintext::placeholder, .form-floating > .form-control::placeholder {
    color: var(--bs-secondary-color);
    text-align: end;
}

.form-floating > .form-control-plaintext:focus::placeholder, .form-floating > .form-control:focus::placeholder {
    text-align: start;
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Pipe\appsettings.Development.json
{
  "Logging": {
    "LogLevel": {
      "Default": "Information",
      "Microsoft.AspNetCore": "Warning"
    }
  }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Pipe\appsettings.json
{
  "Logging": {
    "LogLevel": {
      "Default": "Information",
      "Microsoft.AspNetCore": "Warning"
    }
  },
  "AllowedHosts": "*"
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Pipe\ChokaQ.Sample.Pipe.csproj
<Project Sdk="Microsoft.NET.Sdk.Web">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <Nullable>enable</Nullable>
    <ImplicitUsings>enable</ImplicitUsings>
    <BlazorDisableThrowNavigationException>true</BlazorDisableThrowNavigationException>
  </PropertyGroup>

	<ItemGroup>
		<ProjectReference Include="..\..\src\ChokaQ.Abstractions\ChokaQ.Abstractions.csproj" />
		<ProjectReference Include="..\..\src\ChokaQ.Core\ChokaQ.Core.csproj" />
		<ProjectReference Include="..\..\src\ChokaQ.TheDeck\ChokaQ.TheDeck.csproj" />
	</ItemGroup>

</Project>

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Pipe\Program.cs
using ChokaQ.Core.Extensions;
using ChokaQ.Sample.Pipe.Components;
using ChokaQ.Sample.Pipe.Services;
using ChokaQ.TheDeck.Extensions;

var builder = WebApplication.CreateBuilder(args);

// Add services to the container.
builder.Services.AddRazorComponents()
    .AddInteractiveServerComponents();

// --- CHOKAQ PIPE CONFIGURATION ---
builder.Services.AddChokaQ(options => options.UsePipe<GlobalPipeHandler>());

builder.Services.AddChokaQTheDeck();

var app = builder.Build();

// Configure the HTTP request pipeline.
if (!app.Environment.IsDevelopment())
{
    app.UseExceptionHandler("/Error", createScopeForErrors: true);
    app.UseHsts();
}

app.UseHttpsRedirection();
app.UseStaticFiles();
app.UseAntiforgery();

app.MapRazorComponents<App>()
    .AddInteractiveServerRenderMode();

app.MapChokaQTheDeck();

app.Run();

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Pipe\Components\App.razor
<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <base href="/" />
    <ResourcePreloader />
    <link rel="stylesheet" href="@Assets["app.css"]" />
    <link rel="stylesheet" href="@Assets["ChokaQ.Sample.Pipe.styles.css"]" />
    <ImportMap />
    <link rel="icon" type="image/png" href="favicon.png" />
    <HeadOutlet @rendermode="InteractiveServer" />
</head>

<body>
    <Routes @rendermode="InteractiveServer" />
    <ReconnectModal />
    <script src="@Assets["_framework/blazor.web.js"]"></script>
</body>

</html>

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Pipe\Components\Routes.razor
<Router AppAssembly="typeof(Program).Assembly" NotFoundPage="typeof(Pages.NotFound)">
    <Found Context="routeData">
        <RouteView RouteData="routeData" DefaultLayout="typeof(Layout.MainLayout)" />
        <FocusOnNavigate RouteData="routeData" Selector="h1" />
    </Found>
</Router>

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Pipe\Components\_Imports.razor
@using System.Net.Http
@using System.Net.Http.Json
@using Microsoft.AspNetCore.Components.Forms
@using Microsoft.AspNetCore.Components.Routing
@using Microsoft.AspNetCore.Components.Web
@using static Microsoft.AspNetCore.Components.Web.RenderMode
@using Microsoft.AspNetCore.Components.Web.Virtualization
@using Microsoft.JSInterop
@using ChokaQ.Sample.Pipe
@using ChokaQ.Sample.Pipe.Components
@using ChokaQ.Sample.Pipe.Components.Layout

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Pipe\Components\Layout\MainLayout.razor
@inherits LayoutComponentBase

<div class="container py-5">
    <main>
        @Body
    </main>
</div>

<div id="blazor-error-ui" data-nosnippet>
    An unhandled error has occurred.
    <a href="." class="reload">Reload</a>
    <span class="dismiss">🗙</span>
</div>

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Pipe\Components\Layout\MainLayout.razor.css
#blazor-error-ui {
    background: lightyellow;
    bottom: 0;
    box-shadow: 0 -1px 2px rgba(0, 0, 0, 0.2);
    display: none;
    left: 0;
    padding: 0.6rem 1.25rem 0.7rem 1.25rem;
    position: fixed;
    width: 100%;
    z-index: 1000;
}

    #blazor-error-ui .dismiss {
        cursor: pointer;
        position: absolute;
        right: 0.75rem;
        top: 0.5rem;
    }

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Pipe\Components\Layout\ReconnectModal.razor
<script type="module" src="@Assets["Components/Layout/ReconnectModal.razor.js"]"></script>

<dialog id="components-reconnect-modal" data-nosnippet>
    <div class="components-reconnect-container">
        <div class="components-rejoining-animation" aria-hidden="true">
            <div></div>
            <div></div>
        </div>
        <p class="components-reconnect-first-attempt-visible">
            Rejoining the server...
        </p>
        <p class="components-reconnect-repeated-attempt-visible">
            Rejoin failed... trying again in <span id="components-seconds-to-next-attempt"></span> seconds.
        </p>
        <p class="components-reconnect-failed-visible">
            Failed to rejoin.<br />Please retry or reload the page.
        </p>
        <button id="components-reconnect-button" class="components-reconnect-failed-visible">
            Retry
        </button>
        <p class="components-pause-visible">
            The session has been paused by the server.
        </p>
        <p class="components-resume-failed-visible">
            Failed to resume the session.<br />Please retry or reload the page.
        </p>
        <button id="components-resume-button" class="components-pause-visible components-resume-failed-visible">
            Resume
        </button>
    </div>
</dialog>

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Pipe\Components\Layout\ReconnectModal.razor.css
.components-reconnect-first-attempt-visible,
.components-reconnect-repeated-attempt-visible,
.components-reconnect-failed-visible,
.components-pause-visible,
.components-resume-failed-visible,
.components-rejoining-animation {
    display: none;
}

#components-reconnect-modal.components-reconnect-show .components-reconnect-first-attempt-visible,
#components-reconnect-modal.components-reconnect-show .components-rejoining-animation,
#components-reconnect-modal.components-reconnect-paused .components-pause-visible,
#components-reconnect-modal.components-reconnect-resume-failed .components-resume-failed-visible,
#components-reconnect-modal.components-reconnect-retrying,
#components-reconnect-modal.components-reconnect-retrying .components-reconnect-repeated-attempt-visible,
#components-reconnect-modal.components-reconnect-retrying .components-rejoining-animation,
#components-reconnect-modal.components-reconnect-failed,
#components-reconnect-modal.components-reconnect-failed .components-reconnect-failed-visible {
    display: block;
}


#components-reconnect-modal {
    background-color: white;
    width: 20rem;
    margin: 20vh auto;
    padding: 2rem;
    border: 0;
    border-radius: 0.5rem;
    box-shadow: 0 3px 6px 2px rgba(0, 0, 0, 0.3);
    opacity: 0;
    transition: display 0.5s allow-discrete, overlay 0.5s allow-discrete;
    animation: components-reconnect-modal-fadeOutOpacity 0.5s both;
    &[open]

{
    animation: components-reconnect-modal-slideUp 1.5s cubic-bezier(.05, .89, .25, 1.02) 0.3s, components-reconnect-modal-fadeInOpacity 0.5s ease-in-out 0.3s;
    animation-fill-mode: both;
}

}

#components-reconnect-modal::backdrop {
    background-color: rgba(0, 0, 0, 0.4);
    animation: components-reconnect-modal-fadeInOpacity 0.5s ease-in-out;
    opacity: 1;
}

@keyframes components-reconnect-modal-slideUp {
    0% {
        transform: translateY(30px) scale(0.95);
    }

    100% {
        transform: translateY(0);
    }
}

@keyframes components-reconnect-modal-fadeInOpacity {
    0% {
        opacity: 0;
    }

    100% {
        opacity: 1;
    }
}

@keyframes components-reconnect-modal-fadeOutOpacity {
    0% {
        opacity: 1;
    }

    100% {
        opacity: 0;
    }
}

.components-reconnect-container {
    display: flex;
    flex-direction: column;
    align-items: center;
    gap: 1rem;
}

#components-reconnect-modal p {
    margin: 0;
    text-align: center;
}

#components-reconnect-modal button {
    border: 0;
    background-color: #6b9ed2;
    color: white;
    padding: 4px 24px;
    border-radius: 4px;
}

    #components-reconnect-modal button:hover {
        background-color: #3b6ea2;
    }

    #components-reconnect-modal button:active {
        background-color: #6b9ed2;
    }

.components-rejoining-animation {
    position: relative;
    width: 80px;
    height: 80px;
}

    .components-rejoining-animation div {
        position: absolute;
        border: 3px solid #0087ff;
        opacity: 1;
        border-radius: 50%;
        animation: components-rejoining-animation 1.5s cubic-bezier(0, 0.2, 0.8, 1) infinite;
    }

        .components-rejoining-animation div:nth-child(2) {
            animation-delay: -0.5s;
        }

@keyframes components-rejoining-animation {
    0% {
        top: 40px;
        left: 40px;
        width: 0;
        height: 0;
        opacity: 0;
    }

    4.9% {
        top: 40px;
        left: 40px;
        width: 0;
        height: 0;
        opacity: 0;
    }

    5% {
        top: 40px;
        left: 40px;
        width: 0;
        height: 0;
        opacity: 1;
    }

    100% {
        top: 0px;
        left: 0px;
        width: 80px;
        height: 80px;
        opacity: 0;
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Pipe\Components\Layout\ReconnectModal.razor.js
// Set up event handlers
const reconnectModal = document.getElementById("components-reconnect-modal");
reconnectModal.addEventListener("components-reconnect-state-changed", handleReconnectStateChanged);

const retryButton = document.getElementById("components-reconnect-button");
retryButton.addEventListener("click", retry);

const resumeButton = document.getElementById("components-resume-button");
resumeButton.addEventListener("click", resume);

function handleReconnectStateChanged(event) {
    if (event.detail.state === "show") {
        reconnectModal.showModal();
    } else if (event.detail.state === "hide") {
        reconnectModal.close();
    } else if (event.detail.state === "failed") {
        document.addEventListener("visibilitychange", retryWhenDocumentBecomesVisible);
    } else if (event.detail.state === "rejected") {
        location.reload();
    }
}

async function retry() {
    document.removeEventListener("visibilitychange", retryWhenDocumentBecomesVisible);

    try {
        // Reconnect will asynchronously return:
        // - true to mean success
        // - false to mean we reached the server, but it rejected the connection (e.g., unknown circuit ID)
        // - exception to mean we didn't reach the server (this can be sync or async)
        const successful = await Blazor.reconnect();
        if (!successful) {
            // We have been able to reach the server, but the circuit is no longer available.
            // We'll reload the page so the user can continue using the app as quickly as possible.
            const resumeSuccessful = await Blazor.resumeCircuit();
            if (!resumeSuccessful) {
                location.reload();
            } else {
                reconnectModal.close();
            }
        }
    } catch (err) {
        // We got an exception, server is currently unavailable
        document.addEventListener("visibilitychange", retryWhenDocumentBecomesVisible);
    }
}

async function resume() {
    try {
        const successful = await Blazor.resumeCircuit();
        if (!successful) {
            location.reload();
        }
    } catch {
        reconnectModal.classList.replace("components-reconnect-paused", "components-reconnect-resume-failed");
    }
}

async function retryWhenDocumentBecomesVisible() {
    if (document.visibilityState === "visible") {
        await retry();
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Pipe\Components\Pages\Error.razor
@page "/Error"
@using System.Diagnostics

<PageTitle>Error</PageTitle>

<h1 class="text-danger">Error.</h1>
<h2 class="text-danger">An error occurred while processing your request.</h2>

@if (ShowRequestId)
{
    <p>
        <strong>Request ID:</strong> <code>@RequestId</code>
    </p>
}

<h3>Development Mode</h3>
<p>
    Swapping to <strong>Development</strong> environment will display more detailed information about the error that occurred.
</p>
<p>
    <strong>The Development environment shouldn't be enabled for deployed applications.</strong>
    It can result in displaying sensitive information from exceptions to end users.
    For local debugging, enable the <strong>Development</strong> environment by setting the <strong>ASPNETCORE_ENVIRONMENT</strong> environment variable to <strong>Development</strong>
    and restarting the app.
</p>

@code{
    [CascadingParameter]
    private HttpContext? HttpContext { get; set; }

    private string? RequestId { get; set; }
    private bool ShowRequestId => !string.IsNullOrEmpty(RequestId);

    protected override void OnInitialized() =>
        RequestId = Activity.Current?.Id ?? HttpContext?.TraceIdentifier;
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Pipe\Components\Pages\Home.razor
@page "/"
@rendermode InteractiveServer

<PageTitle>Pipe Launcher</PageTitle>

<div class="container">
    <div class="title-group">
        <h1>🚀 Pipe Mode</h1>
        <p class="subtitle">Raw objects -> Global Handler</p>
    </div>

    <div class="card">
        <div class="form-group">
            <label>Select Event Type</label>
            <select class="input-control" @bind="_selectedType">
                <option value="log">Fast Log (Text)</option>
                <option value="metric">Metric (Sensor Data)</option>
                <option value="heavy">Heavy Operation (Delay)</option>
            </select>
        </div>

        <div class="form-group">
            <label>Count</label>
            <input type="number" class="input-control" @bind="_count" min="1" max="1000" />
        </div>

        <button class="btn btn-primary" @onclick="Fire" disabled="@_isBusy">
            @if (_isBusy)
            {
                <span>Sending...</span>
            }
            else
            {
                <span>🔥 Fire Into Pipe</span>
            }
        </button>

        @if (_message != null)
        {
            <div class="alert alert-success">@_message</div>
        }
    </div>

    <a href="/chokaq" target="_blank" class="btn btn-outline">
        📊 Open Dashboard
    </a>
</div>

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Pipe\Components\Pages\Home.razor.cs
using ChokaQ.Abstractions.Storage;
using ChokaQ.Sample.Pipe.Jobs;
using Microsoft.AspNetCore.Components;

namespace ChokaQ.Sample.Pipe.Components.Pages;

public partial class Home
{
    [Inject] public IChokaQQueue Queue { get; set; } = default!;

    private string _selectedType = "log";
    private int _count = 1;
    private bool _isBusy;
    private string? _message;

    private async Task Fire()
    {
        _isBusy = true;
        _message = null;

        // Run in background to avoid blocking UI thread on heavy enqueues
        await Task.Run(async () =>
        {
            var tasks = new List<Task>();

            for (int i = 0; i < _count; i++)
            {
                // In Pipe Mode, we send typed objects (DTOs).
                // The library uses the class name ("FastLog", "MetricEvent") as the Job Type Key.
                // The GlobalPipeHandler will receive this key and the JSON payload.

                Task t = _selectedType switch
                {
                    "log" => Queue.EnqueueAsync(new FastLog($"Log entry #{i}", "INFO")),
                    "metric" => Queue.EnqueueAsync(new MetricEvent("Sensor-01", Random.Shared.NextDouble() * 100, DateTime.UtcNow)),
                    "heavy" => Queue.EnqueueAsync(new SlowOperation(2000)),
                    _ => Task.CompletedTask
                };
                tasks.Add(t);
            }

            await Task.WhenAll(tasks);
        });

        _isBusy = false;
        _message = $"Sent {_count} events of type '{_selectedType}'!";
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Pipe\Components\Pages\NotFound.razor
@page "/not-found"
@layout MainLayout

<h3>Not Found</h3>
<p>Sorry, the content you are looking for does not exist.</p>

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Pipe\Jobs\PipeContracts.cs
using ChokaQ.Abstractions.Jobs;

namespace ChokaQ.Sample.Pipe.Jobs;

// Inherit from ChokaQBaseJob to satisfy the IChokaQQueue generic constraint.
public record FastLog(string Message, string Level) : ChokaQBaseJob;

public record MetricEvent(string SensorId, double Value, DateTime Timestamp) : ChokaQBaseJob;

public record SlowOperation(int DurationMs) : ChokaQBaseJob;

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Pipe\Properties\launchSettings.json
{
  "$schema": "https://json.schemastore.org/launchsettings.json",
    "profiles": {
      "http": {
        "commandName": "Project",
        "dotnetRunMessages": true,
        "launchBrowser": true,
        "applicationUrl": "http://localhost:5194",
        "environmentVariables": {
          "ASPNETCORE_ENVIRONMENT": "Development"
        }
      },
      "https": {
        "commandName": "Project",
        "dotnetRunMessages": true,
        "launchBrowser": true,
        "applicationUrl": "https://localhost:7231;http://localhost:5194",
        "environmentVariables": {
          "ASPNETCORE_ENVIRONMENT": "Development"
        }
      }
    }
  }

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Pipe\Services\GlobalPipeHandler.cs
using ChokaQ.Abstractions.Jobs;
using System.Text.Json;

namespace ChokaQ.Sample.Pipe.Services;

public class GlobalPipeHandler : IChokaQPipeHandler
{
    private readonly ILogger<GlobalPipeHandler> _logger;

    public GlobalPipeHandler(ILogger<GlobalPipeHandler> logger)
    {
        _logger = logger;
    }

    public async Task HandleAsync(string jobType, string payload, CancellationToken ct)
    {
        // In PIPE mode, we receive the raw string key and the JSON payload.
        // We decide how to parse and process it manually.

        switch (jobType)
        {
            case "FastLog":
                // Parse manually or via JsonElement (quick and dirty)
                var log = JsonSerializer.Deserialize<JsonElement>(payload);
                var lvl = log.GetProperty("Level").GetString();
                var msg = log.GetProperty("Message").GetString();

                _logger.LogInformation("[PIPE LOG] {Level}: {Message}", lvl, msg);
                break;

            case "MetricEvent":
                // We can just log the raw payload or deserialize to a local DTO if needed
                _logger.LogWarning("📊 METRIC RECEIVED: {Payload}", payload);
                await Task.Delay(50, ct); // Simulate DB write
                break;

            case "SlowOperation":
                _logger.LogInformation("🐢 Starting heavy calculation...");
                await Task.Delay(2000, ct);
                _logger.LogInformation("✅ Calculation done.");
                break;

            default:
                _logger.LogError("Unknown Item in the Pipe: {Type}", jobType);
                break;
        }
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\samples\ChokaQ.Sample.Pipe\wwwroot\app.css
/* Minimalist Reset */
html, body {
    margin: 0;
    padding: 0;
    font-family: 'Segoe UI', system-ui, sans-serif;
    background-color: #f5f5f7;
    color: #1d1d1f;
    line-height: 1.5;
}

/* Layout Helpers */
.container {
    max-width: 600px;
    margin: 0 auto;
    padding: 40px 20px;
    text-align: center;
}

.card {
    background: white;
    border-radius: 12px;
    padding: 30px;
    box-shadow: 0 4px 12px rgba(0,0,0,0.05);
    border: 1px solid rgba(0,0,0,0.05);
    text-align: left;
    margin-bottom: 20px;
}

.title-group {
    margin-bottom: 30px;
}

h1 {
    font-weight: 700;
    margin: 0 0 10px 0;
    letter-spacing: -0.5px;
}

.subtitle {
    color: #86868b;
    margin: 0;
}

/* Controls */
.form-group {
    margin-bottom: 20px;
}

label {
    display: block;
    font-weight: 600;
    font-size: 0.9rem;
    margin-bottom: 8px;
    color: #424245;
}

.input-control {
    width: 100%;
    padding: 10px 12px;
    font-size: 1rem;
    border: 1px solid #d2d2d7;
    border-radius: 8px;
    box-sizing: border-box;
    transition: border-color 0.2s;
}

    .input-control:focus {
        outline: none;
        border-color: #0071e3;
    }

/* Buttons */
.btn {
    display: inline-flex;
    justify-content: center;
    align-items: center;
    width: 100%;
    padding: 12px;
    font-size: 1rem;
    font-weight: 600;
    border: none;
    border-radius: 8px;
    cursor: pointer;
    transition: background 0.2s, transform 0.1s;
    text-decoration: none;
}

.btn-primary {
    background-color: #0071e3;
    color: white;
}

    .btn-primary:hover:not(:disabled) {
        background-color: #0077ed;
    }

    .btn-primary:active:not(:disabled) {
        transform: scale(0.98);
    }

    .btn-primary:disabled {
        background-color: #a1a1a6;
        cursor: not-allowed;
    }

.btn-outline {
    background: transparent;
    border: 1px solid #d2d2d7;
    color: #1d1d1f;
    margin-top: 15px;
}

    .btn-outline:hover {
        border-color: #86868b;
        background-color: #f5f5f7;
    }

/* Feedback */
.alert {
    margin-top: 15px;
    padding: 12px;
    border-radius: 8px;
    font-size: 0.9rem;
    text-align: center;
}

.alert-success {
    background-color: #e8f5e9;
    color: #1b5e20;
}

/* Blazor Error UI */
#blazor-error-ui {
    background: #fff3cd;
    bottom: 0;
    box-shadow: 0 -1px 2px rgba(0, 0, 0, 0.2);
    display: none;
    left: 0;
    padding: 0.6rem 1.25rem 0.7rem 1.25rem;
    position: fixed;
    width: 100%;
    z-index: 1000;
}

    #blazor-error-ui .dismiss {
        cursor: pointer;
        position: absolute;
        right: 0.75rem;
        top: 0.5rem;
    }

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Abstractions\ChokaQ.Abstractions.csproj
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
  </PropertyGroup>

</Project>

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Abstractions\Contexts\IJobContext.cs
namespace ChokaQ.Abstractions.Contexts;

/// <summary>
/// Provides context and tools for the currently executing job.
/// Allows handlers to report progress or check job ID without knowing about the worker.
/// </summary>
public interface IJobContext
{
    string JobId { get; }

    /// <summary>
    /// Reports execution progress (0-100) to the dashboard.
    /// </summary>
    Task ReportProgressAsync(int percentage);
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Abstractions\DTOs\CircuitStatsDto.cs
using ChokaQ.Abstractions.Enums;

namespace ChokaQ.Abstractions.DTOs;

/// <summary>
/// Circuit breaker statistics for a job type.
/// Used for resilience monitoring in the dashboard.
/// </summary>
public record CircuitStatsDto(
    string JobType,
    CircuitStatus Status,
    int FailureCount,
    DateTime? ResetAtUtc
);

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Abstractions\DTOs\JobDataUpdateDto.cs
namespace ChokaQ.Abstractions.DTOs;

/// <summary>
/// Unified DTO for editing job data (Payload, Tags, Priority).
/// Used for Hot Editing (Pending jobs) and Resurrection (DLQ jobs).
/// </summary>
public record JobDataUpdateDto(
    string? Payload,
    string? Tags,
    int? Priority
)
{
    /// <summary>
    /// Creates an empty update (no changes).
    /// </summary>
    public static JobDataUpdateDto Empty => new(null, null, null);

    /// <summary>
    /// Checks if any field is set for update.
    /// </summary>
    public bool HasChanges => Payload is not null || Tags is not null || Priority is not null;
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Abstractions\DTOs\JobUpdateDto.cs
using ChokaQ.Abstractions.Enums;

namespace ChokaQ.Abstractions.DTOs;

/// <summary>
/// Real-time job update payload for SignalR notifications.
/// Bundled into a single DTO to avoid SignalR's 8-parameter method limit.
/// </summary>
/// <remarks>
/// Sent via IChokaQNotifier.NotifyJobUpdatedAsync when job state changes.
/// Dashboard components subscribe to "JobUpdated" hub method.
/// </remarks>
/// <param name="JobId">Unique job identifier for client-side lookup.</param>
/// <param name="Type">Job type for display and filtering.</param>
/// <param name="Queue">Queue name for categorization.</param>
/// <param name="Status">New job status after the update.</param>
/// <param name="AttemptCount">Current retry attempt number.</param>
/// <param name="Priority">Current priority (may change via dashboard).</param>
/// <param name="DurationMs">Elapsed time if processing, total time if completed.</param>
/// <param name="CreatedBy">Original creator for audit display.</param>
/// <param name="StartedAtUtc">Processing start time for duration calculation.</param>
public record JobUpdateDto(
    string JobId,
    string Type,
    string Queue,
    JobStatus Status,
    int AttemptCount,
    int Priority,
    double? DurationMs,
    string? CreatedBy,
    DateTime? StartedAtUtc
);

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Abstractions\Entities\JobArchiveEntity.cs
namespace ChokaQ.Abstractions.Entities;

/// <summary>
/// Represents a successfully completed job in the JobsArchive table (Second Pillar).
/// Contains immutable historical records of succeeded jobs.
/// Optimized for analytical queries with page compression enabled.
/// </summary>
/// <remarks>
/// Jobs are moved here atomically from JobsHot upon successful completion.
/// Supports retention policies via scheduled purge operations.
/// </remarks>
/// <param name="Id">Original job identifier from JobsHot.</param>
/// <param name="Queue">Queue where the job was processed.</param>
/// <param name="Type">Job handler type that executed this job.</param>
/// <param name="Payload">Original job payload (preserved for audit/replay).</param>
/// <param name="Tags">Original tags for historical filtering.</param>
/// <param name="AttemptCount">Final attempt count (1 = first-try success).</param>
/// <param name="WorkerId">Worker that successfully completed this job.</param>
/// <param name="CreatedBy">Original creator for audit trail.</param>
/// <param name="LastModifiedBy">Last modifier before archival.</param>
/// <param name="CreatedAtUtc">Original job creation time.</param>
/// <param name="StartedAtUtc">When processing began.</param>
/// <param name="FinishedAtUtc">When processing completed successfully.</param>
/// <param name="DurationMs">Total execution time in milliseconds.</param>
public record JobArchiveEntity(
    string Id,
    string Queue,
    string Type,
    string? Payload,
    string? Tags,
    int AttemptCount,
    string? WorkerId,
    string? CreatedBy,
    string? LastModifiedBy,
    DateTime CreatedAtUtc,
    DateTime? StartedAtUtc,
    DateTime FinishedAtUtc,
    double? DurationMs
);

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Abstractions\Entities\JobDLQEntity.cs
using ChokaQ.Abstractions.Enums;

namespace ChokaQ.Abstractions.Entities;

/// <summary>
/// Represents a failed job in the JobsDLQ (Dead Letter Queue) table (Third Pillar).
/// Contains jobs that cannot proceed without manual intervention.
/// </summary>
/// <remarks>
/// Jobs end up here due to:
/// - MaxRetries exhausted (FailureReason.MaxRetriesExceeded)
/// - Manual cancellation (FailureReason.Cancelled)
/// - Zombie detection (FailureReason.Zombie)
/// 
/// Supports resurrection back to JobsHot for retry with fresh state.
/// </remarks>
/// <param name="Id">Original job identifier for correlation.</param>
/// <param name="Queue">Queue where failure occurred.</param>
/// <param name="Type">Job handler type for debugging.</param>
/// <param name="Payload">Original payload for manual inspection/editing.</param>
/// <param name="Tags">Original tags preserved for filtering.</param>
/// <param name="FailureReason">Categorized reason for DLQ placement.</param>
/// <param name="ErrorDetails">Exception message, stack trace, or cancellation reason.</param>
/// <param name="AttemptCount">Number of attempts before failure.</param>
/// <param name="WorkerId">Last worker that attempted this job.</param>
/// <param name="CreatedBy">Original creator for accountability.</param>
/// <param name="LastModifiedBy">Last modifier before failure.</param>
/// <param name="CreatedAtUtc">Original job creation time.</param>
/// <param name="FailedAtUtc">When the job was moved to DLQ.</param>
public record JobDLQEntity(
    string Id,
    string Queue,
    string Type,
    string? Payload,
    string? Tags,

    FailureReason FailureReason,
    string? ErrorDetails,
    int AttemptCount,

    string? WorkerId,
    string? CreatedBy,
    string? LastModifiedBy,

    DateTime CreatedAtUtc,
    DateTime FailedAtUtc
);

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Abstractions\Entities\JobHotEntity.cs
using ChokaQ.Abstractions.Enums;

namespace ChokaQ.Abstractions.Entities;

/// <summary>
/// Represents an active job in the JobsHot table (First Pillar).
/// Contains jobs in Pending, Fetched, or Processing states.
/// Optimized for high-frequency read/write with row-level locking.
/// </summary>
/// <remarks>
/// Lifecycle: Enqueue → Fetch → Process → Archive/DLQ
/// Jobs are removed from Hot table upon completion (success or failure).
/// </remarks>
/// <param name="Id">Unique job identifier (GUID without hyphens).</param>
/// <param name="Queue">Logical queue name for job routing (e.g., "mailing", "reports").</param>
/// <param name="Type">Fully qualified job handler type name for dispatcher resolution.</param>
/// <param name="Payload">JSON-serialized job arguments. Nullable for parameterless jobs.</param>
/// <param name="Tags">Comma-separated tags for filtering and categorization.</param>
/// <param name="IdempotencyKey">Optional key to prevent duplicate job creation.</param>
/// <param name="Priority">Execution priority (higher = sooner). Default is 10.</param>
/// <param name="Status">Current job state: Pending(0), Fetched(1), Processing(2).</param>
/// <param name="AttemptCount">Number of execution attempts. Incremented on retry.</param>
/// <param name="WorkerId">Identifier of the worker that claimed this job.</param>
/// <param name="HeartbeatUtc">Last heartbeat timestamp for zombie detection.</param>
/// <param name="ScheduledAtUtc">Earliest execution time. Null means immediate.</param>
/// <param name="CreatedAtUtc">Job creation timestamp (UTC).</param>
/// <param name="StartedAtUtc">Processing start timestamp for duration calculation.</param>
/// <param name="LastUpdatedUtc">Last modification timestamp for optimistic concurrency.</param>
/// <param name="CreatedBy">User or system that created the job (audit trail).</param>
/// <param name="LastModifiedBy">User or system that last modified the job.</param>
public record JobHotEntity(
    string Id,
    string Queue,
    string Type,
    string? Payload,
    string? Tags,
    string? IdempotencyKey,

    int Priority,
    JobStatus Status,
    int AttemptCount,

    string? WorkerId,
    DateTime? HeartbeatUtc,

    DateTime? ScheduledAtUtc,
    DateTime CreatedAtUtc,
    DateTime? StartedAtUtc,
    DateTime LastUpdatedUtc,
    string? CreatedBy,
    string? LastModifiedBy
);

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Abstractions\Entities\QueueEntity.cs
namespace ChokaQ.Abstractions.Entities;

/// <summary>
/// Represents queue configuration in the Queues table.
/// Provides runtime control plane for operational management.
/// </summary>
/// <remarks>
/// Queues are auto-created on first job enqueue.
/// Configuration changes take effect immediately (no restart required).
/// </remarks>
/// <param name="Name">Unique queue identifier (e.g., "default", "mailing", "reports").</param>
/// <param name="IsPaused">When true, workers skip this queue during fetch operations.</param>
/// <param name="IsActive">When false, queue is hidden from dashboard (soft delete).</param>
/// <param name="ZombieTimeoutSeconds">Per-queue override for zombie detection. Null uses global setting.</param>
/// <param name="LastUpdatedUtc">Last configuration change timestamp.</param>
public record QueueEntity(
    string Name,
    bool IsPaused,
    bool IsActive,
    int? ZombieTimeoutSeconds,
    DateTime LastUpdatedUtc
);

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Abstractions\Entities\StatsSummaryEntity.cs
namespace ChokaQ.Abstractions.Entities;

/// <summary>
/// Represents job statistics combining real-time Hot counts with historical totals.
/// Used for dashboard metrics and operational monitoring.
/// </summary>
/// <remarks>
/// Data sources:
/// - Pending/Fetched/Processing: Real-time COUNT from JobsHot table
/// - SucceededTotal/FailedTotal/RetriedTotal: Pre-aggregated from StatsSummary table
/// - Total: Sum of all three pillars (Hot + Archive + DLQ)
/// 
/// This hybrid approach provides O(1) dashboard reads while maintaining accuracy.
/// </remarks>
/// <param name="Queue">Queue name for per-queue stats, or null for aggregated totals.</param>
/// <param name="Pending">Jobs waiting to be picked up by workers.</param>
/// <param name="Fetched">Jobs claimed by workers but not yet processing.</param>
/// <param name="Processing">Jobs currently being executed.</param>
/// <param name="SucceededTotal">Lifetime count of successfully completed jobs.</param>
/// <param name="FailedTotal">Lifetime count of jobs in DLQ (failed + cancelled + zombie).</param>
/// <param name="RetriedTotal">Lifetime count of retry attempts across all jobs.</param>
/// <param name="Total">Total jobs across all three pillars.</param>
/// <param name="LastActivityUtc">Most recent job activity timestamp.</param>
public record StatsSummaryEntity(
    string? Queue,
    int Pending,
    int Fetched,
    int Processing,
    long SucceededTotal,
    long FailedTotal,
    long RetriedTotal,
    long Total,
    DateTime? LastActivityUtc
);

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Abstractions\Enums\CircuitStatus.cs
namespace ChokaQ.Abstractions.Enums;

/// <summary>
/// Circuit breaker states following the standard circuit breaker pattern.
/// Prevents cascading failures by temporarily blocking requests to failing services.
/// </summary>
/// <remarks>
/// State transitions:
/// - Closed → Open: After failure threshold exceeded
/// - Open → HalfOpen: After reset timeout expires
/// - HalfOpen → Closed: If test request succeeds
/// - HalfOpen → Open: If test request fails
/// </remarks>
public enum CircuitStatus
{
    /// <summary>
    /// Normal operating state. All executions are allowed.
    /// Failure counter is active and tracking errors.
    /// </summary>
    Closed = 0,

    /// <summary>
    /// Failure threshold exceeded. All executions are blocked.
    /// System waits for ResetTimeout before transitioning to HalfOpen.
    /// </summary>
    Open = 1,

    /// <summary>
    /// Recovery testing state. Limited executions allowed to probe system health.
    /// Success transitions to Closed; failure returns to Open.
    /// </summary>
    HalfOpen = 2
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Abstractions\Enums\FailureReason.cs
namespace ChokaQ.Abstractions.Enums;

/// <summary>
/// Categorizes why a job was moved to the Dead Letter Queue (DLQ).
/// Used for filtering, analytics, and operational dashboards.
/// </summary>
public enum FailureReason
{
    /// <summary>
    /// Job failed after exhausting all retry attempts.
    /// ErrorDetails contains the last exception stack trace.
    /// </summary>
    MaxRetriesExceeded = 0,

    /// <summary>
    /// Job was manually cancelled by an administrator.
    /// ErrorDetails contains the admin identity and timestamp.
    /// </summary>
    Cancelled = 1,

    /// <summary>
    /// Job was detected as zombie (processing timed out).
    /// Worker heartbeat exceeded the configured threshold.
    /// ErrorDetails contains timeout details.
    /// </summary>
    Zombie = 2,

    /// <summary>
    /// Job failed due to circuit breaker being open.
    /// Too many failures for this job type; execution was blocked.
    /// </summary>
    CircuitBreakerOpen = 3,

    /// <summary>
    /// Job was rejected during enqueue (e.g., validation failure, queue full).
    /// Rare case for jobs that never started processing.
    /// </summary>
    Rejected = 4
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Abstractions\Enums\JobStatus.cs
namespace ChokaQ.Abstractions.Enums;

/// <summary>
/// Represents the lifecycle states of a background job.
/// 
/// Three Pillars Architecture:
/// - Hot Table (JobsHot): Pending, Fetched, Processing
/// - Archive (JobsArchive): Jobs that completed successfully (virtual Succeeded state)
/// - DLQ (JobsDLQ): Jobs that failed, were cancelled, or became zombies
/// </summary>
public enum JobStatus
{
    /// <summary>
    /// Job is queued and waiting to be fetched by a worker.
    /// Location: Hot Table
    /// </summary>
    Pending = 0,

    /// <summary>
    /// Job was fetched from database into worker memory buffer.
    /// Waiting for processing slot (semaphore).
    /// Location: Hot Table
    /// </summary>
    Fetched = 1,

    /// <summary>
    /// Job is actively being executed by a worker.
    /// HeartbeatUtc is updated periodically.
    /// Location: Hot Table
    /// </summary>
    Processing = 2,

    /// <summary>
    /// Job completed successfully.
    /// Note: In Three Pillars, succeeded jobs are moved to Archive table.
    /// This status is used for SignalR notifications and In-Memory mode.
    /// </summary>
    Succeeded = 3,

    /// <summary>
    /// Job failed after exhausting all retry attempts.
    /// Note: In Three Pillars, failed jobs are moved to DLQ table.
    /// This status is used for SignalR notifications and In-Memory mode.
    /// </summary>
    Failed = 4,

    /// <summary>
    /// Job was cancelled by an administrator.
    /// Note: In Three Pillars, cancelled jobs are moved to DLQ table.
    /// This status is used for SignalR notifications and In-Memory mode.
    /// </summary>
    Cancelled = 5,

    /// <summary>
    /// Job was detected as zombie (Processing with expired heartbeat).
    /// Note: In Three Pillars, zombie jobs are moved to DLQ table.
    /// This status is used for SignalR notifications and In-Memory mode.
    /// </summary>
    Zombie = 6
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Abstractions\Jobs\ChokaQBaseJob.cs
namespace ChokaQ.Abstractions.Jobs;

/// <summary>
/// Base implementation for jobs that automatically handles unique ID generation.
/// </summary>
public abstract record ChokaQBaseJob : IChokaQJob
{
    /// <summary>
    /// Unique identifier, auto-generated upon instantiation.
    /// </summary>
    public string Id { get; init; } = Guid.NewGuid().ToString();
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Abstractions\Jobs\ChokaQJobProfile.cs
namespace ChokaQ.Abstractions.Jobs;

/// <summary>
/// Base class for defining job configurations.
/// Allows explicit mapping between Job Keys, DTOs, and Handlers.
/// </summary>
public abstract class ChokaQJobProfile
{
    /// <summary>
    /// The list of configured job mappings. 
    /// Must be public so ChokaQ.Core can read it during startup.
    /// </summary>
    public List<JobRegistration> Registrations { get; } = new();

    /// <summary>
    /// Registers a job type and its corresponding handler with a specific key.
    /// </summary>
    /// <typeparam name="TJob">The job DTO type (must implement IChokaQJob).</typeparam>
    /// <typeparam name="THandler">The handler type (must implement IChokaQJobHandler<TJob>).</typeparam>
    /// <param name="typeKey">The unique string key identifying this job type (stored in DB).</param>
    protected void CreateJob<TJob, THandler>(string typeKey)
        where TJob : IChokaQJob
        where THandler : class, IChokaQJobHandler<TJob>
    {
        if (string.IsNullOrWhiteSpace(typeKey))
            throw new ArgumentNullException(nameof(typeKey));

        Registrations.Add(new JobRegistration(typeKey, typeof(TJob), typeof(THandler)));
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Abstractions\Jobs\IChokaQJob.cs
namespace ChokaQ.Abstractions.Jobs;

/// <summary>
/// Represents the fundamental unit of work in ChokaQ.
/// Any class intended to be processed in the background must implement this interface.
/// </summary>
public interface IChokaQJob
{
    /// <summary>
    /// Gets the unique identifier for the job instance.
    /// This ID is used for tracking, logging, and status updates.
    /// </summary>
    string Id { get; }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Abstractions\Jobs\IChokaQJobHandler.cs
namespace ChokaQ.Abstractions.Jobs;

/// <summary>
/// Defines the execution logic for a specific job type in Bus Mode.
/// Each job type requires exactly one handler registered via ChokaQJobProfile.
/// </summary>
/// <typeparam name="TJob">The job DTO type containing execution parameters.</typeparam>
/// <remarks>
/// Implementation guidelines:
/// - Handlers are resolved from DI container (scoped lifetime per job)
/// - Check CancellationToken regularly for graceful shutdown
/// - Throw exceptions to trigger retry logic
/// - Use IJobContext for progress reporting
/// 
/// Example:
/// <code>
/// public class SendEmailHandler : IChokaQJobHandler&lt;SendEmailJob&gt;
/// {
///     public async Task HandleAsync(SendEmailJob job, CancellationToken ct)
///     {
///         await _emailService.SendAsync(job.To, job.Subject, job.Body, ct);
///     }
/// }
/// </code>
/// </remarks>
public interface IChokaQJobHandler<in TJob> where TJob : IChokaQJob
{
    /// <summary>
    /// Executes the job logic.
    /// </summary>
    /// <param name="job">The deserialized job payload.</param>
    /// <param name="ct">Cancellation token for cooperative shutdown.</param>
    Task HandleAsync(TJob job, CancellationToken ct);
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Abstractions\Jobs\IChokaQPipeHandler.cs
namespace ChokaQ.Abstractions.Jobs;

/// <summary>
/// Global handler contract for Pipe Mode (high-throughput event processing).
/// All jobs are routed to a single handler without type-specific deserialization.
/// </summary>
/// <remarks>
/// Use Pipe Mode when:
/// - Processing high-volume event streams
/// - Job types are dynamic or unknown at compile time
/// - You need maximum throughput with minimal overhead
/// - Using external dispatch logic (e.g., routing based on payload content)
/// 
/// Pipe Mode vs Bus Mode:
/// - Bus Mode: Type-safe handlers, automatic DI, ChokaQJobProfile configuration
/// - Pipe Mode: Single handler, raw payloads, manual dispatch, maximum performance
/// 
/// Example:
/// <code>
/// public class GlobalPipeHandler : IChokaQPipeHandler
/// {
///     public async Task HandleAsync(string jobType, string payload, CancellationToken ct)
///     {
///         switch (jobType)
///         {
///             case "email": await ProcessEmail(payload, ct); break;
///             case "sms": await ProcessSms(payload, ct); break;
///             default: throw new NotSupportedException($"Unknown job type: {jobType}");
///         }
///     }
/// }
/// </code>
/// </remarks>
public interface IChokaQPipeHandler
{
    /// <summary>
    /// Processes a job with raw type key and JSON payload.
    /// </summary>
    /// <param name="jobType">Job type identifier (stored in Type column).</param>
    /// <param name="payload">Raw JSON payload from Payload column.</param>
    /// <param name="ct">Cancellation token for cooperative shutdown.</param>
    Task HandleAsync(string jobType, string payload, CancellationToken ct);
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Abstractions\Jobs\JobRegistration.cs
namespace ChokaQ.Abstractions.Jobs
{
    /// <summary>
    /// DTO to hold registration info.
    /// Made public so ChokaQ.Core can access the types during DI registration.
    /// </summary>
    public record JobRegistration(string Key, Type JobType, Type HandlerType);
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Abstractions\Notifications\IChokaQNotifier.cs
using ChokaQ.Abstractions.DTOs;

namespace ChokaQ.Abstractions.Notifications;

/// <summary>
/// Contract for real-time notifications via SignalR.
/// Supports Three Pillars architecture transitions.
/// </summary>
public interface IChokaQNotifier
{
    /// <summary>
    /// Notifies clients about a job status update in Hot table.
    /// </summary>
    Task NotifyJobUpdatedAsync(JobUpdateDto update);

    /// <summary>
    /// Notifies clients about job progress (0-100%).
    /// </summary>
    Task NotifyJobProgressAsync(string jobId, int percentage);

    /// <summary>
    /// Notifies clients that a job was archived to success history.
    /// Dashboard should move job from Active to History view.
    /// </summary>
    Task NotifyJobArchivedAsync(string jobId, string queue);

    /// <summary>
    /// Notifies clients that a job was moved to DLQ (failed/cancelled/zombie).
    /// Dashboard should move job from Active to Morgue view.
    /// </summary>
    Task NotifyJobFailedAsync(string jobId, string queue, string reason);

    /// <summary>
    /// Notifies clients that a job was resurrected from DLQ.
    /// Dashboard should move job from Morgue to Active view.
    /// </summary>
    Task NotifyJobResurrectedAsync(string jobId, string queue);

    /// <summary>
    /// Notifies clients that jobs were purged (permanently deleted).
    /// </summary>
    Task NotifyJobsPurgedAsync(string[] jobIds, string source);

    /// <summary>
    /// Notifies clients about queue state change (paused/resumed).
    /// </summary>
    Task NotifyQueueStateChangedAsync(string queueName, bool isPaused);

    /// <summary>
    /// Notifies clients about statistics update.
    /// Called after batch operations to refresh dashboard counters.
    /// </summary>
    Task NotifyStatsUpdatedAsync();
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Abstractions\Resilience\ICircuitBreaker.cs
using ChokaQ.Abstractions.DTOs;
using ChokaQ.Abstractions.Enums;

namespace ChokaQ.Abstractions.Resilience;

public interface ICircuitBreaker
{
    /// <summary>
    /// Checks if the execution of a specific job type is permitted.
    /// </summary>
    /// <param name="jobType">The key identifying the job type.</param>
    bool IsExecutionPermitted(string jobType);

    /// <summary>
    /// Reports a successful execution, resetting failure counters.
    /// </summary>
    void ReportSuccess(string jobType);

    /// <summary>
    /// Reports a failure, potentially opening the circuit.
    /// </summary>
    void ReportFailure(string jobType);

    /// <summary>
    /// Gets the current status of the circuit for monitoring purposes.
    /// </summary>
    CircuitStatus GetStatus(string jobType);

    /// <summary>
    /// Retrieves the status of all tracked circuits (Job Types).
    /// Used for monitoring/dashboard.
    /// </summary>
    IEnumerable<CircuitStatsDto> GetCircuitStats();
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Abstractions\Resilience\IDeduplicator.cs
namespace ChokaQ.Abstractions.Resilience;

/// <summary>
/// Defines a contract for a lightweight deduplication mechanism.
/// Used to prevent "retry storms" or double-clicks from hitting the database.
/// </summary>
public interface IDeduplicator
{
    /// <summary>
    /// Attempts to acquire a lock for a specific key for a given duration.
    /// </summary>
    /// <param name="key">The unique idempotency key.</param>
    /// <param name="ttl">Time To Live. How long the key should be remembered.</param>
    /// <returns>
    /// True if the lock was acquired (new key).
    /// False if the key is already locked/busy (duplicate).
    /// </returns>
    ValueTask<bool> TryAcquireAsync(string key, TimeSpan ttl);
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Abstractions\Storage\IChokaQQueue.cs
using ChokaQ.Abstractions.Jobs;

namespace ChokaQ.Abstractions.Storage;

/// <summary>
/// Defines the contract for the job queueing mechanism.
/// Responsible for accepting new jobs and dispatching them for processing.
/// </summary>
public interface IChokaQQueue
{
    /// <summary>
    /// Enqueues a job for asynchronous background processing.
    /// </summary>
    /// <typeparam name="TJob">The type of the job payload, must implement <see cref="IChokaQJob"/>.</typeparam>
    /// <param name="job">The job instance to process.</param>
    /// <param name="priority">Execution priority (higher values run first).</param>
    /// <param name="createdBy">The name of the user or service initiating the job.</param>
    /// <param name="tags">Comma-separated tags for filtering.</param>
    /// <param name="ct">Optional cancellation token.</param>
    /// <returns>A task representing the async enqueue operation.</returns>
    Task EnqueueAsync<TJob>(
        TJob job,
        int priority = 10,
        string queue = "default",
        string? createdBy = null,
        string? tags = null,
        CancellationToken ct = default) where TJob : IChokaQJob;
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Abstractions\Storage\IJobStorage.cs
using ChokaQ.Abstractions.DTOs;
using ChokaQ.Abstractions.Entities;
using ChokaQ.Abstractions.Enums;

namespace ChokaQ.Abstractions.Storage;

/// <summary>
/// Defines the contract for job persistence providers.
/// Implements the "Three Pillars" architecture: Hot, Archive, DLQ.
/// </summary>
public interface IJobStorage
{
    // ========================================================================
    // CORE OPERATIONS (Hot Table)
    // ========================================================================

    /// <summary>
    /// Creates a new job in the Hot table with Pending status.
    /// </summary>
    /// <returns>The job ID.</returns>
    ValueTask<string> EnqueueAsync(
        string id,
        string queue,
        string jobType,
        string payload,
        int priority = 10,
        string? createdBy = null,
        string? tags = null,
        TimeSpan? delay = null,
        string? idempotencyKey = null,
        CancellationToken ct = default);

    /// <summary>
    /// Atomically fetches and locks the next batch of pending jobs for a worker.
    /// Sets Status = Fetched and assigns WorkerId.
    /// </summary>
    ValueTask<IEnumerable<JobHotEntity>> FetchNextBatchAsync(
        string workerId,
        int batchSize,
        string[]? allowedQueues = null,
        CancellationToken ct = default);

    /// <summary>
    /// Transitions a job from Fetched to Processing status.
    /// Sets StartedAtUtc and HeartbeatUtc.
    /// </summary>
    ValueTask MarkAsProcessingAsync(string jobId, CancellationToken ct = default);

    /// <summary>
    /// Updates the heartbeat timestamp for an active job.
    /// Used for zombie detection.
    /// </summary>
    ValueTask KeepAliveAsync(string jobId, CancellationToken ct = default);

    /// <summary>
    /// Retrieves a job from the Hot table by ID.
    /// </summary>
    ValueTask<JobHotEntity?> GetJobAsync(string jobId, CancellationToken ct = default);

    // ========================================================================
    // ATOMIC TRANSITIONS (Three Pillars)
    // ========================================================================

    /// <summary>
    /// Atomically archives a succeeded job: Hot → Archive.
    /// Uses OUTPUT clause for data integrity.
    /// Increments StatsSummary.SucceededTotal.
    /// </summary>
    ValueTask ArchiveSucceededAsync(
        string jobId,
        double? durationMs = null,
        CancellationToken ct = default);

    /// <summary>
    /// Atomically moves a failed job to DLQ: Hot → DLQ.
    /// Uses OUTPUT clause for data integrity.
    /// Increments StatsSummary.FailedTotal.
    /// </summary>
    /// <param name="jobId">The job ID.</param>
    /// <param name="errorDetails">Exception details or failure reason.</param>
    ValueTask ArchiveFailedAsync(
        string jobId,
        string errorDetails,
        CancellationToken ct = default);

    /// <summary>
    /// Atomically moves a cancelled job to DLQ: Hot → DLQ.
    /// Uses OUTPUT clause for data integrity.
    /// </summary>
    ValueTask ArchiveCancelledAsync(
        string jobId,
        string? cancelledBy = null,
        CancellationToken ct = default);

    /// <summary>
    /// Atomically moves a zombie job to DLQ: Hot → DLQ.
    /// Called by ZombieRescueService.
    /// </summary>
    ValueTask ArchiveZombieAsync(
        string jobId,
        CancellationToken ct = default);

    /// <summary>
    /// Atomically resurrects a job from DLQ: DLQ → Hot.
    /// Resets AttemptCount to 0, Status to Pending.
    /// Optionally applies data updates (Payload, Tags, Priority).
    /// Decrements StatsSummary.FailedTotal.
    /// </summary>
    /// <param name="jobId">The job ID in DLQ.</param>
    /// <param name="updates">Optional data modifications.</param>
    /// <param name="resurrectedBy">Admin identity for audit.</param>
    ValueTask ResurrectAsync(
        string jobId,
        JobDataUpdateDto? updates = null,
        string? resurrectedBy = null,
        CancellationToken ct = default);

    /// <summary>
    /// Bulk resurrects multiple jobs from DLQ.
    /// Processes in batches of 1000 for transaction safety.
    /// </summary>
    /// <returns>Number of jobs successfully resurrected.</returns>
    ValueTask<int> ResurrectBatchAsync(
        string[] jobIds,
        string? resurrectedBy = null,
        CancellationToken ct = default);

    // ========================================================================
    // RETRY LOGIC (Stays in Hot)
    // ========================================================================

    /// <summary>
    /// Reschedules a failed job for retry within the Hot table.
    /// Increments AttemptCount, sets ScheduledAtUtc, Status = Pending.
    /// Increments StatsSummary.RetriedTotal.
    /// </summary>
    ValueTask RescheduleForRetryAsync(
        string jobId,
        DateTime scheduledAtUtc,
        int newAttemptCount,
        string lastError,
        CancellationToken ct = default);

    // ========================================================================
    // DIVINE MODE (Admin Operations)
    // ========================================================================

    /// <summary>
    /// Updates job data for a Pending job in Hot table.
    /// Safety Gate: Fails with false if Status != Pending.
    /// </summary>
    /// <returns>True if updated, false if job not found or not in Pending status.</returns>
    ValueTask<bool> UpdateJobDataAsync(
        string jobId,
        JobDataUpdateDto updates,
        string? modifiedBy = null,
        CancellationToken ct = default);

    /// <summary>
    /// Permanently deletes jobs from DLQ.
    /// Use with caution - data is unrecoverable.
    /// </summary>
    ValueTask PurgeDLQAsync(
        string[] jobIds,
        CancellationToken ct = default);

    /// <summary>
    /// Permanently deletes old jobs from Archive.
    /// </summary>
    /// <param name="olderThan">Delete jobs finished before this date.</param>
    /// <returns>Number of jobs deleted.</returns>
    ValueTask<int> PurgeArchiveAsync(
        DateTime olderThan,
        CancellationToken ct = default);

    // ========================================================================
    // OBSERVABILITY (Dashboard)
    // ========================================================================

    /// <summary>
    /// Gets hybrid statistics: StatsSummary (totals) + Hot counts.
    /// O(1) read from StatsSummary + fast COUNT on Hot.
    /// Returns aggregated stats (Queue = null for all queues).
    /// </summary>
    ValueTask<StatsSummaryEntity> GetSummaryStatsAsync(CancellationToken ct = default);

    /// <summary>
    /// Gets per-queue statistics: StatsSummary (totals) + Hot counts per queue.
    /// Returns stats for each queue separately (Queue field is not null).
    /// </summary>
    ValueTask<IEnumerable<StatsSummaryEntity>> GetQueueStatsAsync(CancellationToken ct = default);

    /// <summary>
    /// Retrieves active jobs from Hot table for dashboard.
    /// </summary>
    ValueTask<IEnumerable<JobHotEntity>> GetActiveJobsAsync(
        int limit = 100,
        JobStatus? statusFilter = null,
        string? queueFilter = null,
        string? searchTerm = null,
        CancellationToken ct = default);

    /// <summary>
    /// Retrieves succeeded jobs from Archive for history view.
    /// </summary>
    ValueTask<IEnumerable<JobArchiveEntity>> GetArchiveJobsAsync(
        int limit = 100,
        string? queueFilter = null,
        DateTime? fromDate = null,
        DateTime? toDate = null,
        string? tagFilter = null,
        CancellationToken ct = default);

    /// <summary>
    /// Retrieves failed jobs from DLQ for morgue view.
    /// </summary>
    /// <param name="limit">Maximum number of jobs to return.</param>
    /// <param name="queueFilter">Filter by queue name.</param>
    /// <param name="reasonFilter">Filter by failure reason (Cancelled, Zombie, etc.).</param>
    /// <param name="searchTerm">Search in Id, Type, Tags, ErrorDetails.</param>
    ValueTask<IEnumerable<JobDLQEntity>> GetDLQJobsAsync(
        int limit = 100,
        string? queueFilter = null,
        FailureReason? reasonFilter = null,
        string? searchTerm = null,
        CancellationToken ct = default);

    /// <summary>
    /// Gets a single job from Archive by ID.
    /// </summary>
    ValueTask<JobArchiveEntity?> GetArchiveJobAsync(string jobId, CancellationToken ct = default);

    /// <summary>
    /// Gets a single job from DLQ by ID.
    /// </summary>
    ValueTask<JobDLQEntity?> GetDLQJobAsync(string jobId, CancellationToken ct = default);

    // ========================================================================
    // QUEUE MANAGEMENT
    // ========================================================================

    /// <summary>
    /// Gets all queue configurations with live stats.
    /// </summary>
    ValueTask<IEnumerable<QueueEntity>> GetQueuesAsync(CancellationToken ct = default);

    /// <summary>
    /// Pauses or resumes a queue.
    /// </summary>
    ValueTask SetQueuePausedAsync(
        string queueName,
        bool isPaused,
        CancellationToken ct = default);

    /// <summary>
    /// Updates zombie timeout for a queue.
    /// </summary>
    ValueTask SetQueueZombieTimeoutAsync(
        string queueName,
        int? timeoutSeconds,
        CancellationToken ct = default);

    // ========================================================================
    // ZOMBIE DETECTION
    // ========================================================================

    /// <summary>
    /// Finds and archives zombie jobs (Processing with expired heartbeat).
    /// </summary>
    /// <param name="globalTimeoutSeconds">Default timeout if queue-specific not set.</param>
    /// <returns>Number of zombies archived to DLQ.</returns>
    ValueTask<int> ArchiveZombiesAsync(
        int globalTimeoutSeconds,
        CancellationToken ct = default);
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Abstractions\Workers\IWorkerManager.cs
namespace ChokaQ.Abstractions.Workers;

public interface IWorkerManager
{
    /// <summary>
    /// Gets the current number of active background workers.
    /// </summary>
    int ActiveWorkers { get; }

    /// <summary>
    /// Gets the total configured capacity of workers (Pool Size).
    /// </summary>
    int TotalWorkers { get; }

    /// <summary>
    /// Gets or sets the maximum number of retries allowed for a failed job.
    /// </summary>
    int MaxRetries { get; set; }

    /// <summary>
    /// Gets or sets the delay (in seconds) between retry attempts.
    /// </summary>
    int RetryDelaySeconds { get; set; }

    /// <summary>
    /// Dynamically scales the number of workers up or down.
    /// </summary>
    /// <param name="count">The target number of workers.</param>
    void UpdateWorkerCount(int count);

    /// <summary>
    /// Requests cancellation for a specific job.
    /// </summary>
    Task CancelJobAsync(string jobId);

    /// <summary>
    /// Restarts a job by resetting its state and pushing it back to the queue.
    /// </summary>
    Task RestartJobAsync(string jobId);

    // Bulk Action support
    Task SetJobPriorityAsync(string jobId, int priority);
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Core\ChokaQ.Core.csproj
<Project Sdk="Microsoft.NET.Sdk">

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.DependencyInjection" Version="10.0.1" />
    <PackageReference Include="Microsoft.Extensions.Hosting" Version="10.0.1" />
    <PackageReference Include="Microsoft.Extensions.Logging" Version="10.0.1" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\ChokaQ.Abstractions\ChokaQ.Abstractions.csproj" />
  </ItemGroup>

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
  </PropertyGroup>

</Project>

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Core\ChokaQOptions.cs
using ChokaQ.Abstractions.Jobs;
using ChokaQ.Core.Defaults;

namespace ChokaQ.Core;

/// <summary>
/// Configuration options for the ChokaQ library.
/// Allows selecting the processing strategy (Bus vs Pipe) and configuring storage defaults.
/// </summary>
public class ChokaQOptions
{
    // --- Strategy State (Internal use) ---

    internal bool IsPipeMode { get; private set; }
    internal Type? PipeHandlerType { get; private set; }
    internal List<Type> ProfileTypes { get; } = new();

    // --- Storage Configuration ---

    /// <summary>
    /// Holds configuration for the default In-Memory storage.
    /// Access via ConfigureInMemory() method.
    /// </summary>
    public InMemoryStorageOptions InMemoryOptions { get; } = new();

    // --- Public API ---

    /// <summary>
    /// Activates "Pipe Mode". 
    /// In this mode, all jobs are treated as raw data and routed to a single Global Handler.
    /// Ideal for high-throughput scenarios or simple event streams.
    /// </summary>
    /// <typeparam name="THandler">The global handler that will process all incoming messages.</typeparam>
    public void UsePipe<THandler>() where THandler : IChokaQPipeHandler
    {
        IsPipeMode = true;
        PipeHandlerType = typeof(THandler);
    }

    /// <summary>
    /// Adds a Job Profile (Bus Mode).
    /// Registers a set of Job Types and their specific Handlers.
    /// </summary>
    /// <typeparam name="TProfile">The profile class containing job registrations.</typeparam>
    public void AddProfile<TProfile>() where TProfile : ChokaQJobProfile
    {
        ProfileTypes.Add(typeof(TProfile));
    }

    /// <summary>
    /// Configures the default In-Memory storage behavior.
    /// Useful for Pipe Mode where no persistent database is used.
    /// </summary>
    /// <param name="configure">Action to configure options (e.g., MaxCapacity).</param>
    public void ConfigureInMemory(Action<InMemoryStorageOptions> configure)
    {
        configure(InMemoryOptions);
    }

    /// <summary>
    /// Default maximum retries for failed jobs. Default: 3.
    /// </summary>
    public int MaxRetries { get; set; } = 3;

    /// <summary>
    /// Base retry delay in seconds (Exponential Backoff starts here). Default: 3.
    /// </summary>
    public int RetryDelaySeconds { get; set; } = 3;
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Core\Concurrency\ElasticSemaphore.cs
namespace ChokaQ.Core.Concurrency;

/// <summary>
/// A wrapper around SemaphoreSlim that allows dynamic scaling (Elasticity).
/// Supports hot-swapping concurrency limits without recreating the object.
/// </summary>
/// <remarks>
/// Used by JobWorker to dynamically adjust worker count via dashboard
/// without restarting the application.
/// 
/// Scale UP: Simply releases additional permits into the pool.
/// Scale DOWN: "Burns" permits by acquiring and never releasing them.
/// </remarks>
public class ElasticSemaphore : IDisposable
{
    private readonly SemaphoreSlim _semaphore;
    private readonly object _lock = new();
    private CancellationTokenSource? _burnCts;

    // The logical maximum concurrency we want to enforce.
    private int _targetCapacity;

    /// <summary>
    /// Gets the current maximum capacity (concurrency limit).
    /// </summary>
    public int Capacity => _targetCapacity;

    /// <summary>
    /// Gets the approximate number of threads currently occupying a slot.
    /// Formula: TargetCapacity - AvailablePermits
    /// </summary>
    public int RunningCount => _targetCapacity - _semaphore.CurrentCount;

    public ElasticSemaphore(int initialCapacity)
    {
        if (initialCapacity <= 0) initialCapacity = 1;

        _targetCapacity = initialCapacity;

        // Initialize with int.MaxValue to allow "infinite" scaling UP.
        // But we only release 'initialCapacity' permits to start.
        _semaphore = new SemaphoreSlim(initialCapacity, int.MaxValue);
    }

    /// <summary>
    /// Asynchronously waits to enter the semaphore.
    /// </summary>
    public Task WaitAsync(CancellationToken cancellationToken = default)
    {
        return _semaphore.WaitAsync(cancellationToken);
    }

    /// <summary>
    /// Exits the semaphore.
    /// </summary>
    public void Release()
    {
        try
        {
            _semaphore.Release();
        }
        catch (SemaphoreFullException)
        {
            // Should not happen given int.MaxValue max capacity, 
            // but good to catch just in case logic drifts.
        }
    }

    /// <summary>
    /// Dynamically adjusts the semaphore capacity.
    /// Thread-safe and supports being called multiple times.
    /// </summary>
    /// <param name="newCapacity">The new target concurrency limit (minimum 1).</param>
    public void SetCapacity(int newCapacity)
    {
        if (newCapacity <= 0) newCapacity = 1;

        lock (_lock)
        {
            int diff = newCapacity - _targetCapacity;

            if (diff == 0) return;

            if (diff > 0)
            {
                // SCALE UP: Simply release more permits into the pool.
                _semaphore.Release(diff);
            }
            else
            {
                // SCALE DOWN: We need to remove permits. Since SemaphoreSlim 
                // doesn't have "Reduce", spawn a background task to consume ("burn") them.
                int permitsToBurn = Math.Abs(diff);

                // Cancel any previous burn operation
                _burnCts?.Cancel();
                _burnCts = new CancellationTokenSource();

                // Background burner task with cancellation support
                _ = BurnPermitsAsync(permitsToBurn, _burnCts.Token);
            }

            _targetCapacity = newCapacity;
        }
    }

    /// <summary>
    /// Consumes permits permanently to reduce capacity.
    /// Supports cancellation for graceful shutdown.
    /// </summary>
    private async Task BurnPermitsAsync(int count, CancellationToken ct)
    {
        for (int i = 0; i < count; i++)
        {
            try
            {
                // Acquire a permit...
                await _semaphore.WaitAsync(ct);

                // ...and NEVER release it. 
                // It is now lost to the void, effectively reducing capacity.
            }
            catch (OperationCanceledException)
            {
                // Shutdown requested - stop burning permits
                break;
            }
        }
    }

    public void Dispose()
    {
        // Cancel any pending burn operations to allow graceful shutdown
        _burnCts?.Cancel();
        _burnCts?.Dispose();

        _semaphore.Dispose();
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Core\Contexts\JobContext.cs
using ChokaQ.Abstractions.Contexts;
using ChokaQ.Abstractions.Notifications;

namespace ChokaQ.Core.Contexts;

internal class JobContext : IJobContext
{
    private readonly IChokaQNotifier _notifier;

    // Will be set by the Worker before the handler starts
    public string JobId { get; set; } = string.Empty;

    public JobContext(IChokaQNotifier notifier)
    {
        _notifier = notifier;
    }

    public async Task ReportProgressAsync(int percentage)
    {
        if (string.IsNullOrEmpty(JobId)) return;

        percentage = Math.Max(0, Math.Min(100, percentage));

        await _notifier.NotifyJobProgressAsync(JobId, percentage);
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Core\Defaults\InMemoryCircuitBreaker.cs
using ChokaQ.Abstractions.DTOs;
using ChokaQ.Abstractions.Enums;
using ChokaQ.Abstractions.Resilience;
using System.Collections.Concurrent;

namespace ChokaQ.Core.Defaults;

public class InMemoryCircuitBreaker : ICircuitBreaker
{
    private readonly TimeProvider _timeProvider;

    // Configuration constants
    private const int FailureThreshold = 5;
    private const int BreakDurationSeconds = 30; // Circuit stays open for 30s

    private readonly ConcurrentDictionary<string, CircuitStateEntry> _states = new();

    public InMemoryCircuitBreaker(TimeProvider timeProvider)
    {
        _timeProvider = timeProvider;
    }

    public bool IsExecutionPermitted(string jobType)
    {
        var entry = GetEntry(jobType);
        var now = _timeProvider.GetUtcNow();

        if (entry.Status == CircuitStatus.Closed) return true;

        if (entry.Status == CircuitStatus.Open)
        {
            // Check if timeout elapsed
            if (now >= entry.LastFailureUtc.AddSeconds(BreakDurationSeconds))
            {
                if (entry.TryTransitionToHalfOpen())
                {
                    return true;
                }
            }
            return false;
        }

        // Half-Open: Allow execution (could limit concurrency here in future)
        return true;
    }

    public void ReportSuccess(string jobType)
    {
        var entry = GetEntry(jobType);
        if (entry.Status != CircuitStatus.Closed)
        {
            entry.Reset();
        }
    }

    public void ReportFailure(string jobType)
    {
        var entry = GetEntry(jobType);
        var now = _timeProvider.GetUtcNow();

        entry.LastFailureUtc = now;
        entry.FailureCount++;

        if (entry.Status == CircuitStatus.HalfOpen)
        {
            entry.Status = CircuitStatus.Open;
        }
        else if (entry.FailureCount >= FailureThreshold)
        {
            entry.Status = CircuitStatus.Open;
        }
    }

    public CircuitStatus GetStatus(string jobType) => GetEntry(jobType).Status;

    /// <summary>
    /// Implementation of the new DTO-based stats method.
    /// </summary>
    public IEnumerable<CircuitStatsDto> GetCircuitStats()
    {
        return _states.Select(kvp =>
        {
            var jobType = kvp.Key;
            var entry = kvp.Value;

            DateTime? resetAt = null;

            // Calculate reset time if Open
            if (entry.Status == CircuitStatus.Open)
            {
                resetAt = entry.LastFailureUtc.AddSeconds(BreakDurationSeconds).UtcDateTime;
            }

            return new CircuitStatsDto(jobType, entry.Status, entry.FailureCount, resetAt);
        });
    }

    private CircuitStateEntry GetEntry(string jobType)
    {
        return _states.GetOrAdd(jobType, _ => new CircuitStateEntry());
    }

    private class CircuitStateEntry
    {
        public volatile CircuitStatus Status = CircuitStatus.Closed;
        public int FailureCount;
        public DateTimeOffset LastFailureUtc;

        public void Reset()
        {
            Status = CircuitStatus.Closed;
            FailureCount = 0;
        }

        public bool TryTransitionToHalfOpen()
        {
            if (Status == CircuitStatus.Open)
            {
                Status = CircuitStatus.HalfOpen;
                return true;
            }
            return false;
        }
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Core\Defaults\InMemoryDeduplicator.cs
using ChokaQ.Abstractions.Resilience;
using System.Collections.Concurrent;

namespace ChokaQ.Core.Defaults;

/// <summary>
/// A zero-dependency, in-memory implementation of the deduplicator.
/// Uses a ConcurrentDictionary to track active keys and a background timer to cleanup expired entries.
/// </summary>
public class InMemoryDeduplicator : IDeduplicator, IDisposable
{
    private readonly ConcurrentDictionary<string, DateTime> _locks = new();
    private readonly Timer _cleanupTimer;
    private readonly TimeSpan _cleanupInterval = TimeSpan.FromMinutes(1);
    private bool _disposed;

    public InMemoryDeduplicator()
    {
        // Run cleanup every minute
        _cleanupTimer = new Timer(CleanupCycle, null, _cleanupInterval, _cleanupInterval);
    }

    public ValueTask<bool> TryAcquireAsync(string key, TimeSpan ttl)
    {
        if (string.IsNullOrEmpty(key)) return new ValueTask<bool>(true);

        var now = DateTime.UtcNow;

        // Check if exists and valid
        if (_locks.TryGetValue(key, out var expiration))
        {
            if (expiration > now) return new ValueTask<bool>(false);
        }

        // Add or Update
        _locks[key] = now.Add(ttl);
        return new ValueTask<bool>(true);
    }

    private void CleanupCycle(object? state)
    {
        if (_disposed) return;
        var now = DateTime.UtcNow;

        foreach (var kvp in _locks)
        {
            if (kvp.Value < now) _locks.TryRemove(kvp.Key, out _);
        }
    }

    public void Dispose()
    {
        if (_disposed) return;
        _disposed = true;
        _cleanupTimer.Dispose();
        GC.SuppressFinalize(this);
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Core\Defaults\InMemoryJobStorage.cs
using ChokaQ.Abstractions.DTOs;
using ChokaQ.Abstractions.Entities;
using ChokaQ.Abstractions.Enums;
using ChokaQ.Abstractions.Storage;
using System.Collections.Concurrent;

namespace ChokaQ.Core.Defaults;

/// <summary>
/// Thread-safe in-memory implementation of the Three Pillars storage.
/// Suitable for "Pipe Mode" (Rocket Speed) or local development.
/// 
/// Storage structure:
/// - _hotJobs: Active jobs (Pending, Fetched, Processing)
/// - _archiveJobs: Succeeded jobs (History)
/// - _dlqJobs: Failed/Cancelled/Zombie jobs (Dead Letter Queue)
/// - _stats: Pre-aggregated counters per queue
/// - _queues: Queue configuration
/// </summary>
public class InMemoryJobStorage : IJobStorage
{
    private readonly int _maxCapacity;
    private readonly object _transitionLock = new();

    // Three Pillars
    private readonly ConcurrentDictionary<string, JobHotEntity> _hotJobs = new();
    private readonly ConcurrentDictionary<string, JobArchiveEntity> _archiveJobs = new();
    private readonly ConcurrentDictionary<string, JobDLQEntity> _dlqJobs = new();

    // Aggregates & Config
    private readonly ConcurrentDictionary<string, StatsSummaryData> _stats = new();
    private readonly ConcurrentDictionary<string, QueueData> _queues = new();

    public InMemoryJobStorage(InMemoryStorageOptions options)
    {
        _maxCapacity = options.MaxCapacity;

        // Initialize default queue
        _queues.TryAdd("default", new QueueData("default"));
        _stats.TryAdd("default", new StatsSummaryData("default"));
    }

    // ========================================================================
    // CORE OPERATIONS (Hot Table)
    // ========================================================================

    public ValueTask<string> EnqueueAsync(
        string id,
        string queue,
        string jobType,
        string payload,
        int priority = 10,
        string? createdBy = null,
        string? tags = null,
        TimeSpan? delay = null,
        string? idempotencyKey = null,
        CancellationToken ct = default)
    {
        // Idempotency check
        if (!string.IsNullOrEmpty(idempotencyKey))
        {
            var existing = _hotJobs.Values.FirstOrDefault(j => j.IdempotencyKey == idempotencyKey);
            if (existing != null)
                return new ValueTask<string>(existing.Id);
        }

        var now = DateTime.UtcNow;
        var job = new JobHotEntity(
            Id: id,
            Queue: queue,
            Type: jobType,
            Payload: payload,
            Tags: tags,
            IdempotencyKey: idempotencyKey,
            Priority: priority,
            Status: JobStatus.Pending,
            AttemptCount: 0,
            WorkerId: null,
            HeartbeatUtc: null,
            ScheduledAtUtc: delay.HasValue ? now.Add(delay.Value) : null,
            CreatedAtUtc: now,
            StartedAtUtc: null,
            LastUpdatedUtc: now,
            CreatedBy: createdBy,
            LastModifiedBy: null
        );

        EnforceCapacity();
        _hotJobs[id] = job;
        EnsureQueueExists(queue);

        return new ValueTask<string>(id);
    }

    public ValueTask<IEnumerable<JobHotEntity>> FetchNextBatchAsync(
        string workerId,
        int batchSize,
        string[]? allowedQueues = null,
        CancellationToken ct = default)
    {
        var now = DateTime.UtcNow;

        var candidates = _hotJobs.Values
            .Where(j => j.Status == JobStatus.Pending &&
                        (allowedQueues == null || allowedQueues.Contains(j.Queue)) &&
                        (!j.ScheduledAtUtc.HasValue || j.ScheduledAtUtc <= now) &&
                        !IsQueuePaused(j.Queue))
            .OrderByDescending(j => j.Priority)
            .ThenBy(j => j.ScheduledAtUtc ?? j.CreatedAtUtc)
            .Take(batchSize)
            .ToList();

        var lockedJobs = new List<JobHotEntity>();

        foreach (var job in candidates)
        {
            var fetched = job with
            {
                Status = JobStatus.Fetched,
                WorkerId = workerId,
                AttemptCount = job.AttemptCount + 1,
                LastUpdatedUtc = now
            };

            // Optimistic concurrency
            if (_hotJobs.TryUpdate(job.Id, fetched, job))
            {
                lockedJobs.Add(fetched);
            }
        }

        return new ValueTask<IEnumerable<JobHotEntity>>(lockedJobs);
    }

    public ValueTask MarkAsProcessingAsync(string jobId, CancellationToken ct = default)
    {
        if (_hotJobs.TryGetValue(jobId, out var job))
        {
            var now = DateTime.UtcNow;
            var processing = job with
            {
                Status = JobStatus.Processing,
                StartedAtUtc = now,
                HeartbeatUtc = now,
                LastUpdatedUtc = now
            };
            _hotJobs.TryUpdate(jobId, processing, job);
        }
        return ValueTask.CompletedTask;
    }

    public ValueTask KeepAliveAsync(string jobId, CancellationToken ct = default)
    {
        if (_hotJobs.TryGetValue(jobId, out var job))
        {
            var now = DateTime.UtcNow;
            var updated = job with { HeartbeatUtc = now, LastUpdatedUtc = now };
            _hotJobs.TryUpdate(jobId, updated, job);
        }
        return ValueTask.CompletedTask;
    }

    public ValueTask<JobHotEntity?> GetJobAsync(string jobId, CancellationToken ct = default)
    {
        _hotJobs.TryGetValue(jobId, out var job);
        return new ValueTask<JobHotEntity?>(job);
    }

    // ========================================================================
    // ATOMIC TRANSITIONS (Three Pillars)
    // ========================================================================

    public ValueTask ArchiveSucceededAsync(string jobId, double? durationMs = null, CancellationToken ct = default)
    {
        lock (_transitionLock)
        {
            if (!_hotJobs.TryRemove(jobId, out var job))
                return ValueTask.CompletedTask;

            var now = DateTime.UtcNow;
            var archived = new JobArchiveEntity(
                Id: job.Id,
                Queue: job.Queue,
                Type: job.Type,
                Payload: job.Payload,
                Tags: job.Tags,
                AttemptCount: job.AttemptCount,
                WorkerId: job.WorkerId,
                CreatedBy: job.CreatedBy,
                LastModifiedBy: job.LastModifiedBy,
                CreatedAtUtc: job.CreatedAtUtc,
                StartedAtUtc: job.StartedAtUtc,
                FinishedAtUtc: now,
                DurationMs: durationMs ?? (job.StartedAtUtc.HasValue
                    ? (now - job.StartedAtUtc.Value).TotalMilliseconds
                    : null)
            );

            _archiveJobs[job.Id] = archived;
            IncrementStats(job.Queue, succeeded: 1);
        }
        return ValueTask.CompletedTask;
    }

    public ValueTask ArchiveFailedAsync(string jobId, string errorDetails, CancellationToken ct = default)
    {
        return MoveToDLQ(jobId, FailureReason.MaxRetriesExceeded, errorDetails);
    }

    public ValueTask ArchiveCancelledAsync(string jobId, string? cancelledBy = null, CancellationToken ct = default)
    {
        var error = cancelledBy != null
            ? $"Cancelled by admin: {cancelledBy}"
            : "Cancelled by admin";
        return MoveToDLQ(jobId, FailureReason.Cancelled, error);
    }

    public ValueTask ArchiveZombieAsync(string jobId, CancellationToken ct = default)
    {
        return MoveToDLQ(jobId, FailureReason.Zombie, "Zombie: Worker heartbeat expired");
    }

    public ValueTask ResurrectAsync(
        string jobId,
        JobDataUpdateDto? updates = null,
        string? resurrectedBy = null,
        CancellationToken ct = default)
    {
        lock (_transitionLock)
        {
            if (!_dlqJobs.TryRemove(jobId, out var dlqJob))
                return ValueTask.CompletedTask;

            var now = DateTime.UtcNow;
            var resurrected = new JobHotEntity(
                Id: dlqJob.Id,
                Queue: dlqJob.Queue,
                Type: dlqJob.Type,
                Payload: updates?.Payload ?? dlqJob.Payload,
                Tags: updates?.Tags ?? dlqJob.Tags,
                IdempotencyKey: null, // Clear idempotency on resurrection
                Priority: updates?.Priority ?? 10,
                Status: JobStatus.Pending,
                AttemptCount: 0, // Reset attempts
                WorkerId: null,
                HeartbeatUtc: null,
                ScheduledAtUtc: null,
                CreatedAtUtc: dlqJob.CreatedAtUtc,
                StartedAtUtc: null,
                LastUpdatedUtc: now,
                CreatedBy: dlqJob.CreatedBy,
                LastModifiedBy: resurrectedBy
            );

            _hotJobs[dlqJob.Id] = resurrected;
            DecrementStats(dlqJob.Queue, failed: 1);
        }
        return ValueTask.CompletedTask;
    }

    public ValueTask<int> ResurrectBatchAsync(string[] jobIds, string? resurrectedBy = null, CancellationToken ct = default)
    {
        int count = 0;
        // Process in batches of 1000
        foreach (var batch in jobIds.Chunk(1000))
        {
            foreach (var id in batch)
            {
                lock (_transitionLock)
                {
                    if (_dlqJobs.TryRemove(id, out var dlqJob))
                    {
                        var now = DateTime.UtcNow;
                        var resurrected = new JobHotEntity(
                            Id: dlqJob.Id,
                            Queue: dlqJob.Queue,
                            Type: dlqJob.Type,
                            Payload: dlqJob.Payload,
                            Tags: dlqJob.Tags,
                            IdempotencyKey: null,
                            Priority: 10,
                            Status: JobStatus.Pending,
                            AttemptCount: 0,
                            WorkerId: null,
                            HeartbeatUtc: null,
                            ScheduledAtUtc: null,
                            CreatedAtUtc: dlqJob.CreatedAtUtc,
                            StartedAtUtc: null,
                            LastUpdatedUtc: now,
                            CreatedBy: dlqJob.CreatedBy,
                            LastModifiedBy: resurrectedBy
                        );

                        _hotJobs[dlqJob.Id] = resurrected;
                        DecrementStats(dlqJob.Queue, failed: 1);
                        count++;
                    }
                }
            }
        }
        return new ValueTask<int>(count);
    }

    // ========================================================================
    // RETRY LOGIC (Stays in Hot)
    // ========================================================================

    public ValueTask RescheduleForRetryAsync(
        string jobId,
        DateTime scheduledAtUtc,
        int newAttemptCount,
        string lastError,
        CancellationToken ct = default)
    {
        if (_hotJobs.TryGetValue(jobId, out var job))
        {
            var rescheduled = job with
            {
                Status = JobStatus.Pending,
                ScheduledAtUtc = scheduledAtUtc,
                AttemptCount = newAttemptCount,
                WorkerId = null,
                HeartbeatUtc = null,
                LastUpdatedUtc = DateTime.UtcNow
            };
            _hotJobs.TryUpdate(jobId, rescheduled, job);
            IncrementStats(job.Queue, retried: 1);
        }
        return ValueTask.CompletedTask;
    }

    // ========================================================================
    // DIVINE MODE (Admin Operations)
    // ========================================================================

    public ValueTask<bool> UpdateJobDataAsync(
        string jobId,
        JobDataUpdateDto updates,
        string? modifiedBy = null,
        CancellationToken ct = default)
    {
        if (!_hotJobs.TryGetValue(jobId, out var job))
            return new ValueTask<bool>(false);

        // Safety Gate: Only Pending jobs can be edited
        if (job.Status != JobStatus.Pending)
            return new ValueTask<bool>(false);

        var updated = job with
        {
            Payload = updates.Payload ?? job.Payload,
            Tags = updates.Tags ?? job.Tags,
            Priority = updates.Priority ?? job.Priority,
            LastModifiedBy = modifiedBy,
            LastUpdatedUtc = DateTime.UtcNow
        };

        return new ValueTask<bool>(_hotJobs.TryUpdate(jobId, updated, job));
    }

    public ValueTask PurgeDLQAsync(string[] jobIds, CancellationToken ct = default)
    {
        foreach (var id in jobIds)
        {
            _dlqJobs.TryRemove(id, out _);
        }
        return ValueTask.CompletedTask;
    }

    public ValueTask<int> PurgeArchiveAsync(DateTime olderThan, CancellationToken ct = default)
    {
        var toRemove = _archiveJobs.Values
            .Where(j => j.FinishedAtUtc < olderThan)
            .Select(j => j.Id)
            .ToList();

        foreach (var id in toRemove)
        {
            _archiveJobs.TryRemove(id, out _);
        }

        return new ValueTask<int>(toRemove.Count);
    }

    // ========================================================================
    // OBSERVABILITY (Dashboard)
    // ========================================================================

    public ValueTask<StatsSummaryEntity> GetSummaryStatsAsync(CancellationToken ct = default)
    {
        // Hybrid: Real-time counts from Hot + totals from Stats
        var hotValues = _hotJobs.Values;
        var statsValues = _stats.Values;

        var stats = new StatsSummaryEntity(
            Queue: null, // Aggregated across all queues
            Pending: hotValues.Count(x => x.Status == JobStatus.Pending),
            Fetched: hotValues.Count(x => x.Status == JobStatus.Fetched),
            Processing: hotValues.Count(x => x.Status == JobStatus.Processing),
            SucceededTotal: statsValues.Sum(x => x.SucceededTotal),
            FailedTotal: statsValues.Sum(x => x.FailedTotal),
            RetriedTotal: statsValues.Sum(x => x.RetriedTotal),
            Total: hotValues.Count + _archiveJobs.Count + _dlqJobs.Count,
            LastActivityUtc: statsValues.Max(x => x.LastActivityUtc)
        );

        return new ValueTask<StatsSummaryEntity>(stats);
    }

    public ValueTask<IEnumerable<StatsSummaryEntity>> GetQueueStatsAsync(CancellationToken ct = default)
    {
        // Per-queue stats
        var allQueues = _queues.Keys.ToList();
        var result = new List<StatsSummaryEntity>();

        foreach (var queueName in allQueues)
        {
            var hotForQueue = _hotJobs.Values.Where(x => x.Queue == queueName).ToList();
            var statForQueue = _stats.GetValueOrDefault(queueName);

            var queueStat = new StatsSummaryEntity(
                Queue: queueName,
                Pending: hotForQueue.Count(x => x.Status == JobStatus.Pending),
                Fetched: hotForQueue.Count(x => x.Status == JobStatus.Fetched),
                Processing: hotForQueue.Count(x => x.Status == JobStatus.Processing),
                SucceededTotal: statForQueue?.SucceededTotal ?? 0,
                FailedTotal: statForQueue?.FailedTotal ?? 0,
                RetriedTotal: statForQueue?.RetriedTotal ?? 0,
                Total: hotForQueue.Count +
                       _archiveJobs.Values.Count(x => x.Queue == queueName) +
                       _dlqJobs.Values.Count(x => x.Queue == queueName),
                LastActivityUtc: statForQueue?.LastActivityUtc
            );

            result.Add(queueStat);
        }

        return new ValueTask<IEnumerable<StatsSummaryEntity>>(result);
    }

    public ValueTask<IEnumerable<JobHotEntity>> GetActiveJobsAsync(
        int limit = 100,
        JobStatus? statusFilter = null,
        string? queueFilter = null,
        string? searchTerm = null,
        CancellationToken ct = default)
    {
        var query = _hotJobs.Values.AsEnumerable();

        if (statusFilter.HasValue)
            query = query.Where(j => j.Status == statusFilter.Value);

        if (!string.IsNullOrEmpty(queueFilter))
            query = query.Where(j => j.Queue == queueFilter);

        if (!string.IsNullOrEmpty(searchTerm))
            query = query.Where(j =>
                j.Id.Contains(searchTerm, StringComparison.OrdinalIgnoreCase) ||
                j.Type.Contains(searchTerm, StringComparison.OrdinalIgnoreCase) ||
                (j.Tags?.Contains(searchTerm, StringComparison.OrdinalIgnoreCase) ?? false));

        var result = query
            .OrderByDescending(j => j.CreatedAtUtc)
            .Take(limit)
            .ToList();

        return new ValueTask<IEnumerable<JobHotEntity>>(result);
    }

    public ValueTask<IEnumerable<JobArchiveEntity>> GetArchiveJobsAsync(
        int limit = 100,
        string? queueFilter = null,
        DateTime? fromDate = null,
        DateTime? toDate = null,
        string? tagFilter = null,
        CancellationToken ct = default)
    {
        var query = _archiveJobs.Values.AsEnumerable();

        if (!string.IsNullOrEmpty(queueFilter))
            query = query.Where(j => j.Queue == queueFilter);

        if (fromDate.HasValue)
            query = query.Where(j => j.FinishedAtUtc >= fromDate.Value);

        if (toDate.HasValue)
            query = query.Where(j => j.FinishedAtUtc <= toDate.Value);

        if (!string.IsNullOrEmpty(tagFilter))
            query = query.Where(j => j.Tags?.Contains(tagFilter, StringComparison.OrdinalIgnoreCase) ?? false);

        var result = query
            .OrderByDescending(j => j.FinishedAtUtc)
            .Take(limit)
            .ToList();

        return new ValueTask<IEnumerable<JobArchiveEntity>>(result);
    }

    public ValueTask<IEnumerable<JobDLQEntity>> GetDLQJobsAsync(
        int limit = 100,
        string? queueFilter = null,
        FailureReason? reasonFilter = null,
        string? searchTerm = null,
        CancellationToken ct = default)
    {
        var query = _dlqJobs.Values.AsEnumerable();

        if (!string.IsNullOrEmpty(queueFilter))
            query = query.Where(j => j.Queue == queueFilter);

        if (reasonFilter.HasValue)
            query = query.Where(j => j.FailureReason == reasonFilter.Value);

        if (!string.IsNullOrEmpty(searchTerm))
            query = query.Where(j =>
                j.Id.Contains(searchTerm, StringComparison.OrdinalIgnoreCase) ||
                j.Type.Contains(searchTerm, StringComparison.OrdinalIgnoreCase) ||
                (j.Tags?.Contains(searchTerm, StringComparison.OrdinalIgnoreCase) ?? false) ||
                (j.ErrorDetails?.Contains(searchTerm, StringComparison.OrdinalIgnoreCase) ?? false));

        var result = query
            .OrderByDescending(j => j.FailedAtUtc)
            .Take(limit)
            .ToList();

        return new ValueTask<IEnumerable<JobDLQEntity>>(result);
    }

    public ValueTask<JobArchiveEntity?> GetArchiveJobAsync(string jobId, CancellationToken ct = default)
    {
        _archiveJobs.TryGetValue(jobId, out var job);
        return new ValueTask<JobArchiveEntity?>(job);
    }

    public ValueTask<JobDLQEntity?> GetDLQJobAsync(string jobId, CancellationToken ct = default)
    {
        _dlqJobs.TryGetValue(jobId, out var job);
        return new ValueTask<JobDLQEntity?>(job);
    }

    // ========================================================================
    // QUEUE MANAGEMENT
    // ========================================================================

    public ValueTask<IEnumerable<QueueEntity>> GetQueuesAsync(CancellationToken ct = default)
    {
        // Collect all unique queues from all three pillars
        var allQueues = _hotJobs.Values.Select(j => j.Queue)
            .Concat(_archiveJobs.Values.Select(j => j.Queue))
            .Concat(_dlqJobs.Values.Select(j => j.Queue))
            .Concat(_queues.Keys)
            .Distinct();

        var result = allQueues.Select(queueName =>
        {
            var queueData = _queues.GetOrAdd(queueName, new QueueData(queueName));
            return new QueueEntity(
                Name: queueName,
                IsPaused: queueData.IsPaused,
                IsActive: queueData.IsActive,
                ZombieTimeoutSeconds: queueData.ZombieTimeoutSeconds,
                LastUpdatedUtc: queueData.LastUpdatedUtc
            );
        }).ToList();

        return new ValueTask<IEnumerable<QueueEntity>>(result);
    }

    public ValueTask SetQueuePausedAsync(string queueName, bool isPaused, CancellationToken ct = default)
    {
        _queues.AddOrUpdate(queueName,
            new QueueData(queueName) { IsPaused = isPaused },
            (_, old) => { old.IsPaused = isPaused; old.LastUpdatedUtc = DateTime.UtcNow; return old; });
        return ValueTask.CompletedTask;
    }

    public ValueTask SetQueueZombieTimeoutAsync(string queueName, int? timeoutSeconds, CancellationToken ct = default)
    {
        _queues.AddOrUpdate(queueName,
            new QueueData(queueName) { ZombieTimeoutSeconds = timeoutSeconds },
            (_, old) => { old.ZombieTimeoutSeconds = timeoutSeconds; old.LastUpdatedUtc = DateTime.UtcNow; return old; });
        return ValueTask.CompletedTask;
    }

    // ========================================================================
    // ZOMBIE DETECTION
    // ========================================================================

    public ValueTask<int> ArchiveZombiesAsync(int globalTimeoutSeconds, CancellationToken ct = default)
    {
        var now = DateTime.UtcNow;
        int count = 0;

        var processingJobs = _hotJobs.Values
            .Where(j => j.Status == JobStatus.Processing)
            .ToList();

        foreach (var job in processingJobs)
        {
            // Determine effective timeout
            int timeout = globalTimeoutSeconds;
            if (_queues.TryGetValue(job.Queue, out var q) && q.ZombieTimeoutSeconds.HasValue)
                timeout = q.ZombieTimeoutSeconds.Value;

            // Check heartbeat expiration
            var heartbeat = job.HeartbeatUtc ?? job.StartedAtUtc ?? job.LastUpdatedUtc;
            if (heartbeat < now.AddSeconds(-timeout))
            {
                // Move to DLQ
                lock (_transitionLock)
                {
                    if (_hotJobs.TryRemove(job.Id, out var removed))
                    {
                        var dlqJob = new JobDLQEntity(
                            Id: removed.Id,
                            Queue: removed.Queue,
                            Type: removed.Type,
                            Payload: removed.Payload,
                            Tags: removed.Tags,
                            FailureReason: FailureReason.Zombie,
                            ErrorDetails: $"Zombie: Heartbeat expired after {timeout}s",
                            AttemptCount: removed.AttemptCount,
                            WorkerId: removed.WorkerId,
                            CreatedBy: removed.CreatedBy,
                            LastModifiedBy: removed.LastModifiedBy,
                            CreatedAtUtc: removed.CreatedAtUtc,
                            FailedAtUtc: now
                        );

                        _dlqJobs[removed.Id] = dlqJob;
                        IncrementStats(removed.Queue, failed: 1);
                        count++;
                    }
                }
            }
        }

        return new ValueTask<int>(count);
    }

    // ========================================================================
    // PRIVATE HELPERS
    // ========================================================================

    private ValueTask MoveToDLQ(string jobId, FailureReason reason, string errorDetails)
    {
        lock (_transitionLock)
        {
            if (!_hotJobs.TryRemove(jobId, out var job))
                return ValueTask.CompletedTask;

            var now = DateTime.UtcNow;
            var dlqJob = new JobDLQEntity(
                Id: job.Id,
                Queue: job.Queue,
                Type: job.Type,
                Payload: job.Payload,
                Tags: job.Tags,
                FailureReason: reason,
                ErrorDetails: errorDetails,
                AttemptCount: job.AttemptCount,
                WorkerId: job.WorkerId,
                CreatedBy: job.CreatedBy,
                LastModifiedBy: job.LastModifiedBy,
                CreatedAtUtc: job.CreatedAtUtc,
                FailedAtUtc: now
            );

            _dlqJobs[job.Id] = dlqJob;
            IncrementStats(job.Queue, failed: 1);
        }
        return ValueTask.CompletedTask;
    }

    private void EnsureQueueExists(string queue)
    {
        _queues.TryAdd(queue, new QueueData(queue));
        _stats.TryAdd(queue, new StatsSummaryData(queue));
    }

    private bool IsQueuePaused(string queue)
    {
        return _queues.TryGetValue(queue, out var q) && q.IsPaused;
    }

    private void IncrementStats(string queue, long succeeded = 0, long failed = 0, long retried = 0)
    {
        _stats.AddOrUpdate(queue,
            new StatsSummaryData(queue)
            {
                SucceededTotal = succeeded,
                FailedTotal = failed,
                RetriedTotal = retried
            },
            (_, old) =>
            {
                old.SucceededTotal += succeeded;
                old.FailedTotal += failed;
                old.RetriedTotal += retried;
                old.LastActivityUtc = DateTime.UtcNow;
                return old;
            });
    }

    private void DecrementStats(string queue, long failed = 0)
    {
        if (_stats.TryGetValue(queue, out var stats))
        {
            stats.FailedTotal = Math.Max(0, stats.FailedTotal - failed);
            stats.LastActivityUtc = DateTime.UtcNow;
        }
    }

    private void EnforceCapacity()
    {
        var totalCount = _hotJobs.Count + _archiveJobs.Count + _dlqJobs.Count;

        if (totalCount < _maxCapacity)
            return;

        // First: Remove old archived jobs
        var archiveToRemove = _archiveJobs.Values
            .OrderBy(j => j.FinishedAtUtc)
            .Take(1000)
            .Select(j => j.Id)
            .ToList();

        foreach (var id in archiveToRemove)
            _archiveJobs.TryRemove(id, out _);

        // If still over capacity: Remove old DLQ jobs
        if (_hotJobs.Count + _archiveJobs.Count + _dlqJobs.Count >= _maxCapacity)
        {
            var dlqToRemove = _dlqJobs.Values
                .OrderBy(j => j.FailedAtUtc)
                .Take(500)
                .Select(j => j.Id)
                .ToList();

            foreach (var id in dlqToRemove)
                _dlqJobs.TryRemove(id, out _);
        }
    }

    // ========================================================================
    // INTERNAL DATA CLASSES
    // ========================================================================

    private class QueueData
    {
        public string Name { get; }
        public bool IsPaused { get; set; }
        public bool IsActive { get; set; } = true;
        public int? ZombieTimeoutSeconds { get; set; }
        public DateTime LastUpdatedUtc { get; set; } = DateTime.UtcNow;

        public QueueData(string name) => Name = name;
    }

    private class StatsSummaryData
    {
        public string Queue { get; }
        public long SucceededTotal { get; set; }
        public long FailedTotal { get; set; }
        public long RetriedTotal { get; set; }
        public DateTime? LastActivityUtc { get; set; }

        public StatsSummaryData(string queue) => Queue = queue;
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Core\Defaults\InMemoryQueue.cs
using ChokaQ.Abstractions.DTOs;
using ChokaQ.Abstractions.Enums;
using ChokaQ.Abstractions.Jobs;
using ChokaQ.Abstractions.Notifications;
using ChokaQ.Abstractions.Storage;
using ChokaQ.Core.Execution;
using Microsoft.Extensions.Logging;
using System.Text.Json;
using System.Threading.Channels;

namespace ChokaQ.Core.Defaults;

/// <summary>
/// High-performance, in-memory implementation of the job queue using System.Threading.Channels.
/// Acts as a Producer-Consumer buffer between the API and the Worker.
/// </summary>
public class InMemoryQueue : IChokaQQueue
{
    private readonly Channel<IChokaQJob> _queue;
    private readonly IJobStorage _storage;
    private readonly IChokaQNotifier _notifier;
    private readonly JobTypeRegistry _registry;
    private readonly ILogger<InMemoryQueue> _logger;

    public InMemoryQueue(
        IJobStorage storage,
        IChokaQNotifier notifier,
        JobTypeRegistry registry,
        ILogger<InMemoryQueue> logger)
    {
        _storage = storage ?? throw new ArgumentNullException(nameof(storage));
        _notifier = notifier ?? throw new ArgumentNullException(nameof(notifier));
        _registry = registry ?? throw new ArgumentNullException(nameof(registry));
        _logger = logger;

        var options = new UnboundedChannelOptions
        {
            SingleReader = false,
            SingleWriter = false
        };
        _queue = Channel.CreateUnbounded<IChokaQJob>(options);
    }

    public ChannelReader<IChokaQJob> Reader => _queue.Reader;

    public async Task EnqueueAsync<TJob>(
        TJob job,
        int priority = 10,
        string queue = "default",
        string? createdBy = null,
        string? tags = null,
        CancellationToken ct = default) where TJob : IChokaQJob
    {
        // 1. Serialize payload for persistence
        var payload = JsonSerializer.Serialize(job, job.GetType());

        // Resolve Key from Registry first. 
        // If the user mapped this DTO in a Profile, use that Key.
        // Otherwise, fall back to the Type Name.
        var jobTypeName = _registry.GetKeyByType(job.GetType()) ?? job.GetType().Name;

        // 2. Persist to Storage (Hot table, Status: Pending)
        await _storage.EnqueueAsync(
             id: job.Id,
             queue: queue,
             jobType: jobTypeName,
             payload: payload,
             priority: priority,
             createdBy: createdBy,
             tags: tags,
             ct: ct
        );

        // 3. Real-time Notification
        try
        {
            var update = new JobUpdateDto(
                JobId: job.Id,
                Type: jobTypeName,
                Queue: queue,
                Status: JobStatus.Pending,
                AttemptCount: 0,
                Priority: priority,
                DurationMs: null,
                CreatedBy: createdBy,
                StartedAtUtc: null
            );
            await _notifier.NotifyJobUpdatedAsync(update);
        }
        catch (Exception ex)
        {
            _logger.LogWarning("Failed to notify UI about new job: {Message}", ex.Message);
        }

        // 4. Push to Channel
        await _queue.Writer.WriteAsync(job, ct);
    }

    public async ValueTask RequeueAsync(IChokaQJob job, CancellationToken ct = default)
    {
        await _queue.Writer.WriteAsync(job, ct);
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Core\Defaults\InMemoryStorageOptions.cs
namespace ChokaQ.Core.Defaults;

public class InMemoryStorageOptions
{
    /// <summary>
    /// The maximum number of jobs to keep in memory.
    /// When this limit is reached, the storage will attempt to remove finished jobs first, 
    /// then the oldest jobs, to prevent OutOfMemory exceptions.
    /// Default: 100,000.
    /// </summary>
    public int MaxCapacity { get; set; } = 100_000;
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Core\Defaults\NullNotifier.cs
using ChokaQ.Abstractions.DTOs;
using ChokaQ.Abstractions.Notifications;

namespace ChokaQ.Core.Defaults;

/// <summary>
/// No-op implementation of IChokaQNotifier.
/// Used when SignalR dashboard is not enabled.
/// </summary>
internal class NullNotifier : IChokaQNotifier
{
    public Task NotifyJobUpdatedAsync(JobUpdateDto update) => Task.CompletedTask;

    public Task NotifyJobProgressAsync(string jobId, int percentage) => Task.CompletedTask;

    public Task NotifyJobArchivedAsync(string jobId, string queue) => Task.CompletedTask;

    public Task NotifyJobFailedAsync(string jobId, string queue, string reason) => Task.CompletedTask;

    public Task NotifyJobResurrectedAsync(string jobId, string queue) => Task.CompletedTask;

    public Task NotifyJobsPurgedAsync(string[] jobIds, string source) => Task.CompletedTask;

    public Task NotifyQueueStateChangedAsync(string queueName, bool isPaused) => Task.CompletedTask;

    public Task NotifyStatsUpdatedAsync() => Task.CompletedTask;
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Core\Execution\BusJobDispatcher.cs
using ChokaQ.Abstractions.Jobs;
using ChokaQ.Core.Contexts;
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;
using System.Reflection;
using System.Text.Json;
using System.Text.Json.Nodes;

namespace ChokaQ.Core.Execution;

public class BusJobDispatcher : IJobDispatcher
{
    private readonly IServiceScopeFactory _scopeFactory;
    private readonly JobTypeRegistry _registry;
    private readonly ILogger<BusJobDispatcher> _logger;

    public BusJobDispatcher(
        IServiceScopeFactory scopeFactory,
        JobTypeRegistry registry,
        ILogger<BusJobDispatcher> logger)
    {
        _scopeFactory = scopeFactory;
        _registry = registry;
        _logger = logger;
    }

    public async Task DispatchAsync(string jobId, string jobType, string payload, CancellationToken ct)
    {
        using var scope = _scopeFactory.CreateScope();
        var serviceProvider = scope.ServiceProvider;

        // 1. Setup Context
        var jobContext = serviceProvider.GetRequiredService<JobContext>();
        jobContext.JobId = jobId;

        // 2. Resolve Type from Registry (Fast & Safe)
        var clrType = _registry.GetTypeByKey(jobType);

        // Fallback: Try standard Type.GetType if not in registry (legacy support)
        if (clrType == null)
        {
            clrType = Type.GetType(jobType);
        }

        if (clrType == null)
        {
            throw new InvalidOperationException($"Bus Mode: Unknown Job Type '{jobType}'. Ensure the job class is defined in a scanned assembly.");
        }

        // 3. Deserialize
        var jobObject = JsonSerializer.Deserialize(payload, clrType) as IChokaQJob;
        if (jobObject == null)
        {
            throw new InvalidOperationException($"Bus Mode: Failed to deserialize payload for '{clrType.Name}'.");
        }

        // 4. Resolve Handler
        var handlerType = typeof(IChokaQJobHandler<>).MakeGenericType(clrType);
        var handler = serviceProvider.GetService(handlerType);

        if (handler == null)
        {
            throw new InvalidOperationException($"Bus Mode: No IChokaQJobHandler<{clrType.Name}> found in DI. Did you forget to register it?");
        }

        // 5. Invoke
        var method = handlerType.GetMethod("HandleAsync");
        if (method == null)
        {
            throw new InvalidOperationException($"Method 'HandleAsync' not found on {handlerType.Name}");
        }

        try
        {
            var task = (Task)method.Invoke(handler, new object[] { jobObject, ct })!;
            await task;
        }
        catch (TargetInvocationException ex)
        {
            if (ex.InnerException != null) throw ex.InnerException;
            throw;
        }
    }

    public JobMetadata ParseMetadata(string payload)
    {
        if (string.IsNullOrWhiteSpace(payload))
            return new JobMetadata("default", 10);

        try
        {
            var node = JsonNode.Parse(payload);
            var metaNode = node?["Metadata"];
            var queue = metaNode?["Queue"]?.ToString() ?? "default";
            var priority = metaNode?["Priority"]?.GetValue<int>() ?? 10;

            return new JobMetadata(queue, priority);
        }
        catch
        {
            return new JobMetadata("default", 10);
        }
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Core\Execution\IJobDispatcher.cs
namespace ChokaQ.Core.Execution;

public record JobMetadata(string Queue, int Priority);

/// <summary>
/// Responsible for dispatching the job execution to the appropriate handler.
/// This abstraction supports different processing strategies (Bus vs. Pipe).
/// </summary>
public interface IJobDispatcher
{
    /// <summary>
    /// Dispatches the job execution.
    /// </summary>
    /// <param name="jobId">The unique ID of the job.</param>
    /// <param name="jobType">The type key or class name.</param>
    /// <param name="payload">The raw JSON payload.</param>
    /// <param name="ct">Cancellation token.</param>
    Task DispatchAsync(string jobId, string jobType, string payload, CancellationToken ct);

    JobMetadata ParseMetadata(string payload);
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Core\Execution\JobTypeRegistry.cs
using System.Collections.Concurrent;

namespace ChokaQ.Core.Execution;

/// <summary>
/// Maintains a bidirectional mapping between string Keys (stored in DB) and C# Types.
/// Populated at startup via Profiles.
/// </summary>
public class JobTypeRegistry
{
    // Key: "email_v1" -> Value: typeof(EmailJobDto)
    private readonly ConcurrentDictionary<string, Type> _keyToTypeMap = new(StringComparer.OrdinalIgnoreCase);

    // Key: typeof(EmailJobDto) -> Value: "email_v1"
    private readonly ConcurrentDictionary<Type, string> _typeToKeyMap = new();

    /// <summary>
    /// Registers a job type with a specific key.
    /// </summary>
    public void Register(string key, Type jobType)
    {
        if (!_keyToTypeMap.TryAdd(key, jobType))
        {
            throw new InvalidOperationException($"Duplicate Job Key detected: '{key}'. Keys must be unique across all profiles.");
        }

        // We also allow reverse lookup. 
        // If one DTO is mapped to multiple keys (rare), the first one wins for reverse lookup.
        _typeToKeyMap.TryAdd(jobType, key);
    }

    /// <summary>
    /// Resolves the C# Type for a given job key (used by Worker/Dispatcher).
    /// </summary>
    public Type? GetTypeByKey(string key)
    {
        if (_keyToTypeMap.TryGetValue(key, out var type))
        {
            return type;
        }
        return null;
    }

    /// <summary>
    /// Resolves the Job Key for a given C# Type (used by Queue/Enqueuer).
    /// </summary>
    public string? GetKeyByType(Type type)
    {
        if (_typeToKeyMap.TryGetValue(type, out var key))
        {
            return key;
        }
        return null;
    }

    public IEnumerable<string> GetAllKeys() => _keyToTypeMap.Keys;
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Core\Execution\PipeJobDispatcher.cs
using ChokaQ.Abstractions.Jobs;
using ChokaQ.Core.Contexts;
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;
using System.Text.Json.Nodes;

namespace ChokaQ.Core.Execution;

/// <summary>
/// Implementation of IJobDispatcher for the "Pipe" strategy.
/// Delegates all jobs to a single registered IChokaQPipeHandler.
/// </summary>
public class PipeJobDispatcher : IJobDispatcher
{
    private readonly IServiceScopeFactory _scopeFactory;
    private readonly ILogger<PipeJobDispatcher> _logger;

    public PipeJobDispatcher(IServiceScopeFactory scopeFactory, ILogger<PipeJobDispatcher> logger)
    {
        _scopeFactory = scopeFactory;
        _logger = logger;
    }

    public async Task DispatchAsync(string jobId, string jobType, string payload, CancellationToken ct)
    {
        using var scope = _scopeFactory.CreateScope();
        var serviceProvider = scope.ServiceProvider;

        // 1. Setup Context
        var jobContext = serviceProvider.GetRequiredService<JobContext>();
        jobContext.JobId = jobId;

        // 2. Resolve the single global handler
        var handler = serviceProvider.GetService<IChokaQPipeHandler>();

        if (handler == null)
        {
            throw new InvalidOperationException("Pipe mode is enabled, but no implementation of IChokaQPipeHandler was found in the DI container.");
        }

        // 3. Execute
        // We pass the raw type string and payload directly to the user code.
        await handler.HandleAsync(jobType, payload, ct);
    }

    public JobMetadata ParseMetadata(string payload)
    {
        if (string.IsNullOrWhiteSpace(payload))
            return new JobMetadata("default", 10);

        try
        {
            var node = JsonNode.Parse(payload);
            var metaNode = node?["Metadata"];

            var queue = metaNode?["Queue"]?.ToString() ?? "default";
            var priority = metaNode?["Priority"]?.GetValue<int>() ?? 10;

            return new JobMetadata(queue, priority);
        }
        catch
        {
            return new JobMetadata("default", 10);
        }
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Core\Extensions\ChokaQCoreExtensions.cs
using ChokaQ.Abstractions.Contexts;
using ChokaQ.Abstractions.Jobs;
using ChokaQ.Abstractions.Notifications;
using ChokaQ.Abstractions.Resilience;
using ChokaQ.Abstractions.Storage;
using ChokaQ.Abstractions.Workers;
using ChokaQ.Core.Contexts;
using ChokaQ.Core.Defaults;
using ChokaQ.Core.Execution;
using ChokaQ.Core.Processing;
using ChokaQ.Core.Resilience;
using ChokaQ.Core.State;
using ChokaQ.Core.Workers;
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.DependencyInjection.Extensions;
using Microsoft.Extensions.Logging;

namespace ChokaQ.Core.Extensions;

/// <summary>
/// Extension methods for registering ChokaQ services in the DI container.
/// </summary>
public static class ChokaQCoreExtensions
{
    /// <summary>
    /// Registers ChokaQ background job processing services.
    /// </summary>
    /// <param name="services">The service collection.</param>
    /// <param name="configure">Optional configuration callback for ChokaQOptions.</param>
    /// <returns>The service collection for chaining.</returns>
    /// <remarks>
    /// Basic usage (Bus Mode with profiles):
    /// <code>
    /// services.AddChokaQ(options =>
    /// {
    ///     options.AddProfile&lt;MailingProfile&gt;();
    ///     options.AddProfile&lt;ReportingProfile&gt;();
    /// });
    /// </code>
    /// 
    /// Pipe Mode (high-throughput):
    /// <code>
    /// services.AddChokaQ(options =>
    /// {
    ///     options.UsePipe&lt;GlobalPipeHandler&gt;();
    ///     options.ConfigureInMemory(o => o.MaxCapacity = 100_000);
    /// });
    /// </code>
    /// 
    /// For SQL Server persistence, chain with AddChokaQSqlServer():
    /// <code>
    /// services.AddChokaQ(options => options.AddProfile&lt;MyProfile&gt;())
    ///         .AddChokaQSqlServer(connectionString);
    /// </code>
    /// </remarks>
    public static IServiceCollection AddChokaQ(this IServiceCollection services, Action<ChokaQOptions>? configure = null)
    {
        var options = new ChokaQOptions();
        configure?.Invoke(options);

        // Register core infrastructure (storage, queues, processors)
        AddInfrastructure(services, options);

        // Register strategy-specific services (Bus vs Pipe)
        if (options.IsPipeMode)
        {
            AddPipeStrategy(services, options);
        }
        else
        {
            AddBusStrategy(services, options);
        }

        return services;
    }

    /// <summary>
    /// Registers core infrastructure services shared by both Bus and Pipe modes.
    /// Uses TryAdd to allow external packages (e.g., SqlServer) to override defaults.
    /// </summary>
    private static void AddInfrastructure(IServiceCollection services, ChokaQOptions options)
    {
        services.TryAddSingleton(TimeProvider.System);
        services.TryAddSingleton<IDeduplicator, InMemoryDeduplicator>();
        services.TryAddSingleton<ICircuitBreaker, InMemoryCircuitBreaker>();

        // Register InMemoryJobStorage with the configured options (Three Pillars)
        services.TryAddSingleton<IJobStorage>(sp => new InMemoryJobStorage(options.InMemoryOptions));
        services.TryAddSingleton<IChokaQNotifier, NullNotifier>();
        services.TryAddSingleton<InMemoryQueue>();
        services.TryAddSingleton<IChokaQQueue>(sp => sp.GetRequiredService<InMemoryQueue>());

        services.TryAddScoped<JobContext>();
        services.TryAddScoped<IJobContext>(sp => sp.GetRequiredService<JobContext>());
        services.TryAddSingleton<IJobStateManager, JobStateManager>();
        services.TryAddSingleton<IJobProcessor>(sp => new JobProcessor(
            sp.GetRequiredService<IJobStorage>(),
            sp.GetRequiredService<ILogger<JobProcessor>>(),
            sp.GetRequiredService<ICircuitBreaker>(),
            sp.GetRequiredService<IJobDispatcher>(),
            sp.GetRequiredService<IJobStateManager>(),
            options
        ));
        services.TryAddSingleton<JobWorker>();
        services.TryAddSingleton<IWorkerManager>(sp => sp.GetRequiredService<JobWorker>());

        services.AddHostedService(sp => sp.GetRequiredService<JobWorker>());

        // Register the Zombie Rescue Service
        services.AddHostedService<ZombieRescueService>();
    }

    private static void AddPipeStrategy(IServiceCollection services, ChokaQOptions options)
    {
        services.TryAddSingleton<IJobDispatcher, PipeJobDispatcher>();

        if (options.PipeHandlerType != null)
        {
            services.TryAddTransient(typeof(IChokaQPipeHandler), options.PipeHandlerType);
        }
        services.TryAddSingleton(new JobTypeRegistry());
    }

    private static void AddBusStrategy(IServiceCollection services, ChokaQOptions options)
    {
        services.TryAddSingleton<IJobDispatcher, BusJobDispatcher>();
        var registry = new JobTypeRegistry();
        foreach (var profileType in options.ProfileTypes)
        {
            if (Activator.CreateInstance(profileType) is ChokaQJobProfile profileInstance)
            {
                foreach (var reg in profileInstance.Registrations)
                {
                    registry.Register(reg.Key, reg.JobType);
                    var interfaceType = typeof(IChokaQJobHandler<>).MakeGenericType(reg.JobType);
                    services.TryAddTransient(interfaceType, reg.HandlerType);
                }
            }
        }
        services.AddSingleton(registry);
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Core\Processing\IJobProcessor.cs
namespace ChokaQ.Core.Processing;

/// <summary>
/// Encapsulates the complete lifecycle of processing a single job.
/// Handles Circuit Breaker checks, execution, success/failure reporting, and retries.
/// </summary>
public interface IJobProcessor
{
    /// <summary>
    /// Configuration: Maximum number of retries.
    /// </summary>
    int MaxRetries { get; set; }

    /// <summary>
    /// Configuration: Delay between retries in seconds.
    /// </summary>
    int RetryDelaySeconds { get; set; }

    /// <summary>
    /// Configuration: Time to wait (in seconds) when the Circuit Breaker blocks execution.
    /// Default: 5 seconds.
    /// </summary>
    int CircuitBreakerDelaySeconds { get; set; }

    /// <summary>
    /// Processes a single job with full resilience logic.
    /// </summary>
    /// <param name="jobId">Unique Job ID.</param>
    /// <param name="jobType">Type key or class name.</param>
    /// <param name="payload">JSON payload.</param>
    /// <param name="workerId">The ID of the worker thread.</param>
    /// <param name="workerCt">The worker's cancellation token.</param>
    Task ProcessJobAsync(
        string jobId,
        string jobType,
        string payload,
        string workerId,
        int attemptCount,
        string? createdBy,
        CancellationToken workerCt);
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Core\Processing\JobProcessor.cs
using ChokaQ.Abstractions.Resilience;
using ChokaQ.Abstractions.Storage;
using ChokaQ.Core.Execution;
using ChokaQ.Core.State;
using Microsoft.Extensions.Logging;
using System.Collections.Concurrent;
using System.Diagnostics;

namespace ChokaQ.Core.Processing;

/// <summary>
/// The core execution engine for a single job.
/// Orchestrates the lifecycle: Fetch -> Circuit Check -> Execute -> Archive (Success/DLQ).
/// 
/// Three Pillars Integration:
/// - Success: Job archived to Archive table
/// - Failure (max retries): Job archived to DLQ
/// - Cancelled: Job archived to DLQ
/// - Retry: Job stays in Hot table with scheduled time
/// </summary>
public class JobProcessor : IJobProcessor
{
    private readonly IJobStorage _storage;
    private readonly ILogger<JobProcessor> _logger;
    private readonly ICircuitBreaker _breaker;
    private readonly IJobDispatcher _dispatcher;
    private readonly IJobStateManager _stateManager;

    // Registry of tokens for currently running jobs to allow real-time cancellation.
    private readonly ConcurrentDictionary<string, CancellationTokenSource> _activeJobTokens = new();

    // --- Configuration ---

    /// <summary>
    /// Maximum number of retries before archiving job to DLQ.
    /// Default: 3.
    /// </summary>
    public int MaxRetries { get; set; } = 3;

    /// <summary>
    /// Base delay (in seconds) for the exponential backoff strategy.
    /// Default: 3 seconds.
    /// </summary>
    public int RetryDelaySeconds { get; set; } = 3;

    /// <summary>
    /// Time to wait (in seconds) if the Circuit Breaker blocks execution.
    /// Default: 5 seconds.
    /// </summary>
    public int CircuitBreakerDelaySeconds { get; set; } = 5;

    public JobProcessor(
        IJobStorage storage,
        ILogger<JobProcessor> logger,
        ICircuitBreaker breaker,
        IJobDispatcher dispatcher,
        IJobStateManager stateManager,
        ChokaQOptions? options = null)
    {
        _storage = storage ?? throw new ArgumentNullException(nameof(storage));
        _logger = logger ?? throw new ArgumentNullException(nameof(logger));
        _breaker = breaker ?? throw new ArgumentNullException(nameof(breaker));
        _dispatcher = dispatcher ?? throw new ArgumentNullException(nameof(dispatcher));
        _stateManager = stateManager ?? throw new ArgumentNullException(nameof(stateManager));

        if (options != null)
        {
            MaxRetries = options.MaxRetries;
            RetryDelaySeconds = options.RetryDelaySeconds;
        }
    }

    /// <summary>
    /// Thread-safe method to signal cancellation for a running job.
    /// </summary>
    public void CancelJob(string jobId)
    {
        if (_activeJobTokens.TryGetValue(jobId, out var cts))
        {
            _logger.LogInformation("Requesting cancellation for running job {JobId}...", jobId);
            cts.Cancel();
        }
    }

    /// <summary>
    /// Processes a single job with full resilience logic.
    /// </summary>
    public async Task ProcessJobAsync(
        string jobId,
        string jobType,
        string payload,
        string workerId,
        int attemptCount,
        string? createdBy,
        CancellationToken workerCt)
    {
        var meta = _dispatcher.ParseMetadata(payload);
        var context = new JobExecutionContext(jobId, jobType, createdBy, meta.Queue, meta.Priority, attemptCount);

        // 1. Circuit Breaker Check
        if (!_breaker.IsExecutionPermitted(jobType))
        {
            _logger.LogWarning("[CircuitBreaker] Job {JobId} skipped. Circuit for {Type} is OPEN.", jobId, jobType);

            // Reschedule with delay
            await _stateManager.RescheduleForRetryAsync(
                jobId, jobType, meta.Queue, meta.Priority,
                DateTime.UtcNow.AddSeconds(CircuitBreakerDelaySeconds),
                attemptCount,
                "Circuit Breaker Open",
                workerCt);
            return;
        }

        // 2. Mark as Processing and Start Heartbeat
        await _stateManager.MarkAsProcessingAsync(
            jobId, jobType, meta.Queue, meta.Priority, attemptCount, createdBy, workerCt);

        // Create a linked token for cancellation
        using var jobCts = CancellationTokenSource.CreateLinkedTokenSource(workerCt);
        _activeJobTokens.TryAdd(jobId, jobCts);

        // Start Heartbeat loop
        using var heartbeatCts = CancellationTokenSource.CreateLinkedTokenSource(workerCt);
        var heartbeatTask = StartHeartbeatLoopAsync(jobId, heartbeatCts.Token);

        var sw = Stopwatch.StartNew();
        try
        {
            // 3. Dispatch execution
            await _dispatcher.DispatchAsync(jobId, jobType, payload, jobCts.Token);
            sw.Stop();

            // Stop heartbeat
            await heartbeatCts.CancelAsync();
            try { await heartbeatTask; } catch (OperationCanceledException) { }

            // 4. SUCCESS: Archive to Archive table
            _breaker.ReportSuccess(jobType);
            await _stateManager.ArchiveSucceededAsync(
                jobId, jobType, meta.Queue, sw.Elapsed.TotalMilliseconds, workerCt);

            _logger.LogInformation(
                "[Worker {ID}] Job {JobId} succeeded in {Duration:F1}ms → Archived.",
                workerId, jobId, sw.Elapsed.TotalMilliseconds);
        }
        catch (OperationCanceledException)
        {
            sw.Stop();
            await heartbeatCts.CancelAsync();

            // CANCELLED: Archive to DLQ
            _logger.LogInformation("[Worker {ID}] Job {JobId} was cancelled.", workerId, jobId);
            await _stateManager.ArchiveCancelledAsync(
                jobId, jobType, meta.Queue, "Worker/Admin cancellation", workerCt);
        }
        catch (Exception ex)
        {
            sw.Stop();
            await heartbeatCts.CancelAsync();

            // 5. FAILURE: Retry or Archive to DLQ
            await HandleErrorAsync(ex, context, workerId, workerCt);
        }
        finally
        {
            _activeJobTokens.TryRemove(jobId, out _);
        }
    }

    /// <summary>
    /// Periodically updates the job heartbeat in storage.
    /// Uses jitter to prevent thundering herd effect.
    /// </summary>
    private async Task StartHeartbeatLoopAsync(string jobId, CancellationToken ct)
    {
        var random = Random.Shared;

        try
        {
            while (!ct.IsCancellationRequested)
            {
                // Jitter: Wait between 8 and 12 seconds
                var delayMs = random.Next(8000, 12000);
                await Task.Delay(delayMs, ct);
                await _storage.KeepAliveAsync(jobId, ct);
            }
        }
        catch (OperationCanceledException)
        {
            // Expected when job completes
        }
        catch (Exception ex)
        {
            _logger.LogWarning(ex, "Heartbeat failed for job {JobId}", jobId);
        }
    }

    private async Task HandleErrorAsync(
        Exception ex,
        JobExecutionContext context,
        string workerId,
        CancellationToken ct)
    {
        // Notify Circuit Breaker
        _breaker.ReportFailure(context.JobType);

        // Decision: Retry or Archive to DLQ?
        if (context.AttemptCount < MaxRetries)
        {
            var nextAttempt = context.AttemptCount + 1;
            var delayMs = CalculateBackoff(nextAttempt);
            var scheduledAt = DateTime.UtcNow.AddMilliseconds(delayMs);

            _logger.LogWarning(ex,
                "[Worker {WorkerId}] Job {JobId} failed. Retry #{Attempt} scheduled in {Delay}ms.",
                workerId, context.JobId, nextAttempt, delayMs);

            // RETRY: Stay in Hot table
            await _stateManager.RescheduleForRetryAsync(
                context.JobId, context.JobType, context.Queue, context.Priority,
                scheduledAt, nextAttempt, ex.Message, ct);
        }
        else
        {
            _logger.LogError(ex,
                "[Worker {WorkerId}] Job {JobId} failed permanently after {Retries} attempts → Archived to DLQ.",
                workerId, context.JobId, MaxRetries);

            // FINAL FAILURE: Archive to DLQ
            await _stateManager.ArchiveFailedAsync(
                context.JobId, context.JobType, context.Queue, ex.ToString(), ct);
        }
    }

    /// <summary>
    /// Calculates exponential backoff with jitter.
    /// Formula: (Base * 2^(attempt-1)) + Jitter
    /// </summary>
    private int CalculateBackoff(int attempt)
    {
        var baseDelay = RetryDelaySeconds * Math.Pow(2, attempt - 1);

        // Cap at 1 hour
        if (baseDelay > 3600) baseDelay = 3600;

        var jitter = Random.Shared.Next(0, 1000);
        return (int)(baseDelay * 1000) + jitter;
    }

    // Immutable context for job execution
    private record JobExecutionContext(
        string JobId,
        string JobType,
        string? CreatedBy,
        string Queue,
        int Priority,
        int AttemptCount);
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Core\Resilience\ZombieRescueService.cs
using ChokaQ.Abstractions.Notifications;
using ChokaQ.Abstractions.Storage;
using Microsoft.Extensions.Hosting;
using Microsoft.Extensions.Logging;

namespace ChokaQ.Core.Resilience;

/// <summary>
/// Background service that periodically scans for "Zombie" jobs.
/// A Zombie is a job stuck in 'Processing' state but whose worker has stopped sending heartbeats
/// (e.g., due to a server crash, power outage, or OOM killer).
/// 
/// In Three Pillars architecture, zombies are moved to DLQ with FailureReason.Zombie.
/// </summary>
public class ZombieRescueService : BackgroundService
{
    private readonly IJobStorage _storage;
    private readonly IChokaQNotifier _notifier;
    private readonly ILogger<ZombieRescueService> _logger;

    // Config: How often to run the cleanup scan
    private static readonly TimeSpan CheckInterval = TimeSpan.FromMinutes(1);

    // Config: Default fallback timeout if queue specific setting is missing.
    // 10 minutes allows for some network latency or long GC pauses before declaring death.
    private const int DefaultGlobalZombieTimeoutSeconds = 600;

    public ZombieRescueService(
        IJobStorage storage,
        IChokaQNotifier notifier,
        ILogger<ZombieRescueService> logger)
    {
        _storage = storage;
        _notifier = notifier;
        _logger = logger;
    }

    protected override async Task ExecuteAsync(CancellationToken stoppingToken)
    {
        _logger.LogInformation("Zombie Rescue Service started. Watching for dead workers...");

        while (!stoppingToken.IsCancellationRequested)
        {
            try
            {
                // Execute the cleanup - zombies are moved to DLQ
                int zombiesArchived = await _storage.ArchiveZombiesAsync(DefaultGlobalZombieTimeoutSeconds, stoppingToken);

                if (zombiesArchived > 0)
                {
                    _logger.LogWarning(
                        "ZOMBIE ALERT: Archived {Count} dead jobs to DLQ. They can be resurrected from the Morgue view.",
                        zombiesArchived);

                    // Notify dashboard to refresh
                    try
                    {
                        await _notifier.NotifyStatsUpdatedAsync();
                    }
                    catch
                    {
                        // Ignore notification failures
                    }
                }
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Failed to execute Zombie Rescue cycle.");
            }

            // Wait for next cycle
            await Task.Delay(CheckInterval, stoppingToken);
        }
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Core\State\IJobStateManager.cs
namespace ChokaQ.Core.State;

/// <summary>
/// Manages the state transitions of jobs in Three Pillars architecture.
/// Coordinates storage operations and real-time notifications.
/// </summary>
public interface IJobStateManager
{
    /// <summary>
    /// Archives a succeeded job: Hot → Archive.
    /// Notifies dashboard about the transition.
    /// </summary>
    Task ArchiveSucceededAsync(
        string jobId,
        string jobType,
        string queue,
        double? durationMs = null,
        CancellationToken ct = default);

    /// <summary>
    /// Archives a failed job: Hot → DLQ.
    /// Notifies dashboard about the transition.
    /// </summary>
    Task ArchiveFailedAsync(
        string jobId,
        string jobType,
        string queue,
        string errorDetails,
        CancellationToken ct = default);

    /// <summary>
    /// Archives a cancelled job: Hot → DLQ.
    /// Notifies dashboard about the transition.
    /// </summary>
    Task ArchiveCancelledAsync(
        string jobId,
        string jobType,
        string queue,
        string? cancelledBy = null,
        CancellationToken ct = default);

    /// <summary>
    /// Reschedules a job for retry (stays in Hot).
    /// Notifies dashboard about the update.
    /// </summary>
    Task RescheduleForRetryAsync(
        string jobId,
        string jobType,
        string queue,
        int priority,
        DateTime scheduledAtUtc,
        int newAttemptCount,
        string lastError,
        CancellationToken ct = default);

    /// <summary>
    /// Updates job to Processing status (stays in Hot).
    /// Notifies dashboard about the update.
    /// </summary>
    Task MarkAsProcessingAsync(
        string jobId,
        string jobType,
        string queue,
        int priority,
        int attemptCount,
        string? createdBy,
        CancellationToken ct = default);
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Core\State\JobStateManager.cs
using ChokaQ.Abstractions.DTOs;
using ChokaQ.Abstractions.Enums;
using ChokaQ.Abstractions.Notifications;
using ChokaQ.Abstractions.Storage;
using Microsoft.Extensions.Logging;

namespace ChokaQ.Core.State;

/// <summary>
/// Manages job state transitions following the Three Pillars architecture.
/// Acts as an orchestration layer between storage persistence and SignalR notifications.
/// </summary>
/// <remarks>
/// Responsibilities:
/// - Coordinates atomic transitions between pillars (Hot → Archive, Hot → DLQ)
/// - Triggers real-time dashboard updates via IChokaQNotifier
/// - Handles notification failures gracefully (fire-and-forget with logging)
/// 
/// This separation of concerns allows JobProcessor to focus on execution logic
/// while JobStateManager handles the persistence and notification plumbing.
/// </remarks>
public class JobStateManager : IJobStateManager
{
    private readonly IJobStorage _storage;
    private readonly IChokaQNotifier _notifier;
    private readonly ILogger<JobStateManager> _logger;

    public JobStateManager(
        IJobStorage storage,
        IChokaQNotifier notifier,
        ILogger<JobStateManager> logger)
    {
        _storage = storage;
        _notifier = notifier;
        _logger = logger;
    }

    /// <summary>
    /// Archives a successfully completed job from Hot to Archive table.
    /// Updates StatsSummary.SucceededTotal and notifies connected dashboards.
    /// </summary>
    public async Task ArchiveSucceededAsync(
        string jobId,
        string jobType,
        string queue,
        double? durationMs = null,
        CancellationToken ct = default)
    {
        // 1. Archive: Hot → Archive
        await _storage.ArchiveSucceededAsync(jobId, durationMs, ct);

        // 2. Notify dashboard
        await SafeNotifyAsync(() => _notifier.NotifyJobArchivedAsync(jobId, queue));
        await SafeNotifyAsync(() => _notifier.NotifyStatsUpdatedAsync());
    }

    /// <summary>
    /// Archives a permanently failed job from Hot to DLQ table.
    /// Called when a job exhausts all retry attempts.
    /// Updates StatsSummary.FailedTotal and notifies connected dashboards.
    /// </summary>
    public async Task ArchiveFailedAsync(
        string jobId,
        string jobType,
        string queue,
        string errorDetails,
        CancellationToken ct = default)
    {
        // 1. Archive: Hot → DLQ
        await _storage.ArchiveFailedAsync(jobId, errorDetails, ct);

        // 2. Notify dashboard
        await SafeNotifyAsync(() => _notifier.NotifyJobFailedAsync(jobId, queue, "MaxRetriesExceeded"));
        await SafeNotifyAsync(() => _notifier.NotifyStatsUpdatedAsync());
    }

    public async Task ArchiveCancelledAsync(
        string jobId,
        string jobType,
        string queue,
        string? cancelledBy = null,
        CancellationToken ct = default)
    {
        // 1. Archive: Hot → DLQ
        await _storage.ArchiveCancelledAsync(jobId, cancelledBy, ct);

        // 2. Notify dashboard
        await SafeNotifyAsync(() => _notifier.NotifyJobFailedAsync(jobId, queue, "Cancelled"));
        await SafeNotifyAsync(() => _notifier.NotifyStatsUpdatedAsync());
    }

    public async Task RescheduleForRetryAsync(
        string jobId,
        string jobType,
        string queue,
        int priority,
        DateTime scheduledAtUtc,
        int newAttemptCount,
        string lastError,
        CancellationToken ct = default)
    {
        // 1. Reschedule in Hot table
        await _storage.RescheduleForRetryAsync(jobId, scheduledAtUtc, newAttemptCount, lastError, ct);

        // 2. Notify dashboard
        var update = new JobUpdateDto(
            JobId: jobId,
            Type: jobType,
            Queue: queue,
            Status: JobStatus.Pending,
            AttemptCount: newAttemptCount,
            Priority: priority,
            DurationMs: null,
            CreatedBy: null,
            StartedAtUtc: null
        );
        await SafeNotifyAsync(() => _notifier.NotifyJobUpdatedAsync(update));
        await SafeNotifyAsync(() => _notifier.NotifyStatsUpdatedAsync());
    }

    public async Task MarkAsProcessingAsync(
        string jobId,
        string jobType,
        string queue,
        int priority,
        int attemptCount,
        string? createdBy,
        CancellationToken ct = default)
    {
        // 1. Update status in Hot table
        await _storage.MarkAsProcessingAsync(jobId, ct);

        // 2. Notify dashboard
        var now = DateTime.UtcNow;
        var update = new JobUpdateDto(
            JobId: jobId,
            Type: jobType,
            Queue: queue,
            Status: JobStatus.Processing,
            AttemptCount: attemptCount,
            Priority: priority,
            DurationMs: null,
            CreatedBy: createdBy,
            StartedAtUtc: now
        );
        await SafeNotifyAsync(() => _notifier.NotifyJobUpdatedAsync(update));
    }

    private async Task SafeNotifyAsync(Func<Task> notifyAction)
    {
        try
        {
            await notifyAction();
        }
        catch (Exception ex)
        {
            _logger.LogWarning("Failed to send notification: {Message}", ex.Message);
        }
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Core\Workers\JobWorker.cs
using ChokaQ.Abstractions.Enums;
using ChokaQ.Abstractions.Jobs;
using ChokaQ.Abstractions.Storage;
using ChokaQ.Abstractions.Workers;
using ChokaQ.Core.Defaults;
using ChokaQ.Core.Processing;
using ChokaQ.Core.State;
using Microsoft.Extensions.Hosting;
using Microsoft.Extensions.Logging;
using System.Text.Json;

namespace ChokaQ.Core.Workers;

/// <summary>
/// In-Memory Worker implementation used for development or non-persistent scenarios.
/// Consumes jobs from System.Threading.Channels.
/// 
/// Three Pillars integration:
/// - Reads from Hot table via storage
/// - Cancellation archives to DLQ
/// - Resurrection happens via storage.ResurrectAsync
/// </summary>
public class JobWorker : BackgroundService, IWorkerManager
{
    private readonly InMemoryQueue _queue;
    private readonly IJobStorage _storage;
    private readonly ILogger<JobWorker> _logger;
    private readonly IJobStateManager _stateManager;
    private readonly IJobProcessor _processor;
    private readonly List<(Task Task, CancellationTokenSource Cts)> _workers = new();
    private readonly object _lock = new();

    // Configuration delegated to Processor
    public int MaxRetries
    {
        get => _processor.MaxRetries;
        set => _processor.MaxRetries = value;
    }

    public int RetryDelaySeconds
    {
        get => _processor.RetryDelaySeconds;
        set => _processor.RetryDelaySeconds = value;
    }

    public int ActiveWorkers { get; private set; } = 0;
    private int _targetWorkerCount = 1;
    public int TotalWorkers => _targetWorkerCount;

    public JobWorker(
        InMemoryQueue queue,
        IJobStorage storage,
        ILogger<JobWorker> logger,
        IJobStateManager stateManager,
        IJobProcessor processor)
    {
        _queue = queue;
        _storage = storage;
        _logger = logger;
        _stateManager = stateManager;
        _processor = processor;
    }

    public async Task CancelJobAsync(string jobId)
    {
        // Try to cancel if running
        if (_processor is JobProcessor concreteProcessor)
        {
            concreteProcessor.CancelJob(jobId);
        }

        // Fetch job from Hot table
        var job = await _storage.GetJobAsync(jobId);
        if (job == null)
        {
            _logger.LogWarning("Cannot cancel job {JobId}: not found in Hot table.", jobId);
            return;
        }

        // Only cancel if Pending or Fetched (Processing is handled by CancelJob above)
        if (job.Status == JobStatus.Pending || job.Status == JobStatus.Fetched)
        {
            _logger.LogInformation("Archiving pending job {JobId} to DLQ as Cancelled.", jobId);
            await _stateManager.ArchiveCancelledAsync(
                jobId, job.Type, job.Queue, "Admin cancellation");
        }
    }

    public async Task RestartJobAsync(string jobId)
    {
        // First check Hot table
        var hotJob = await _storage.GetJobAsync(jobId);
        if (hotJob != null)
        {
            if (hotJob.Status == JobStatus.Processing || hotJob.Status == JobStatus.Pending)
            {
                _logger.LogWarning("Cannot restart job {JobId}: still active ({Status}).", jobId, hotJob.Status);
                return;
            }
        }

        // Check DLQ for resurrection
        var dlqJob = await _storage.GetDLQJobAsync(jobId);
        if (dlqJob != null)
        {
            _logger.LogInformation("Resurrecting job {JobId} from DLQ...", jobId);
            await _storage.ResurrectAsync(jobId, null, "Admin restart");

            // Re-queue for processing
            await RequeueJobFromStorage(jobId);
            return;
        }

        // Check Archive for clone/restart
        var archivedJob = await _storage.GetArchiveJobAsync(jobId);
        if (archivedJob != null)
        {
            _logger.LogInformation("Cannot restart succeeded job {JobId} from Archive. Use clone functionality.", jobId);
            return;
        }

        _logger.LogWarning("Cannot restart job {JobId}: not found in any table.", jobId);
    }

    public async Task SetJobPriorityAsync(string jobId, int priority)
    {
        var result = await _storage.UpdateJobDataAsync(
            jobId,
            new Abstractions.DTOs.JobDataUpdateDto(null, null, priority),
            "Admin");

        if (!result)
        {
            _logger.LogWarning("Cannot update priority for job {JobId}: not Pending or not found.", jobId);
        }
    }

    protected override Task ExecuteAsync(CancellationToken stoppingToken)
    {
        UpdateWorkerCount(1);
        return Task.CompletedTask;
    }

    public void UpdateWorkerCount(int targetCount)
    {
        if (targetCount < 0) targetCount = 0;
        if (targetCount > 100) targetCount = 100;

        _targetWorkerCount = targetCount;

        lock (_lock)
        {
            int current = _workers.Count;
            if (targetCount > current)
            {
                int toAdd = targetCount - current;
                for (int i = 0; i < toAdd; i++)
                {
                    var cts = new CancellationTokenSource();
                    var task = Task.Run(() => WorkerLoopAsync(cts.Token), cts.Token);
                    _workers.Add((task, cts));
                }
            }
            else if (targetCount < current)
            {
                int toRemove = current - targetCount;
                for (int i = 0; i < toRemove; i++)
                {
                    var worker = _workers.Last();
                    worker.Cts.Cancel();
                    _workers.RemoveAt(_workers.Count - 1);
                }
            }

            ActiveWorkers = _workers.Count;
        }
    }

    private async Task WorkerLoopAsync(CancellationToken workerCt)
    {
        var workerId = Guid.NewGuid().ToString()[..4];
        try
        {
            while (!workerCt.IsCancellationRequested)
            {
                if (await _queue.Reader.WaitToReadAsync(workerCt))
                {
                    while (_queue.Reader.TryRead(out var job))
                    {
                        // Look up job in Hot table
                        var storageJob = await _storage.GetJobAsync(job.Id, workerCt);
                        if (storageJob == null) continue;

                        // Check if queue is paused
                        var queues = await _storage.GetQueuesAsync(workerCt);
                        var targetQueue = queues.FirstOrDefault(q => q.Name == storageJob.Queue);

                        if (targetQueue != null && targetQueue.IsPaused)
                        {
                            // Queue is paused - requeue
                            await _queue.RequeueAsync(job, workerCt);
                            await Task.Delay(1000, workerCt);
                            continue;
                        }

                        var typeKey = job.GetType().Name;
                        var payload = JsonSerializer.Serialize(job, job.GetType());

                        await _processor.ProcessJobAsync(
                            job.Id,
                            typeKey,
                            payload,
                            workerId,
                            storageJob.AttemptCount,
                            storageJob.CreatedBy,
                            workerCt
                        );

                        if (workerCt.IsCancellationRequested) break;
                    }
                }
            }
        }
        catch (OperationCanceledException) { }
        finally
        {
            _logger.LogInformation("[Worker {ID}] Stopped.", workerId);
        }
    }

    private async Task RequeueJobFromStorage(string jobId)
    {
        var job = await _storage.GetJobAsync(jobId);
        if (job == null) return;

        // Try to reconstruct job object for channel
        var jobType = Type.GetType(job.Type);
        if (jobType == null)
        {
            jobType = AppDomain.CurrentDomain.GetAssemblies()
                .SelectMany(a => a.GetTypes())
                .FirstOrDefault(t => t.Name == job.Type);
        }

        if (jobType != null && job.Payload != null)
        {
            var jobObject = JsonSerializer.Deserialize(job.Payload, jobType) as IChokaQJob;
            if (jobObject != null)
            {
                await _queue.RequeueAsync(jobObject);
                return;
            }
        }

        _logger.LogWarning("Could not requeue job {JobId}: type resolution failed.", jobId);
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Storage.SqlServer\ChokaQ.Storage.SqlServer.csproj
<Project Sdk="Microsoft.NET.Sdk">

  <ItemGroup>
    <None Remove="Scripts\CleanupProcTemplate.sql" />
    <None Remove="Scripts\SchemaTemplate.sql" />
  </ItemGroup>

  <ItemGroup>
    <EmbeddedResource Include="Scripts\CleanupProcTemplate.sql" />
    <EmbeddedResource Include="Scripts\SchemaTemplate.sql" />
  </ItemGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Data.SqlClient" Version="6.1.3" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\ChokaQ.Core\ChokaQ.Core.csproj" />
  </ItemGroup>

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
  </PropertyGroup>

</Project>

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Storage.SqlServer\ChokaQSqlServerExtensions.cs
using ChokaQ.Abstractions.Storage;
using ChokaQ.Abstractions.Workers;
using ChokaQ.Core.Workers;
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.DependencyInjection.Extensions;
using Microsoft.Extensions.Hosting;
using Microsoft.Extensions.Logging;
using Microsoft.Extensions.Options;

namespace ChokaQ.Storage.SqlServer;

/// <summary>
/// Extension methods for configuring ChokaQ with SQL Server persistence.
/// </summary>
public static class ChokaQSqlServerExtensions
{
    /// <summary>
    /// Configures ChokaQ to use SQL Server as the storage provider.
    /// Implements the Three Pillars architecture: JobsHot, JobsArchive, JobsDLQ.
    /// </summary>
    /// <param name="services">The service collection.</param>
    /// <param name="configure">Configuration callback for SQL Server options.</param>
    /// <remarks>
    /// Usage:
    /// <code>
    /// services.AddChokaQ(options => options.AddProfile&lt;MyProfile&gt;());
    /// services.UseSqlServer(options =>
    /// {
    ///     options.ConnectionString = "Server=...";
    ///     options.SchemaName = "chokaq";
    ///     options.AutoCreateSqlTable = true;
    ///     options.PollingInterval = TimeSpan.FromSeconds(5);
    /// });
    /// </code>
    /// 
    /// This method performs the "Great Swap":
    /// 1. Replaces InMemoryJobStorage with SqlJobStorage
    /// 2. Replaces JobWorker with SqlJobWorker (polling-based)
    /// 3. Optionally creates database schema on startup
    /// 
    /// Tables created (when AutoCreateSqlTable = true):
    /// - [schema].[JobsHot]: Active jobs
    /// - [schema].[JobsArchive]: Succeeded jobs history
    /// - [schema].[JobsDLQ]: Failed jobs (dead letter queue)
    /// - [schema].[StatsSummary]: Pre-aggregated metrics
    /// - [schema].[Queues]: Queue configuration
    /// </remarks>
    public static void UseSqlServer(this IServiceCollection services, Action<SqlJobStorageOptions> configure)
    {
        var options = new SqlJobStorageOptions();
        configure(options);

        // Validation
        if (string.IsNullOrWhiteSpace(options.ConnectionString))
        {
            throw new ArgumentNullException(nameof(options.ConnectionString), "Connection string cannot be empty.");
        }

        // Register options for DI
        services.Configure<SqlJobStorageOptions>(opt =>
        {
            opt.ConnectionString = options.ConnectionString;
            opt.SchemaName = options.SchemaName;
            opt.AutoCreateSqlTable = options.AutoCreateSqlTable;
            opt.PollingInterval = options.PollingInterval;
            opt.NoQueuesSleepInterval = options.NoQueuesSleepInterval;
        });

        // =========================================================
        // 1. STORAGE REPLACEMENT
        // =========================================================

        // Remove the default InMemoryJobStorage
        services.RemoveAll<IJobStorage>();

        // Register the SQL Implementation (Three Pillars)
        services.AddSingleton<IJobStorage, SqlJobStorage>();

        // =========================================================
        // 2. WORKER REPLACEMENT (THE SWAP)
        // =========================================================

        // Remove the default JobWorker (listens to In-Memory channels)
        var workerDescriptors = services.Where(d =>
            d.ServiceType == typeof(IHostedService) &&
            (d.ImplementationType == typeof(JobWorker) ||
             d.ImplementationFactory?.Method.ReturnType == typeof(JobWorker)))
            .ToList();

        foreach (var descriptor in workerDescriptors)
        {
            services.Remove(descriptor);
        }

        // Remove IWorkerManager registration
        services.RemoveAll<IWorkerManager>();

        // Register SqlJobWorker
        services.AddSingleton<SqlJobWorker>(sp =>
        {
            var sqlOptions = sp.GetRequiredService<IOptions<SqlJobStorageOptions>>().Value;
            return new SqlJobWorker(
                sp.GetRequiredService<IJobStorage>(),
                sp.GetRequiredService<ChokaQ.Core.Processing.IJobProcessor>(),
                sp.GetRequiredService<ChokaQ.Core.State.IJobStateManager>(),
                sp.GetRequiredService<ILogger<SqlJobWorker>>(),
                sqlOptions
            );
        });

        // Bind interfaces to SqlJobWorker
        services.AddSingleton<IWorkerManager>(sp => sp.GetRequiredService<SqlJobWorker>());
        services.AddHostedService(sp => sp.GetRequiredService<SqlJobWorker>());

        // =========================================================
        // 3. AUTO-PROVISIONING (MIGRATIONS)
        // =========================================================

        if (options.AutoCreateSqlTable)
        {
            services.AddTransient<SqlInitializer>(sp =>
            {
                var logger = sp.GetRequiredService<ILogger<SqlInitializer>>();
                return new SqlInitializer(options.ConnectionString, options.SchemaName, logger);
            });

            services.AddHostedService<DbMigrationWorker>();
        }
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Storage.SqlServer\DbMigrationWorker.cs
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Hosting;
using Microsoft.Extensions.Logging;

namespace ChokaQ.Storage.SqlServer;

/// <summary>
/// Background worker that triggers database initialization at application startup.
/// </summary>
public class DbMigrationWorker : IHostedService
{
    private readonly IServiceProvider _serviceProvider;
    private readonly ILogger<DbMigrationWorker> _logger;

    public DbMigrationWorker(IServiceProvider serviceProvider, ILogger<DbMigrationWorker> logger)
    {
        _serviceProvider = serviceProvider;
        _logger = logger;
    }

    public async Task StartAsync(CancellationToken cancellationToken)
    {
        // Create a scope to resolve scoped/transient services
        using var scope = _serviceProvider.CreateScope();
        var initializer = scope.ServiceProvider.GetRequiredService<SqlInitializer>();

        _logger.LogInformation("Running automatic database migration...");
        await initializer.InitializeAsync(cancellationToken);
    }

    public Task StopAsync(CancellationToken cancellationToken) => Task.CompletedTask;
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Storage.SqlServer\SqlInitializer.cs
using ChokaQ.Storage.SqlServer.DataEngine;
using Microsoft.Data.SqlClient;
using Microsoft.Extensions.Logging;
using System.Reflection;
using System.Text.RegularExpressions;

namespace ChokaQ.Storage.SqlServer;

/// <summary>
/// Handles database schema provisioning.
/// Reads embedded SQL scripts, replaces schema placeholders, and executes them against the target database.
/// </summary>
public class SqlInitializer
{
    private readonly string _connectionString;
    private readonly string _schemaName;
    private readonly ILogger<SqlInitializer> _logger;

    public SqlInitializer(string connectionString, string schemaName, ILogger<SqlInitializer> logger)
    {
        _connectionString = connectionString ?? throw new ArgumentNullException(nameof(connectionString));
        _schemaName = schemaName ?? throw new ArgumentNullException(nameof(schemaName));
        _logger = logger ?? throw new ArgumentNullException(nameof(logger));
    }

    /// <summary>
    /// Executes the provisioning logic.
    /// </summary>
    public async Task InitializeAsync(CancellationToken ct = default)
    {
        _logger.LogInformation("Starting ChokaQ database initialization. Target Schema: {Schema}", _schemaName);

        // 1. Security Validation
        // Prevent SQL Injection via schema name configuration
        if (!Regex.IsMatch(_schemaName, "^[a-zA-Z0-9_]+$"))
        {
            throw new ArgumentException($"Invalid schema name: '{_schemaName}'. Only alphanumeric characters and underscores are allowed.");
        }

        try
        {
            using var connection = new SqlConnection(_connectionString);
            await connection.OpenAsync(ct);

            // 2. Define execution order
            // Tables must be created before Stored Procedures
            var scripts = new[]
            {
                "ChokaQ.Storage.SqlServer.Scripts.SchemaTemplate.sql",
                "ChokaQ.Storage.SqlServer.Scripts.CleanupProcTemplate.sql"
            };

            foreach (var resourceName in scripts)
            {
                await ExecuteScriptFromResourceAsync(connection, resourceName, ct);
            }

            _logger.LogInformation("ChokaQ database initialization completed successfully.");
        }
        catch (Exception ex)
        {
            _logger.LogCritical(ex, "ChokaQ database initialization failed. Application may not function correctly.");
            throw;
        }
    }

    private async Task ExecuteScriptFromResourceAsync(SqlConnection connection, string resourceName, CancellationToken ct)
    {
        // 3. Load Embedded Resource
        var assembly = Assembly.GetExecutingAssembly();
        using var stream = assembly.GetManifestResourceStream(resourceName);

        if (stream == null)
        {
            throw new FileNotFoundException($"Embedded SQL resource not found: {resourceName}. Ensure 'Build Action' is set to 'Embedded Resource'.");
        }

        using var reader = new StreamReader(stream);
        var template = await reader.ReadToEndAsync(ct);

        // 4. Replace Placeholders
        var finalScript = template.Replace("{SCHEMA}", _schemaName);

        // 5. Split by 'GO'
        // ADO.NET / Dapper cannot execute scripts containing 'GO' as a single batch.
        // We must split them and execute individually.
        // Regex logic: Matches "GO" on a separate line, case-insensitive, ignoring whitespace.
        var commands = Regex.Split(finalScript, @"^\s*GO\s*$", RegexOptions.Multiline | RegexOptions.IgnoreCase);

        foreach (var commandText in commands)
        {
            if (string.IsNullOrWhiteSpace(commandText)) continue;

            try
            {
                await connection.ExecuteAsync(commandText, null, ct);
            }
            catch (SqlException ex)
            {
                _logger.LogError(ex, "Error executing SQL block from {Resource}.", resourceName);
                throw; // Rethrow to stop initialization
            }
        }
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Storage.SqlServer\SqlJobStorage.cs
using ChokaQ.Abstractions.DTOs;
using ChokaQ.Abstractions.Entities;
using ChokaQ.Abstractions.Enums;
using ChokaQ.Abstractions.Storage;
using ChokaQ.Storage.SqlServer.DataEngine;
using Microsoft.Data.SqlClient;
using Microsoft.Extensions.Options;

namespace ChokaQ.Storage.SqlServer;

/// <summary>
/// SQL Server implementation of IJobStorage using Three Pillars architecture.
/// 
/// Tables:
/// - JobsHot: Active jobs (Pending, Fetched, Processing)
/// - JobsArchive: Succeeded jobs (History)
/// - JobsDLQ: Failed/Cancelled/Zombie jobs (Dead Letter Queue)
/// - StatsSummary: Pre-aggregated counters
/// - Queues: Queue configuration
/// </summary>
public class SqlJobStorage : IJobStorage
{
    private readonly SqlJobStorageOptions _options;
    private readonly string _schema;
    private readonly Queries _q;

    public SqlJobStorage(IOptions<SqlJobStorageOptions> options)
    {
        _options = options.Value;
        _schema = _options.SchemaName;
        _q = new Queries(_schema);
    }

    private async Task<SqlConnection> OpenConnectionAsync(CancellationToken ct = default)
    {
        var conn = new SqlConnection(_options.ConnectionString);
        await conn.OpenAsync(ct);
        return conn;
    }

    // ========================================================================
    // CORE OPERATIONS (Hot Table)
    // ========================================================================

    public async ValueTask<string> EnqueueAsync(
        string id,
        string queue,
        string jobType,
        string payload,
        int priority = 10,
        string? createdBy = null,
        string? tags = null,
        TimeSpan? delay = null,
        string? idempotencyKey = null,
        CancellationToken ct = default)
    {
        await using var conn = await OpenConnectionAsync(ct);

        // Idempotency check - return existing ID if key exists
        if (!string.IsNullOrEmpty(idempotencyKey))
        {
            var existingId = await conn.QueryFirstOrDefaultAsync<string>(
                _q.CheckIdempotency,
                new { Key = idempotencyKey });

            if (existingId != null)
                return existingId;
        }

        await conn.ExecuteAsync(_q.EnqueueJob, new
        {
            Id = id,
            Queue = queue,
            Type = jobType,
            Payload = payload,
            Tags = tags,
            IdempotencyKey = idempotencyKey,
            Priority = priority,
            CreatedBy = createdBy,
            ScheduledAt = delay.HasValue ? DateTime.UtcNow.Add(delay.Value) : (DateTime?)null
        }, ct);

        return id;
    }

    public async ValueTask<IEnumerable<JobHotEntity>> FetchNextBatchAsync(
        string workerId,
        int batchSize,
        string[]? allowedQueues = null,
        CancellationToken ct = default)
    {
        await using var conn = await OpenConnectionAsync(ct);

        // CTE + UPDLOCK + READPAST = atomic lock acquisition without race conditions
        var queueFilter = allowedQueues?.Length > 0
            ? "AND h.[Queue] IN @Queues"
            : "";

        var sql = _q.FetchNextBatch.Replace("{QUEUE_FILTER}", queueFilter);

        return await conn.QueryAsync<JobHotEntity>(
            sql,
            new { Limit = batchSize, WorkerId = workerId, Queues = allowedQueues },
            ct);
    }

    public async ValueTask MarkAsProcessingAsync(string jobId, CancellationToken ct = default)
    {
        await using var conn = await OpenConnectionAsync(ct);
        await conn.ExecuteAsync(_q.MarkAsProcessing, new { Id = jobId }, ct);
    }

    public async ValueTask KeepAliveAsync(string jobId, CancellationToken ct = default)
    {
        await using var conn = await OpenConnectionAsync(ct);
        await conn.ExecuteAsync(_q.KeepAlive, new { Id = jobId }, ct);
    }

    public async ValueTask<JobHotEntity?> GetJobAsync(string jobId, CancellationToken ct = default)
    {
        await using var conn = await OpenConnectionAsync(ct);
        return await conn.QueryFirstOrDefaultAsync<JobHotEntity>(_q.GetJob, new { Id = jobId }, ct);
    }
    // ========================================================================
    // ATOMIC TRANSITIONS (Three Pillars)
    // ========================================================================

    public async ValueTask ArchiveSucceededAsync(string jobId, double? durationMs = null, CancellationToken ct = default)
    {
        await using var conn = await OpenConnectionAsync(ct);
        await conn.ExecuteAsync(_q.ArchiveSucceeded, new { Id = jobId, DurationMs = durationMs }, ct);
    }

    public async ValueTask ArchiveFailedAsync(string jobId, string errorDetails, CancellationToken ct = default)
    {
        await MoveToDLQAsync(jobId, FailureReason.MaxRetriesExceeded, errorDetails, ct);
    }

    public async ValueTask ArchiveCancelledAsync(string jobId, string? cancelledBy = null, CancellationToken ct = default)
    {
        var error = cancelledBy != null ? $"Cancelled by: {cancelledBy}" : "Cancelled by admin";
        await MoveToDLQAsync(jobId, FailureReason.Cancelled, error, ct);
    }

    public async ValueTask ArchiveZombieAsync(string jobId, CancellationToken ct = default)
    {
        await MoveToDLQAsync(jobId, FailureReason.Zombie, "Zombie: Worker heartbeat expired", ct);
    }

    private async ValueTask MoveToDLQAsync(string jobId, FailureReason reason, string errorDetails, CancellationToken ct)
    {
        await using var conn = await OpenConnectionAsync(ct);
        await conn.ExecuteAsync(_q.MoveToDLQ, new
        {
            Id = jobId,
            Reason = (int)reason,
            Error = errorDetails ?? "Unknown error (No details provided)"
        }, ct);
    }

    public async ValueTask ResurrectAsync(
        string jobId,
        JobDataUpdateDto? updates = null,
        string? resurrectedBy = null,
        CancellationToken ct = default)
    {
        await using var conn = await OpenConnectionAsync(ct);
        await conn.ExecuteAsync(_q.Resurrect, new
        {
            Id = jobId,
            NewPayload = updates?.Payload,
            NewTags = updates?.Tags,
            NewPriority = updates?.Priority,
            ResurrectedBy = resurrectedBy
        }, ct);
    }

    public async ValueTask<int> ResurrectBatchAsync(string[] jobIds, string? resurrectedBy = null, CancellationToken ct = default)
    {
        if (jobIds.Length == 0) return 0;

        await using var conn = await OpenConnectionAsync(ct);
        int total = 0;

        // Process in batches of 1000
        foreach (var batch in jobIds.Chunk(1000))
        {
            var affected = await conn.ExecuteAsync(
                _q.ResurrectBatch,
                new { Ids = batch, ResurrectedBy = resurrectedBy },
                ct);
            total += affected / 2; // Each job = 1 INSERT + 1 DELETE
        }

        return total;
    }

    // ========================================================================
    // RETRY LOGIC (Stays in Hot)
    // ========================================================================

    public async ValueTask RescheduleForRetryAsync(
        string jobId,
        DateTime scheduledAtUtc,
        int newAttemptCount,
        string lastError,
        CancellationToken ct = default)
    {
        await using var conn = await OpenConnectionAsync(ct);
        await conn.ExecuteAsync(_q.RescheduleForRetry, new
        {
            Id = jobId,
            Attempt = newAttemptCount,
            ScheduledAt = scheduledAtUtc
        }, ct);
    }

    // ========================================================================
    // DIVINE MODE (Admin Operations)
    // ========================================================================

    public async ValueTask<bool> UpdateJobDataAsync(
        string jobId,
        JobDataUpdateDto updates,
        string? modifiedBy = null,
        CancellationToken ct = default)
    {
        if (!updates.HasChanges) return false;

        await using var conn = await OpenConnectionAsync(ct);
        var affected = await conn.ExecuteAsync(_q.UpdateJobData, new
        {
            Id = jobId,
            updates.Payload,
            updates.Tags,
            updates.Priority,
            ModifiedBy = modifiedBy
        }, ct);

        return affected > 0;
    }

    public async ValueTask PurgeDLQAsync(string[] jobIds, CancellationToken ct = default)
    {
        if (jobIds.Length == 0) return;

        await using var conn = await OpenConnectionAsync(ct);
        await conn.ExecuteAsync(_q.PurgeDLQ, new { Ids = jobIds }, ct);
    }

    public async ValueTask<int> PurgeArchiveAsync(DateTime olderThan, CancellationToken ct = default)
    {
        await using var conn = await OpenConnectionAsync(ct);
        return await conn.ExecuteAsync(_q.PurgeArchive, new { CutOff = olderThan }, ct);
    }

    // ========================================================================
    // OBSERVABILITY (Dashboard)
    // ========================================================================

    public async ValueTask<StatsSummaryEntity> GetSummaryStatsAsync(CancellationToken ct = default)
    {
        await using var conn = await OpenConnectionAsync(ct);
        return await conn.QuerySingleAsync<StatsSummaryEntity>(_q.GetSummaryStats, null, ct);
    }

    public async ValueTask<IEnumerable<StatsSummaryEntity>> GetQueueStatsAsync(CancellationToken ct = default)
    {
        await using var conn = await OpenConnectionAsync(ct);
        return await conn.QueryAsync<StatsSummaryEntity>(_q.GetQueueStats, null, ct);
    }

    public async ValueTask<IEnumerable<JobHotEntity>> GetActiveJobsAsync(
        int limit = 100,
        JobStatus? statusFilter = null,
        string? queueFilter = null,
        string? searchTerm = null,
        CancellationToken ct = default)
    {
        await using var conn = await OpenConnectionAsync(ct);

        var where = "WHERE 1=1";
        if (statusFilter.HasValue) where += " AND [Status] = @Status";
        if (!string.IsNullOrEmpty(queueFilter)) where += " AND [Queue] = @Queue";
        if (!string.IsNullOrEmpty(searchTerm))
            where += " AND ([Id] LIKE @Search OR [Type] LIKE @Search OR [Tags] LIKE @Search)";

        var sql = _q.GetActiveJobs.Replace("{WHERE_CLAUSE}", where);

        return await conn.QueryAsync<JobHotEntity>(sql, new
        {
            Limit = limit,
            Status = statusFilter.HasValue ? (int)statusFilter.Value : (int?)null,
            Queue = queueFilter,
            Search = $"%{searchTerm}%"
        }, ct);
    }

    public async ValueTask<IEnumerable<JobArchiveEntity>> GetArchiveJobsAsync(
        int limit = 100,
        string? queueFilter = null,
        DateTime? fromDate = null,
        DateTime? toDate = null,
        string? tagFilter = null,
        CancellationToken ct = default)
    {
        await using var conn = await OpenConnectionAsync(ct);

        var where = "WHERE 1=1";
        if (!string.IsNullOrEmpty(queueFilter)) where += " AND [Queue] = @Queue";
        if (fromDate.HasValue) where += " AND [FinishedAtUtc] >= @FromDate";
        if (toDate.HasValue) where += " AND [FinishedAtUtc] <= @ToDate";
        if (!string.IsNullOrEmpty(tagFilter)) where += " AND [Tags] LIKE @TagFilter";

        var sql = _q.GetArchiveJobs.Replace("{WHERE_CLAUSE}", where);

        return await conn.QueryAsync<JobArchiveEntity>(sql, new
        {
            Limit = limit,
            Queue = queueFilter,
            FromDate = fromDate,
            ToDate = toDate,
            TagFilter = $"%{tagFilter}%"
        }, ct);
    }

    public async ValueTask<IEnumerable<JobDLQEntity>> GetDLQJobsAsync(
        int limit = 100,
        string? queueFilter = null,
        FailureReason? reasonFilter = null,
        string? searchTerm = null,
        CancellationToken ct = default)
    {
        await using var conn = await OpenConnectionAsync(ct);

        var where = "WHERE 1=1";
        if (!string.IsNullOrEmpty(queueFilter)) where += " AND [Queue] = @Queue";
        if (reasonFilter.HasValue) where += " AND [FailureReason] = @Reason";
        if (!string.IsNullOrEmpty(searchTerm))
            where += " AND ([Id] LIKE @Search OR [Type] LIKE @Search OR [Tags] LIKE @Search OR [ErrorDetails] LIKE @Search)";

        var sql = _q.GetDLQJobs.Replace("{WHERE_CLAUSE}", where);

        return await conn.QueryAsync<JobDLQEntity>(sql, new
        {
            Limit = limit,
            Queue = queueFilter,
            Reason = reasonFilter.HasValue ? (int)reasonFilter.Value : (int?)null,
            Search = $"%{searchTerm}%"
        }, ct);
    }

    public async ValueTask<JobArchiveEntity?> GetArchiveJobAsync(string jobId, CancellationToken ct = default)
    {
        await using var conn = await OpenConnectionAsync(ct);
        return await conn.QueryFirstOrDefaultAsync<JobArchiveEntity>(_q.GetArchiveJob, new { Id = jobId }, ct);
    }

    public async ValueTask<JobDLQEntity?> GetDLQJobAsync(string jobId, CancellationToken ct = default)
    {
        await using var conn = await OpenConnectionAsync(ct);
        return await conn.QueryFirstOrDefaultAsync<JobDLQEntity>(_q.GetDLQJob, new { Id = jobId }, ct);
    }

    // ========================================================================
    // QUEUE MANAGEMENT
    // ========================================================================

    public async ValueTask<IEnumerable<QueueEntity>> GetQueuesAsync(CancellationToken ct = default)
    {
        await using var conn = await OpenConnectionAsync(ct);
        return await conn.QueryAsync<QueueEntity>(_q.GetQueues, null, ct);
    }

    public async ValueTask SetQueuePausedAsync(string queueName, bool isPaused, CancellationToken ct = default)
    {
        await using var conn = await OpenConnectionAsync(ct);
        await conn.ExecuteAsync(_q.SetQueuePaused, new { Name = queueName, IsPaused = isPaused }, ct);
    }

    public async ValueTask SetQueueZombieTimeoutAsync(string queueName, int? timeoutSeconds, CancellationToken ct = default)
    {
        await using var conn = await OpenConnectionAsync(ct);
        await conn.ExecuteAsync(_q.SetQueueZombieTimeout, new { Name = queueName, Timeout = timeoutSeconds }, ct);
    }

    // ========================================================================
    // ZOMBIE DETECTION
    // ========================================================================

    public async ValueTask<int> ArchiveZombiesAsync(int globalTimeoutSeconds, CancellationToken ct = default)
    {
        await using var conn = await OpenConnectionAsync(ct);
        return await conn.ExecuteScalarAsync<int>(_q.ArchiveZombies, new { GlobalTimeout = globalTimeoutSeconds }, ct);
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Storage.SqlServer\SqlJobStorageOptions.cs
namespace ChokaQ.Storage.SqlServer;

public class SqlJobStorageOptions
{
    /// <summary>
    /// The connection string to the SQL Server database.
    /// </summary>
    public string ConnectionString { get; set; } = string.Empty;

    /// <summary>
    /// The schema name where tables and procedures will be created.
    /// Default: "chokaq".
    /// </summary>
    public string SchemaName { get; set; } = "chokaq";

    /// <summary>
    /// If true, the library will attempt to create the schema and tables at startup.
    /// WARNING: Requires 'CREATE SCHEMA' and 'CREATE TABLE' permissions.
    /// Recommended for Development, but use with caution in Production.
    /// Default: false.
    /// </summary>
    public bool AutoCreateSqlTable { get; set; } = false;

    /// <summary>
    /// The interval at which the worker polls the database for new jobs when queues are active.
    /// Default: 1 second.
    /// </summary>
    public TimeSpan PollingInterval { get; set; } = TimeSpan.FromSeconds(1);

    /// <summary>
    /// The interval to sleep when no active queues are found.
    /// Default: 5 seconds.
    /// </summary>
    public TimeSpan NoQueuesSleepInterval { get; set; } = TimeSpan.FromSeconds(5);
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Storage.SqlServer\SqlJobWorker.cs
using ChokaQ.Abstractions.Entities;
using ChokaQ.Abstractions.Enums;
using ChokaQ.Abstractions.Storage;
using ChokaQ.Abstractions.Workers;
using ChokaQ.Core.Concurrency;
using ChokaQ.Core.Processing;
using ChokaQ.Core.State;
using Microsoft.Extensions.Hosting;
using Microsoft.Extensions.Logging;
using System.Threading.Channels;

namespace ChokaQ.Storage.SqlServer;

/// <summary>
/// Worker implementing the "Prefetching Consumer" pattern for SQL Server.
/// Decouples DB fetching latency from Job Execution throughput using an elastic concurrency limiter.
/// 
/// Three Pillars Integration:
/// - Fetches from JobsHot table
/// - Archives to JobsArchive or JobsDLQ via StateManager
/// </summary>
public class SqlJobWorker : BackgroundService, IWorkerManager
{
    private readonly IJobStorage _storage;
    private readonly IJobProcessor _processor;
    private readonly IJobStateManager _stateManager;
    private readonly ILogger<SqlJobWorker> _logger;
    private readonly SqlJobStorageOptions _options;

    // Internal buffer: Decouples Fetching (IO Bound) from Processing (CPU Bound)
    private readonly Channel<JobHotEntity> _prefetchBuffer;

    // Encapsulates the logic for dynamic scaling (Permit Burning / Minting)
    private readonly ElasticSemaphore _concurrencyLimiter;

    /// <summary>
    /// Gets the number of currently executing jobs.
    /// </summary>
    public int ActiveWorkers => _concurrencyLimiter.RunningCount;

    /// <summary>
    /// Gets the maximum concurrency limit.
    /// </summary>
    public int TotalWorkers => _concurrencyLimiter.Capacity;

    // Delegate configuration to the central Processor
    public int MaxRetries
    {
        get => _processor.MaxRetries;
        set => _processor.MaxRetries = value;
    }

    public int RetryDelaySeconds
    {
        get => _processor.RetryDelaySeconds;
        set => _processor.RetryDelaySeconds = value;
    }

    public SqlJobWorker(
        IJobStorage storage,
        IJobProcessor processor,
        IJobStateManager stateManager,
        ILogger<SqlJobWorker> logger,
        SqlJobStorageOptions? options = null)
    {
        _storage = storage ?? throw new ArgumentNullException(nameof(storage));
        _processor = processor ?? throw new ArgumentNullException(nameof(processor));
        _stateManager = stateManager ?? throw new ArgumentNullException(nameof(stateManager));
        _logger = logger ?? throw new ArgumentNullException(nameof(logger));
        _options = options ?? new SqlJobStorageOptions();

        // Bounded Channel for Backpressure
        _prefetchBuffer = Channel.CreateBounded<JobHotEntity>(new BoundedChannelOptions(100)
        {
            FullMode = BoundedChannelFullMode.Wait,
            SingleWriter = true,
            SingleReader = false
        });

        // Initialize elastic semaphore with default capacity of 10
        _concurrencyLimiter = new ElasticSemaphore(10);
    }

    protected override async Task ExecuteAsync(CancellationToken stoppingToken)
    {
        _logger.LogInformation(
            "SQL Worker Starting. Strategy: Prefetch + ElasticSemaphore. Initial Capacity: {Capacity}",
            _concurrencyLimiter.Capacity);

        // Two independent long-running loops:
        var fetcherTask = Task.Factory.StartNew(
            () => FetcherLoopAsync(stoppingToken),
            TaskCreationOptions.LongRunning);

        var processorTask = Task.Factory.StartNew(
            () => ProcessorLoopAsync(stoppingToken),
            TaskCreationOptions.LongRunning);

        await Task.WhenAll(fetcherTask, processorTask);
    }

    /// <summary>
    /// The "Supplier". Keeps the local buffer full of work from JobsHot table.
    /// </summary>
    private async Task FetcherLoopAsync(CancellationToken ct)
    {
        var workerId = $"{Environment.MachineName}-{Guid.NewGuid().ToString()[..4]}";

        while (!ct.IsCancellationRequested)
        {
            try
            {
                // Wait for space in buffer
                await _prefetchBuffer.Writer.WaitToWriteAsync(ct);

                // Determine batch size based on buffer space
                int batchSize = Math.Min(20, 100 - _prefetchBuffer.Reader.Count);
                if (batchSize <= 0) batchSize = 1;

                // Get active queues
                var queues = await _storage.GetQueuesAsync(ct);
                var activeQueues = queues.Where(q => !q.IsPaused).Select(q => q.Name).ToArray();

                if (activeQueues.Length == 0)
                {
                    _logger.LogDebug("No active queues. Fetcher sleeping...");
                    await Task.Delay(_options.NoQueuesSleepInterval, ct);
                    continue;
                }

                // Atomic Fetch & Lock from Hot table
                var jobs = await _storage.FetchNextBatchAsync(workerId, batchSize, activeQueues, ct);

                if (!jobs.Any())
                {
                    await Task.Delay(_options.PollingInterval, ct);
                    continue;
                }

                foreach (var job in jobs)
                {
                    // Push to buffer - awaits if full (backpressure)
                    await _prefetchBuffer.Writer.WriteAsync(job, ct);
                }
            }
            catch (OperationCanceledException)
            {
                break;
            }
            catch (Exception ex)
            {
                _logger.LogError(ex, "Fetcher Loop crashed. Cooling down...");
                await Task.Delay(5000, ct);
            }
        }

        _logger.LogInformation("Fetcher Loop Stopped.");
    }

    /// <summary>
    /// The "Consumer". Orchestrates parallel execution limited by ElasticSemaphore.
    /// </summary>
    private async Task ProcessorLoopAsync(CancellationToken ct)
    {
        try
        {
            await foreach (var job in _prefetchBuffer.Reader.ReadAllAsync(ct))
            {
                await _concurrencyLimiter.WaitAsync(ct);

                _ = Task.Run(async () =>
                {
                    try
                    {
                        // Processor handles the full lifecycle including archiving
                        await _processor.ProcessJobAsync(
                            job.Id,
                            job.Type,
                            job.Payload ?? "{}",
                            "sql-worker",
                            job.AttemptCount,
                            job.CreatedBy,
                            ct);
                    }
                    catch (Exception ex)
                    {
                        _logger.LogError(ex, "Critical error in job dispatch wrapper for {JobId}.", job.Id);
                    }
                    finally
                    {
                        _concurrencyLimiter.Release();
                    }
                }, ct);
            }
        }
        catch (OperationCanceledException) { }
    }

    // --- Management Interface Implementation ---

    public void UpdateWorkerCount(int count)
    {
        _logger.LogInformation("Updating worker count to {Count}", count);
        _concurrencyLimiter.SetCapacity(count);
    }

    public async Task CancelJobAsync(string jobId)
    {
        // Try to cancel if running
        if (_processor is JobProcessor concreteProcessor)
        {
            concreteProcessor.CancelJob(jobId);
        }

        // Also archive to DLQ if still in Hot and Pending/Fetched
        var job = await _storage.GetJobAsync(jobId);
        if (job != null && (job.Status == JobStatus.Pending || job.Status == JobStatus.Fetched))
        {
            await _stateManager.ArchiveCancelledAsync(jobId, job.Type, job.Queue, "Admin cancellation");
        }
    }

    public async Task RestartJobAsync(string jobId)
    {
        // Check Hot table first
        var hotJob = await _storage.GetJobAsync(jobId);
        if (hotJob != null && hotJob.Status == JobStatus.Processing)
        {
            _logger.LogWarning("Cannot restart job {JobId}: still processing.", jobId);
            return;
        }

        // Check DLQ for resurrection
        var dlqJob = await _storage.GetDLQJobAsync(jobId);
        if (dlqJob != null)
        {
            _logger.LogInformation("Resurrecting job {JobId} from DLQ...", jobId);
            await _storage.ResurrectAsync(jobId, null, "Admin restart");
            return;
        }

        _logger.LogWarning("Cannot restart job {JobId}: not found in DLQ.", jobId);
    }

    public async Task SetJobPriorityAsync(string jobId, int priority)
    {
        var result = await _storage.UpdateJobDataAsync(
            jobId,
            new Abstractions.DTOs.JobDataUpdateDto(null, null, priority),
            "Admin");

        if (!result)
        {
            _logger.LogWarning("Cannot update priority for job {JobId}: not Pending or not found.", jobId);
        }
    }

    public override void Dispose()
    {
        _concurrencyLimiter.Dispose();
        base.Dispose();
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Storage.SqlServer\DataEngine\ParameterBuilder.cs
using Microsoft.Data.SqlClient;
using System.Collections;
using System.Reflection;
using System.Text;

namespace ChokaQ.Storage.SqlServer.DataEngine;

/// <summary>
/// Converts anonymous objects to SqlParameter arrays and handles IN clause expansion.
/// </summary>
internal static class ParameterBuilder
{
    /// <summary>
    /// Builds SqlParameter array from an anonymous object.
    /// Expands array properties for IN clauses.
    /// </summary>
    public static (SqlParameter[], string) BuildParameters(object? parameters, string sql)
    {
        if (parameters == null)
            return (Array.Empty<SqlParameter>(), sql);

        var paramList = new List<SqlParameter>();
        var modifiedSql = sql;

        var properties = parameters.GetType().GetProperties(BindingFlags.Public | BindingFlags.Instance);

        foreach (var prop in properties)
        {
            var value = prop.GetValue(parameters);
            var paramName = "@" + prop.Name;

            // Handle array/enumerable parameters (for IN clauses)
            if (value is IEnumerable enumerable and not string)
            {
                var (expandedParams, expandedSql) = ExpandArrayParameter(paramName, enumerable, modifiedSql);
                paramList.AddRange(expandedParams);
                modifiedSql = expandedSql;
            }
            else
            {
                // Regular parameter
                paramList.Add(new SqlParameter(paramName, value ?? DBNull.Value));
            }
        }

        return (paramList.ToArray(), modifiedSql);
    }

    private static (SqlParameter[], string) ExpandArrayParameter(string paramName, IEnumerable values, string sql)
    {
        var paramList = new List<SqlParameter>();
        var valueList = new List<object?>();

        foreach (var item in values)
        {
            valueList.Add(item);
        }

        if (valueList.Count == 0)
        {
            // Empty array - replace with (SELECT NULL WHERE 1=0) to ensure no matches
            var modifiedSql = sql.Replace(paramName, "(SELECT NULL WHERE 1=0)");
            return (Array.Empty<SqlParameter>(), modifiedSql);
        }

        // Generate @ParamName0, @ParamName1, etc.
        var parameterNames = new StringBuilder();
        for (int i = 0; i < valueList.Count; i++)
        {
            var indexedParamName = $"{paramName}{i}";
            paramList.Add(new SqlParameter(indexedParamName, valueList[i] ?? DBNull.Value));

            if (i > 0) parameterNames.Append(", ");
            parameterNames.Append(indexedParamName);
        }

        // Replace @ParamName with (@ParamName0, @ParamName1, ...)
        var expandedSql = sql.Replace(paramName, $"({parameterNames})");

        return (paramList.ToArray(), expandedSql);
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Storage.SqlServer\DataEngine\Queries.cs
namespace ChokaQ.Storage.SqlServer.DataEngine;

/// <summary>
/// Contains all SQL query templates for ChokaQ storage operations.
/// Queries are initialized once with schema name and cached for the application lifetime.
/// </summary>
internal sealed class Queries
{
    // ========================================================================
    // CORE OPERATIONS
    // ========================================================================

    public readonly string CheckIdempotency;
    public readonly string EnqueueJob;
    public readonly string FetchNextBatch;
    public readonly string MarkAsProcessing;
    public readonly string KeepAlive;
    public readonly string GetJob;

    // ========================================================================
    // ARCHIVE OPERATIONS
    // ========================================================================

    public readonly string ArchiveSucceeded;
    public readonly string MoveToDLQ;
    public readonly string Resurrect;
    public readonly string ResurrectBatch;
    public readonly string RescheduleForRetry;

    // ========================================================================
    // DIVINE MODE (Admin Operations)
    // ========================================================================

    public readonly string UpdateJobData;
    public readonly string PurgeDLQ;
    public readonly string PurgeArchive;

    // ========================================================================
    // OBSERVABILITY (Dashboard)
    // ========================================================================

    public readonly string GetSummaryStats;
    public readonly string GetQueueStats;
    public readonly string GetActiveJobs;
    public readonly string GetArchiveJobs;
    public readonly string GetArchiveJob;
    public readonly string GetDLQJobs;
    public readonly string GetDLQJob;

    // ========================================================================
    // QUEUE MANAGEMENT
    // ========================================================================

    public readonly string GetQueues;
    public readonly string SetQueuePaused;
    public readonly string SetQueueZombieTimeout;

    // ========================================================================
    // ZOMBIE DETECTION
    // ========================================================================

    public readonly string ArchiveZombies;

    public Queries(string schema)
    {
        // CORE OPERATIONS
        CheckIdempotency = $"SELECT [Id] FROM [{schema}].[JobsHot] WHERE [IdempotencyKey] = @Key";

        EnqueueJob = $@"
            INSERT INTO [{schema}].[JobsHot] 
            ([Id], [Queue], [Type], [Payload], [Tags], [IdempotencyKey], [Priority], [Status], 
             [AttemptCount], [ScheduledAtUtc], [CreatedAtUtc], [LastUpdatedUtc], [CreatedBy])
            VALUES 
            (@Id, @Queue, @Type, @Payload, @Tags, @IdempotencyKey, @Priority, 0,
             0, @ScheduledAt, SYSUTCDATETIME(), SYSUTCDATETIME(), @CreatedBy);
            
            -- Ensure queue exists in config
            IF NOT EXISTS (SELECT 1 FROM [{schema}].[Queues] WHERE [Name] = @Queue)
                INSERT INTO [{schema}].[Queues] ([Name], [IsPaused], [IsActive], [LastUpdatedUtc])
                VALUES (@Queue, 0, 1, SYSUTCDATETIME());
            
            -- Ensure stats row exists (MERGE for atomicity)
            MERGE [{schema}].[StatsSummary] AS target
            USING (SELECT @Queue AS Queue) AS source
            ON target.[Queue] = source.Queue
            WHEN NOT MATCHED THEN
                INSERT ([Queue], [SucceededTotal], [FailedTotal], [RetriedTotal])
                VALUES (@Queue, 0, 0, 0);";

        FetchNextBatch = $@"
            WITH CTE AS (
                SELECT TOP (@Limit) h.*
                FROM [{schema}].[JobsHot] h WITH (UPDLOCK, READPAST)
                LEFT JOIN [{schema}].[Queues] q ON q.[Name] = h.[Queue]
                WHERE h.[Status] = 0
                  AND (h.[ScheduledAtUtc] IS NULL OR h.[ScheduledAtUtc] <= SYSUTCDATETIME())
                  AND (q.[IsPaused] = 0 OR q.[IsPaused] IS NULL)
                  {{QUEUE_FILTER}}
                ORDER BY h.[Priority] DESC, ISNULL(h.[ScheduledAtUtc], h.[CreatedAtUtc]) ASC
            )
            UPDATE CTE 
            SET [Status] = 1,
                [WorkerId] = @WorkerId,
                [AttemptCount] = [AttemptCount] + 1,
                [LastUpdatedUtc] = SYSUTCDATETIME()
            OUTPUT inserted.*;";

        MarkAsProcessing = $@"
            UPDATE [{schema}].[JobsHot]
            SET [Status] = 2,
                [StartedAtUtc] = SYSUTCDATETIME(),
                [HeartbeatUtc] = SYSUTCDATETIME(),
                [LastUpdatedUtc] = SYSUTCDATETIME()
            WHERE [Id] = @Id";

        KeepAlive = $@"
            UPDATE [{schema}].[JobsHot]
            SET [HeartbeatUtc] = SYSUTCDATETIME(),
                [LastUpdatedUtc] = SYSUTCDATETIME()
            WHERE [Id] = @Id";

        GetJob = $"SELECT * FROM [{schema}].[JobsHot] WHERE [Id] = @Id";

        // ARCHIVE OPERATIONS
        ArchiveSucceeded = $@"
            DECLARE @Queue varchar(255);
            SELECT @Queue = [Queue] FROM [{schema}].[JobsHot] WHERE [Id] = @Id;

            -- 1. Archive to JobsArchive using OUTPUT from DELETE
            INSERT INTO [{schema}].[JobsArchive]
            ([Id], [Queue], [Type], [Payload], [Tags], [AttemptCount], [WorkerId], 
             [CreatedBy], [LastModifiedBy], [CreatedAtUtc], [StartedAtUtc], [FinishedAtUtc], [DurationMs])
            SELECT [Id], [Queue], [Type], [Payload], [Tags], [AttemptCount], [WorkerId],
                   [CreatedBy], [LastModifiedBy], [CreatedAtUtc], [StartedAtUtc], SYSUTCDATETIME(), @DurationMs
            FROM [{schema}].[JobsHot]
            WHERE [Id] = @Id;

            -- 2. Delete from Hot
            DELETE FROM [{schema}].[JobsHot] WHERE [Id] = @Id;

            -- 3. Update stats (MERGE for upsert)
            MERGE [{schema}].[StatsSummary] AS target
            USING (SELECT @Queue AS Queue) AS source
            ON target.[Queue] = source.Queue
            WHEN MATCHED THEN
                UPDATE SET [SucceededTotal] = [SucceededTotal] + 1,
                           [LastActivityUtc] = SYSUTCDATETIME()
            WHEN NOT MATCHED THEN
                INSERT ([Queue], [SucceededTotal], [FailedTotal], [RetriedTotal], [LastActivityUtc])
                VALUES (@Queue, 1, 0, 0, SYSUTCDATETIME());";

        MoveToDLQ = $@"
            DECLARE @Queue varchar(255);
            SELECT @Queue = [Queue] FROM [{schema}].[JobsHot] WHERE [Id] = @Id;

            IF @Queue IS NULL RETURN;

            -- 1. Insert into DLQ
            INSERT INTO [{schema}].[JobsDLQ]
            ([Id], [Queue], [Type], [Payload], [Tags], [FailureReason], [ErrorDetails], [AttemptCount],
             [WorkerId], [CreatedBy], [LastModifiedBy], [CreatedAtUtc], [FailedAtUtc])
            SELECT [Id], [Queue], [Type], [Payload], [Tags], @Reason, @Error, [AttemptCount],
                   [WorkerId], [CreatedBy], [LastModifiedBy], [CreatedAtUtc], SYSUTCDATETIME()
            FROM [{schema}].[JobsHot]
            WHERE [Id] = @Id;

            -- 2. Delete from Hot
            DELETE FROM [{schema}].[JobsHot] WHERE [Id] = @Id;

            -- 3. Update stats
            MERGE [{schema}].[StatsSummary] AS target
            USING (SELECT @Queue AS Queue) AS source
            ON target.[Queue] = source.Queue
            WHEN MATCHED THEN
                UPDATE SET [FailedTotal] = [FailedTotal] + 1,
                           [LastActivityUtc] = SYSUTCDATETIME()
            WHEN NOT MATCHED THEN
                INSERT ([Queue], [SucceededTotal], [FailedTotal], [RetriedTotal], [LastActivityUtc])
                VALUES (@Queue, 0, 1, 0, SYSUTCDATETIME());";

        Resurrect = $@"
            DECLARE @Queue varchar(255);
            SELECT @Queue = [Queue] FROM [{schema}].[JobsDLQ] WHERE [Id] = @Id;

            -- 1. Move to Hot (reset state)
            INSERT INTO [{schema}].[JobsHot]
            ([Id], [Queue], [Type], [Payload], [Tags], [Priority], [Status], [AttemptCount],
             [CreatedAtUtc], [LastUpdatedUtc], [CreatedBy], [LastModifiedBy])
            SELECT [Id], [Queue], [Type], 
                   ISNULL(@NewPayload, [Payload]), 
                   ISNULL(@NewTags, [Tags]), 
                   ISNULL(@NewPriority, 10), 
                   0, 0,
                   [CreatedAtUtc], SYSUTCDATETIME(), [CreatedBy], @ResurrectedBy
            FROM [{schema}].[JobsDLQ]
            WHERE [Id] = @Id;

            -- 2. Remove from DLQ
            DELETE FROM [{schema}].[JobsDLQ] WHERE [Id] = @Id;

            -- 3. Decrement failed stats
            UPDATE [{schema}].[StatsSummary]
            SET [FailedTotal] = CASE WHEN [FailedTotal] > 0 THEN [FailedTotal] - 1 ELSE 0 END,
                [LastActivityUtc] = SYSUTCDATETIME()
            WHERE [Queue] = @Queue;";

        ResurrectBatch = $@"
                -- Move batch to Hot
                INSERT INTO [{schema}].[JobsHot]
                ([Id], [Queue], [Type], [Payload], [Tags], [Priority], [Status], [AttemptCount],
                 [CreatedAtUtc], [LastUpdatedUtc], [CreatedBy], [LastModifiedBy])
                SELECT [Id], [Queue], [Type], [Payload], [Tags], 10, 0, 0,
                       [CreatedAtUtc], SYSUTCDATETIME(), [CreatedBy], @ResurrectedBy
                FROM [{schema}].[JobsDLQ]
                WHERE [Id] IN @Ids;

                -- Remove from DLQ
                DELETE FROM [{schema}].[JobsDLQ] WHERE [Id] IN @Ids;";

        RescheduleForRetry = $@"
            DECLARE @Queue varchar(255);
            SELECT @Queue = [Queue] FROM [{schema}].[JobsHot] WHERE [Id] = @Id;

            UPDATE [{schema}].[JobsHot]
            SET [Status] = 0,
                [AttemptCount] = @Attempt,
                [ScheduledAtUtc] = @ScheduledAt,
                [WorkerId] = NULL,
                [HeartbeatUtc] = NULL,
                [LastUpdatedUtc] = SYSUTCDATETIME()
            WHERE [Id] = @Id;

            -- Increment retry counter (MERGE for upsert)
            MERGE [{schema}].[StatsSummary] AS target
            USING (SELECT @Queue AS Queue) AS source
            ON target.[Queue] = source.Queue
            WHEN MATCHED THEN
                UPDATE SET [RetriedTotal] = [RetriedTotal] + 1,
                           [LastActivityUtc] = SYSUTCDATETIME()
            WHEN NOT MATCHED THEN
                INSERT ([Queue], [SucceededTotal], [FailedTotal], [RetriedTotal], [LastActivityUtc])
                VALUES (@Queue, 0, 0, 1, SYSUTCDATETIME());";

        // DIVINE MODE
        UpdateJobData = $@"
            UPDATE [{schema}].[JobsHot]
            SET [Payload] = ISNULL(@Payload, [Payload]),
                [Tags] = ISNULL(@Tags, [Tags]),
                [Priority] = ISNULL(@Priority, [Priority]),
                [LastModifiedBy] = @ModifiedBy,
                [LastUpdatedUtc] = SYSUTCDATETIME()
            WHERE [Id] = @Id AND [Status] = 0";

        PurgeDLQ = $"DELETE FROM [{schema}].[JobsDLQ] WHERE [Id] IN @Ids";

        PurgeArchive = $"DELETE FROM [{schema}].[JobsArchive] WHERE [FinishedAtUtc] < @CutOff";

        // OBSERVABILITY
        GetSummaryStats = $@"
            SELECT 
                CAST(NULL AS NVARCHAR(100)) AS [Queue],
                (SELECT COUNT(1) FROM [{schema}].[JobsHot] WHERE [Status] = 0) AS [Pending],
                (SELECT COUNT(1) FROM [{schema}].[JobsHot] WHERE [Status] = 1) AS [Fetched],
                (SELECT COUNT(1) FROM [{schema}].[JobsHot] WHERE [Status] = 2) AS [Processing],
                (SELECT ISNULL(SUM([SucceededTotal]), 0) FROM [{schema}].[StatsSummary]) AS [SucceededTotal],
                (SELECT ISNULL(SUM([FailedTotal]), 0) FROM [{schema}].[StatsSummary]) AS [FailedTotal],
                (SELECT ISNULL(SUM([RetriedTotal]), 0) FROM [{schema}].[StatsSummary]) AS [RetriedTotal],
                CAST(
                    (SELECT COUNT(1) FROM [{schema}].[JobsHot]) + 
                    (SELECT COUNT(1) FROM [{schema}].[JobsArchive]) + 
                    (SELECT COUNT(1) FROM [{schema}].[JobsDLQ]) 
                AS BIGINT) AS [Total],
                (SELECT MAX([LastActivityUtc]) FROM [{schema}].[StatsSummary]) AS [LastActivityUtc]";

        GetQueueStats = $@"
            SELECT 
                q.[Name] AS [Queue],
                (SELECT COUNT(1) FROM [{schema}].[JobsHot] WHERE [Queue] = q.[Name] AND [Status] = 0) AS [Pending],
                (SELECT COUNT(1) FROM [{schema}].[JobsHot] WHERE [Queue] = q.[Name] AND [Status] = 1) AS [Fetched],
                (SELECT COUNT(1) FROM [{schema}].[JobsHot] WHERE [Queue] = q.[Name] AND [Status] = 2) AS [Processing],
                ISNULL(s.[SucceededTotal], 0) AS [SucceededTotal],
                ISNULL(s.[FailedTotal], 0) AS [FailedTotal],
                ISNULL(s.[RetriedTotal], 0) AS [RetriedTotal],
                CAST(
                    (SELECT COUNT(1) FROM [{schema}].[JobsHot] WHERE [Queue] = q.[Name]) + 
                    (SELECT COUNT(1) FROM [{schema}].[JobsArchive] WHERE [Queue] = q.[Name]) + 
                    (SELECT COUNT(1) FROM [{schema}].[JobsDLQ] WHERE [Queue] = q.[Name])
                AS BIGINT) AS [Total],
                s.[LastActivityUtc]
            FROM [{schema}].[Queues] q
            LEFT JOIN [{schema}].[StatsSummary] s ON s.[Queue] = q.[Name]
            ORDER BY q.[Name]";

        GetActiveJobs = $@"
            SELECT TOP (@Limit) * 
            FROM [{schema}].[JobsHot] 
            {{WHERE_CLAUSE}}
            ORDER BY [CreatedAtUtc] DESC";

        GetArchiveJobs = $@"
            SELECT TOP (@Limit) * 
            FROM [{schema}].[JobsArchive] 
            {{WHERE_CLAUSE}}
            ORDER BY [FinishedAtUtc] DESC";

        GetArchiveJob = $"SELECT * FROM [{schema}].[JobsArchive] WHERE [Id] = @Id";

        GetDLQJobs = $@"
            SELECT TOP (@Limit) * 
            FROM [{schema}].[JobsDLQ] 
            {{WHERE_CLAUSE}}
            ORDER BY [FailedAtUtc] DESC";

        GetDLQJob = $"SELECT * FROM [{schema}].[JobsDLQ] WHERE [Id] = @Id";

        // QUEUE MANAGEMENT
        GetQueues = $@"
            SELECT q.[Name], q.[IsPaused], q.[IsActive], q.[ZombieTimeoutSeconds], q.[LastUpdatedUtc]
            FROM [{schema}].[Queues] q
            ORDER BY q.[Name]";

        SetQueuePaused = $@"
            MERGE [{schema}].[Queues] AS t
            USING (SELECT @Name AS Name) AS s ON (t.[Name] = s.Name)
            WHEN MATCHED THEN 
                UPDATE SET [IsPaused] = @IsPaused, [LastUpdatedUtc] = SYSUTCDATETIME()
            WHEN NOT MATCHED THEN 
                INSERT ([Name], [IsPaused], [IsActive], [LastUpdatedUtc]) 
                VALUES (@Name, @IsPaused, 1, SYSUTCDATETIME());";

        SetQueueZombieTimeout = $@"
            MERGE [{schema}].[Queues] AS t
            USING (SELECT @Name AS Name) AS s ON (t.[Name] = s.Name)
            WHEN MATCHED THEN 
                UPDATE SET [ZombieTimeoutSeconds] = @Timeout, [LastUpdatedUtc] = SYSUTCDATETIME()
            WHEN NOT MATCHED THEN 
                INSERT ([Name], [IsPaused], [IsActive], [ZombieTimeoutSeconds], [LastUpdatedUtc]) 
                VALUES (@Name, 0, 1, @Timeout, SYSUTCDATETIME());";

        // ZOMBIE DETECTION
        ArchiveZombies = $@"
            DECLARE @ZombieIds TABLE (Id varchar(50), Queue varchar(255));

            -- Find zombies (Processing or Fetched with expired heartbeat)
            INSERT INTO @ZombieIds (Id, Queue)
            SELECT h.[Id], h.[Queue]
            FROM [{schema}].[JobsHot] h
            LEFT JOIN [{schema}].[Queues] q ON q.[Name] = h.[Queue]
            WHERE h.[Status] IN (1, 2)
              AND DATEDIFF(SECOND, ISNULL(h.[HeartbeatUtc], h.[LastUpdatedUtc]), SYSUTCDATETIME()) 
                  > ISNULL(q.[ZombieTimeoutSeconds], @GlobalTimeout);

            -- Archive to DLQ
            INSERT INTO [{schema}].[JobsDLQ]
            ([Id], [Queue], [Type], [Payload], [Tags], [FailureReason], [ErrorDetails], [AttemptCount],
             [WorkerId], [CreatedBy], [LastModifiedBy], [CreatedAtUtc], [FailedAtUtc])
            SELECT h.[Id], h.[Queue], h.[Type], h.[Payload], h.[Tags], 
                   2, -- Zombie
                   'Zombie: Worker heartbeat expired',
                   h.[AttemptCount], h.[WorkerId], h.[CreatedBy], h.[LastModifiedBy], 
                   h.[CreatedAtUtc], SYSUTCDATETIME()
            FROM [{schema}].[JobsHot] h
            INNER JOIN @ZombieIds z ON z.Id = h.Id;

            -- Delete from Hot
            DELETE FROM [{schema}].[JobsHot] 
            WHERE [Id] IN (SELECT Id FROM @ZombieIds);

            -- Update stats per queue
            UPDATE s
            SET s.[FailedTotal] = s.[FailedTotal] + counts.ZombieCount,
                s.[LastActivityUtc] = SYSUTCDATETIME()
            FROM [{schema}].[StatsSummary] s
            INNER JOIN (
                SELECT Queue, COUNT(*) as ZombieCount FROM @ZombieIds GROUP BY Queue
            ) counts ON counts.Queue = s.[Queue];

            SELECT COUNT(*) FROM @ZombieIds;";
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Storage.SqlServer\DataEngine\SqlMapper.cs
using Microsoft.Data.SqlClient;

namespace ChokaQ.Storage.SqlServer.DataEngine;

/// <summary>
/// Extension methods for SqlConnection providing Dapper-like functionality.
/// </summary>
public static class SqlMapper
{
    /// <summary>
    /// Executes a query and returns multiple rows.
    /// </summary>
    public static async Task<IEnumerable<T>> QueryAsync<T>(
        this SqlConnection conn,
        string sql,
        object? parameters = null,
        CancellationToken ct = default)
    {
        var (sqlParams, modifiedSql) = ParameterBuilder.BuildParameters(parameters, sql);

        using var cmd = new SqlCommand(modifiedSql, conn);
        cmd.Parameters.AddRange(sqlParams);

        using var reader = await cmd.ExecuteReaderAsync(ct);
        var results = new List<T>();

        // Check if T is a primitive/value type
        var isPrimitive = IsPrimitiveType(typeof(T));

        while (await reader.ReadAsync(ct))
        {
            if (isPrimitive)
            {
                var value = reader.GetValue(0);
                results.Add(value == DBNull.Value ? default! : (T)Convert.ChangeType(value, typeof(T)));
            }
            else
            {
                results.Add(TypeMapper.MapRow<T>(reader));
            }
        }

        return results;
    }

    /// <summary>
    /// Executes a query and returns the first row or null.
    /// </summary>
    public static async Task<T?> QueryFirstOrDefaultAsync<T>(
        this SqlConnection conn,
        string sql,
        object? parameters = null,
        CancellationToken ct = default)
    {
        var (sqlParams, modifiedSql) = ParameterBuilder.BuildParameters(parameters, sql);

        using var cmd = new SqlCommand(modifiedSql, conn);
        cmd.Parameters.AddRange(sqlParams);

        using var reader = await cmd.ExecuteReaderAsync(ct);

        if (await reader.ReadAsync(ct))
        {
            // Handle primitive types (string, int, etc.)
            if (IsPrimitiveType(typeof(T)))
            {
                var value = reader.GetValue(0);
                return value == DBNull.Value ? default : (T)Convert.ChangeType(value, typeof(T));
            }

            // Handle complex types
            return TypeMapper.MapRow<T>(reader);
        }

        return default;
    }

    /// <summary>
    /// Executes a query and returns exactly one row. Throws if 0 or more than 1.
    /// </summary>
    public static async Task<T> QuerySingleAsync<T>(
        this SqlConnection conn,
        string sql,
        object? parameters = null,
        CancellationToken ct = default)
    {
        var (sqlParams, modifiedSql) = ParameterBuilder.BuildParameters(parameters, sql);

        using var cmd = new SqlCommand(modifiedSql, conn);
        cmd.Parameters.AddRange(sqlParams);

        using var reader = await cmd.ExecuteReaderAsync(ct);

        if (!await reader.ReadAsync(ct))
        {
            throw new InvalidOperationException("Sequence contains no elements");
        }

        T result;
        if (IsPrimitiveType(typeof(T)))
        {
            var value = reader.GetValue(0);
            result = value == DBNull.Value ? default! : (T)Convert.ChangeType(value, typeof(T));
        }
        else
        {
            result = TypeMapper.MapRow<T>(reader);
        }

        if (await reader.ReadAsync(ct))
        {
            throw new InvalidOperationException("Sequence contains more than one element");
        }

        return result;
    }

    /// <summary>
    /// Executes a command and returns the number of affected rows.
    /// </summary>
    public static async Task<int> ExecuteAsync(
        this SqlConnection conn,
        string sql,
        object? parameters = null,
        CancellationToken ct = default)
    {
        var (sqlParams, modifiedSql) = ParameterBuilder.BuildParameters(parameters, sql);

        using var cmd = new SqlCommand(modifiedSql, conn);
        cmd.Parameters.AddRange(sqlParams);

        return await cmd.ExecuteNonQueryAsync(ct);
    }

    /// <summary>
    /// Executes a query and returns a scalar value.
    /// </summary>
    public static async Task<T> ExecuteScalarAsync<T>(
        this SqlConnection conn,
        string sql,
        object? parameters = null,
        CancellationToken ct = default)
    {
        var (sqlParams, modifiedSql) = ParameterBuilder.BuildParameters(parameters, sql);

        using var cmd = new SqlCommand(modifiedSql, conn);
        cmd.Parameters.AddRange(sqlParams);

        var result = await cmd.ExecuteScalarAsync(ct);

        if (result == null || result == DBNull.Value)
        {
            return default!;
        }

        return (T)Convert.ChangeType(result, typeof(T));
    }

    private static bool IsPrimitiveType(Type type)
    {
        return type.IsPrimitive
            || type.IsValueType
            || type == typeof(string)
            || type == typeof(decimal)
            || type == typeof(DateTime)
            || type == typeof(DateTimeOffset)
            || type == typeof(TimeSpan)
            || type == typeof(Guid)
            || (Nullable.GetUnderlyingType(type) != null && IsPrimitiveType(Nullable.GetUnderlyingType(type)!));
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Storage.SqlServer\DataEngine\TypeMapper.cs
using System.Collections.Concurrent;
using System.Data;
using System.Reflection;

namespace ChokaQ.Storage.SqlServer.DataEngine;

/// <summary>
/// Maps SqlDataReader rows to typed objects using cached reflection.
/// </summary>
internal static class TypeMapper
{
    private static readonly ConcurrentDictionary<Type, PropertyInfo[]> _propertyCache = new();
    private static readonly ConcurrentDictionary<Type, ConstructorInfo?> _constructorCache = new();

    /// <summary>
    /// Maps a single row from SqlDataReader to type T.
    /// </summary>
    public static T MapRow<T>(IDataReader reader)
    {
        var type = typeof(T);
        var properties = GetProperties(type);

        // Try to find a suitable constructor
        var ctor = GetConstructor(type);

        T instance;
        if (ctor != null && ctor.GetParameters().Length > 0)
        {
            // Use constructor with parameters (for record types)
            instance = CreateInstanceViaConstructor<T>(reader, ctor, properties);
        }
        else
        {
            // Use parameterless constructor or FormatterServices for classes
            instance = CreateInstanceDefault<T>(type);
            PopulateProperties(instance, reader, properties);
        }

        return instance;
    }

    private static T CreateInstanceDefault<T>(Type type)
    {
        try
        {
            return (T)Activator.CreateInstance(type)!;
        }
        catch
        {
            // Fallback for types without parameterless constructor
            return (T)System.Runtime.CompilerServices.RuntimeHelpers.GetUninitializedObject(type);
        }
    }

    private static T CreateInstanceViaConstructor<T>(IDataReader reader, ConstructorInfo ctor, PropertyInfo[] properties)
    {
        var parameters = ctor.GetParameters();
        var args = new object?[parameters.Length];

        for (int i = 0; i < parameters.Length; i++)
        {
            var param = parameters[i];
            var property = Array.Find(properties, p =>
                string.Equals(p.Name, param.Name, StringComparison.OrdinalIgnoreCase));

            if (property != null)
            {
                // Find column by property name
                var value = GetColumnValue(reader, property.Name);
                args[i] = ConvertValue(value, param.ParameterType);
            }
            else
            {
                args[i] = param.HasDefaultValue ? param.DefaultValue : GetDefaultValue(param.ParameterType);
            }
        }

        return (T)ctor.Invoke(args);
    }

    private static void PopulateProperties<T>(T instance, IDataReader reader, PropertyInfo[] properties)
    {
        for (int i = 0; i < reader.FieldCount; i++)
        {
            var columnName = reader.GetName(i);
            var property = Array.Find(properties, p =>
                string.Equals(p.Name, columnName, StringComparison.OrdinalIgnoreCase));

            if (property != null && property.CanWrite)
            {
                var value = reader.GetValue(i);
                if (value != DBNull.Value)
                {
                    var convertedValue = ConvertValue(value, property.PropertyType);
                    property.SetValue(instance, convertedValue);
                }
            }
        }
    }

    private static object? GetColumnValue(IDataReader reader, string columnName)
    {
        for (int i = 0; i < reader.FieldCount; i++)
        {
            if (string.Equals(reader.GetName(i), columnName, StringComparison.OrdinalIgnoreCase))
            {
                var value = reader.GetValue(i);
                return value == DBNull.Value ? null : value;
            }
        }
        return null;
    }

    private static object? ConvertValue(object? value, Type targetType)
    {
        if (value == null || value == DBNull.Value)
            return GetDefaultValue(targetType);

        var targetBaseType = Nullable.GetUnderlyingType(targetType) ?? targetType;

        if (targetBaseType.IsEnum)
            return Enum.ToObject(targetBaseType, value);

        if (targetBaseType == value.GetType())
            return value;

        return Convert.ChangeType(value, targetBaseType);
    }

    private static object? GetDefaultValue(Type type)
    {
        return type.IsValueType ? Activator.CreateInstance(type) : null;
    }

    private static PropertyInfo[] GetProperties(Type type)
    {
        return _propertyCache.GetOrAdd(type, t =>
            t.GetProperties(BindingFlags.Public | BindingFlags.Instance));
    }

    private static ConstructorInfo? GetConstructor(Type type)
    {
        return _constructorCache.GetOrAdd(type, t =>
        {
            // First try parameterless
            var parameterless = t.GetConstructor(BindingFlags.Public | BindingFlags.Instance, null, Type.EmptyTypes, null);
            if (parameterless != null)
                return parameterless;

            // Then try to find constructor with most parameters (for records)
            var ctors = t.GetConstructors(BindingFlags.Public | BindingFlags.Instance);
            return ctors.OrderByDescending(c => c.GetParameters().Length).FirstOrDefault();
        });
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Storage.SqlServer\Scripts\CleanupProcTemplate.sql
-- ==========================================================
-- ChokaQ Cleanup Procedure Template
-- ==========================================================
-- Efficiently removes old job history using Batch Deletion logic.
-- This prevents transaction log explosion and table locking issues.
-- Note: Uses "CREATE OR ALTER" (requires SQL Server 2016+).
-- ==========================================================

CREATE OR ALTER PROCEDURE [{SCHEMA}].[sp_CleanupJobs]
    @SucceededRetentionDays int = 7,  -- Keep successful jobs for 1 week
    @FailedRetentionDays int = 30,    -- Keep failed jobs for 1 month (for debugging)
    @BatchSize int = 1000             -- Rows to delete per transaction
AS
BEGIN
    SET NOCOUNT ON;

    DECLARE @RowsAffected int;
    
    -- Calculate cutoff dates
    DECLARE @SucceededCutoff datetime2(7) = DATEADD(day, -@SucceededRetentionDays, SYSUTCDATETIME());
    DECLARE @FailedCutoff datetime2(7) = DATEADD(day, -@FailedRetentionDays, SYSUTCDATETIME());

    -- ======================================================
    -- 1. Cleanup SUCCEEDED (2) and CANCELLED (4) Jobs
    -- ======================================================
    SET @RowsAffected = 1;
    
    WHILE @RowsAffected > 0
    BEGIN
        BEGIN TRANSACTION;
        
        -- Delete in small batches to avoid locking the table for too long
        DELETE TOP (@BatchSize) 
        FROM [{SCHEMA}].[Jobs]
        WHERE (Status = 2 OR Status = 4) -- Succeeded or Cancelled
          AND FinishedAtUtc < @SucceededCutoff;
        
        SET @RowsAffected = @@ROWCOUNT;
        
        COMMIT TRANSACTION;
        
    END

    -- ======================================================
    -- 2. Cleanup FAILED (3) Jobs
    -- ======================================================
    SET @RowsAffected = 1;
    
    WHILE @RowsAffected > 0
    BEGIN
        BEGIN TRANSACTION;
        
        DELETE TOP (@BatchSize) 
        FROM [{SCHEMA}].[Jobs]
        WHERE Status = 3 -- Failed
          AND FinishedAtUtc < @FailedCutoff;
        
        SET @RowsAffected = @@ROWCOUNT;
        
        COMMIT TRANSACTION;
    END

    RETURN 0;
END
GO

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.Storage.SqlServer\Scripts\SchemaTemplate.sql
-- ============================================================================
-- PROJECT: ChokaQ — THREE PILLARS ARCHITECTURE
-- DESCRIPTION: High-performance schema for SQL Server.
-- OPTIMIZATIONS: PAGE Compression, Filtered Indexes, FillFactor 80.
-- ============================================================================
-- TABLES:
--   JobsHot      → Active jobs (Hot Data)
--   JobsArchive  → Succeeded jobs (History)
--   JobsDLQ      → Failed jobs (Dead Letter Queue)
--   StatsSummary → Pre-aggregated counters
--   Queues       → Queue configuration
-- ============================================================================

-- ============================================================================
-- 0. SCHEMA INITIALIZATION
-- ============================================================================
IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = '{SCHEMA}')
BEGIN
    EXEC('CREATE SCHEMA [{SCHEMA}]');
END
GO


-- ============================================================================
-- 1. HOT DATA TABLE (Active Jobs)
-- Optimized for high-frequency INSERT/UPDATE/DELETE cycles.
-- ============================================================================
IF OBJECT_ID(N'[{SCHEMA}].[JobsHot]', N'U') IS NULL 
BEGIN
    CREATE TABLE [{SCHEMA}].[JobsHot](
        [Id]             [varchar](50)    NOT NULL,
        [Queue]          [varchar](255)   NOT NULL,
        [Type]           [varchar](255)   NOT NULL,
        [Payload]        [nvarchar](max)  NULL,                                 -- NVARCHAR for Unicode safety
        [Tags]           [varchar](1000)  NULL,
        [IdempotencyKey] [varchar](255)   NULL,
        
        [Priority]       [int]            NOT NULL DEFAULT 10,
        [Status]         [int]            NOT NULL,                             -- 0:Pending, 1:Fetched, 2:Processing
        [AttemptCount]   [int]            NOT NULL DEFAULT 0,
        
        [WorkerId]       [varchar](100)   NULL,
        [HeartbeatUtc]   [datetime2](7)   NULL,
        
        [ScheduledAtUtc] [datetime2](7)   NULL,
        [CreatedAtUtc]   [datetime2](7)   NOT NULL,
        [StartedAtUtc]   [datetime2](7)   NULL,
        [LastUpdatedUtc] [datetime2](7)   NOT NULL,
        [CreatedBy]      [varchar](100)   NULL,
        [LastModifiedBy] [varchar](100)   NULL,

        CONSTRAINT [PK_{SCHEMA}_JobsHot] PRIMARY KEY CLUSTERED ([Id] ASC)
        WITH (DATA_COMPRESSION = PAGE, FILLFACTOR = 80)
    );
END
GO

-- 1a. Ultimate Fetch Index (The Engine)
-- Zero Key-Lookups, minimal size (filtered), prioritized sorting.
IF NOT EXISTS (SELECT * FROM sys.indexes WHERE name = 'IX_{SCHEMA}_JobsHot_Fetch' AND object_id = OBJECT_ID('[{SCHEMA}].[JobsHot]'))
BEGIN
    CREATE NONCLUSTERED INDEX [IX_{SCHEMA}_JobsHot_Fetch] 
    ON [{SCHEMA}].[JobsHot] ([Queue], [Priority] DESC, [ScheduledAtUtc]) 
    INCLUDE ([Id], [Type])
    WHERE [Status] = 0
    WITH (DATA_COMPRESSION = PAGE, FILLFACTOR = 80);
END
GO

-- 1b. Search Index for active jobs (Tags)
IF NOT EXISTS (SELECT * FROM sys.indexes WHERE name = 'IX_{SCHEMA}_JobsHot_Tags' AND object_id = OBJECT_ID('[{SCHEMA}].[JobsHot]'))
BEGIN
    CREATE NONCLUSTERED INDEX [IX_{SCHEMA}_JobsHot_Tags] 
    ON [{SCHEMA}].[JobsHot] ([Tags]) 
    WHERE [Tags] IS NOT NULL
    WITH (DATA_COMPRESSION = PAGE, FILLFACTOR = 80);
END
GO

-- 1c. Strict Idempotency Guard
IF NOT EXISTS (SELECT * FROM sys.indexes WHERE name = 'IX_{SCHEMA}_JobsHot_Idempotency' AND object_id = OBJECT_ID('[{SCHEMA}].[JobsHot]'))
BEGIN
    CREATE UNIQUE NONCLUSTERED INDEX [IX_{SCHEMA}_JobsHot_Idempotency] 
    ON [{SCHEMA}].[JobsHot] ([IdempotencyKey]) 
    WHERE [IdempotencyKey] IS NOT NULL
    WITH (DATA_COMPRESSION = PAGE, FILLFACTOR = 80);
END
GO

-- 1d. Queue Statistics Index (for GetQueuesAsync aggregation)
IF NOT EXISTS (SELECT * FROM sys.indexes WHERE name = 'IX_{SCHEMA}_JobsHot_QueueStats' AND object_id = OBJECT_ID('[{SCHEMA}].[JobsHot]'))
BEGIN
    CREATE NONCLUSTERED INDEX [IX_{SCHEMA}_JobsHot_QueueStats] 
    ON [{SCHEMA}].[JobsHot] ([Queue], [Status])
    INCLUDE ([Priority])
    WITH (DATA_COMPRESSION = PAGE, FILLFACTOR = 80);
END
GO


-- ============================================================================
-- 2. ARCHIVE TABLE (Success History)
-- Optimized for long-term storage and infrequent audit reads.
-- ============================================================================
IF OBJECT_ID(N'[{SCHEMA}].[JobsArchive]', N'U') IS NULL 
BEGIN
    CREATE TABLE [{SCHEMA}].[JobsArchive](
        [Id]             [varchar](50)    NOT NULL,
        [Queue]          [varchar](255)   NOT NULL,
        [Type]           [varchar](255)   NOT NULL,
        [Payload]        [nvarchar](max)  NULL,
        [Tags]           [varchar](1000)  NULL,
        [AttemptCount]   [int]            NOT NULL DEFAULT 1,
        [WorkerId]       [varchar](100)   NULL,
        [CreatedBy]      [varchar](100)   NULL,
        [LastModifiedBy] [varchar](100)   NULL,
        [CreatedAtUtc]   [datetime2](7)   NOT NULL,
        [StartedAtUtc]   [datetime2](7)   NULL,
        [FinishedAtUtc]  [datetime2](7)   NOT NULL,
        [DurationMs]     [float]          NULL,

        CONSTRAINT [PK_{SCHEMA}_JobsArchive] PRIMARY KEY CLUSTERED ([Id] ASC)
        WITH (DATA_COMPRESSION = PAGE)
    );
END
GO

-- 2a. Archive Date Index (Dashboard trends)
IF NOT EXISTS (SELECT * FROM sys.indexes WHERE name = 'IX_{SCHEMA}_JobsArchive_Date' AND object_id = OBJECT_ID('[{SCHEMA}].[JobsArchive]'))
BEGIN
    CREATE NONCLUSTERED INDEX [IX_{SCHEMA}_JobsArchive_Date] 
    ON [{SCHEMA}].[JobsArchive] ([FinishedAtUtc] DESC)
    INCLUDE ([Queue], [Type], [DurationMs])
    WITH (DATA_COMPRESSION = PAGE);
END
GO

-- 2b. Archive Tags Search
IF NOT EXISTS (SELECT * FROM sys.indexes WHERE name = 'IX_{SCHEMA}_JobsArchive_Tags' AND object_id = OBJECT_ID('[{SCHEMA}].[JobsArchive]'))
BEGIN
    CREATE NONCLUSTERED INDEX [IX_{SCHEMA}_JobsArchive_Tags] 
    ON [{SCHEMA}].[JobsArchive] ([Tags]) 
    WHERE [Tags] IS NOT NULL
    WITH (DATA_COMPRESSION = PAGE);
END
GO

-- 2c. Archive Queue Filter (for "show history of queue X")
IF NOT EXISTS (SELECT * FROM sys.indexes WHERE name = 'IX_{SCHEMA}_JobsArchive_Queue' AND object_id = OBJECT_ID('[{SCHEMA}].[JobsArchive]'))
BEGIN
    CREATE NONCLUSTERED INDEX [IX_{SCHEMA}_JobsArchive_Queue] 
    ON [{SCHEMA}].[JobsArchive] ([Queue], [FinishedAtUtc] DESC)
    WITH (DATA_COMPRESSION = PAGE);
END
GO


-- ============================================================================
-- 3. DEAD LETTER QUEUE (Failed Jobs)
-- Stores jobs that exhausted retries, were cancelled, or became zombies.
-- Supports manual review, resurrection, and operational analytics.
-- ============================================================================
IF OBJECT_ID(N'[{SCHEMA}].[JobsDLQ]', N'U') IS NULL 
BEGIN
    CREATE TABLE [{SCHEMA}].[JobsDLQ](
        [Id]             [varchar](50)    NOT NULL,
        [Queue]          [varchar](255)   NOT NULL,
        [Type]           [varchar](255)   NOT NULL,
        [Payload]        [nvarchar](max)  NULL,
        [Tags]           [varchar](1000)  NULL,
        
        [FailureReason]  [int]            NOT NULL,                             -- 0:MaxRetries, 1:Cancelled, 2:Zombie, 3:CircuitBreaker, 4:Rejected
        [ErrorDetails]   [nvarchar](max)  NULL,
        [AttemptCount]   [int]            NOT NULL,
        
        [WorkerId]       [varchar](100)   NULL,
        [CreatedBy]      [varchar](100)   NULL,
        [LastModifiedBy] [varchar](100)   NULL,
        [CreatedAtUtc]   [datetime2](7)   NOT NULL,
        [FailedAtUtc]    [datetime2](7)   NOT NULL,

        CONSTRAINT [PK_{SCHEMA}_JobsDLQ] PRIMARY KEY CLUSTERED ([Id] ASC)
        WITH (DATA_COMPRESSION = PAGE)
    );
END
GO

-- 3a. DLQ Date Index (Dashboard: recent failures)
IF NOT EXISTS (SELECT * FROM sys.indexes WHERE name = 'IX_{SCHEMA}_JobsDLQ_Date' AND object_id = OBJECT_ID('[{SCHEMA}].[JobsDLQ]'))
BEGIN
    CREATE NONCLUSTERED INDEX [IX_{SCHEMA}_JobsDLQ_Date] 
    ON [{SCHEMA}].[JobsDLQ] ([FailedAtUtc] DESC)
    INCLUDE ([Queue], [Type], [FailureReason], [AttemptCount])
    WITH (DATA_COMPRESSION = PAGE);
END
GO

-- 3b. DLQ Tags Search (Support investigations)
IF NOT EXISTS (SELECT * FROM sys.indexes WHERE name = 'IX_{SCHEMA}_JobsDLQ_Tags' AND object_id = OBJECT_ID('[{SCHEMA}].[JobsDLQ]'))
BEGIN
    CREATE NONCLUSTERED INDEX [IX_{SCHEMA}_JobsDLQ_Tags] 
    ON [{SCHEMA}].[JobsDLQ] ([Tags]) 
    WHERE [Tags] IS NOT NULL
    WITH (DATA_COMPRESSION = PAGE);
END
GO

-- 3c. DLQ Queue Filter
IF NOT EXISTS (SELECT * FROM sys.indexes WHERE name = 'IX_{SCHEMA}_JobsDLQ_Queue' AND object_id = OBJECT_ID('[{SCHEMA}].[JobsDLQ]'))
BEGIN
    CREATE NONCLUSTERED INDEX [IX_{SCHEMA}_JobsDLQ_Queue] 
    ON [{SCHEMA}].[JobsDLQ] ([Queue], [FailedAtUtc] DESC)
    WITH (DATA_COMPRESSION = PAGE);
END
GO

-- 3d. DLQ Failure Reason Filter (Analytics: show all zombies, all cancelled, etc.)
IF NOT EXISTS (SELECT * FROM sys.indexes WHERE name = 'IX_{SCHEMA}_JobsDLQ_Reason' AND object_id = OBJECT_ID('[{SCHEMA}].[JobsDLQ]'))
BEGIN
    CREATE NONCLUSTERED INDEX [IX_{SCHEMA}_JobsDLQ_Reason] 
    ON [{SCHEMA}].[JobsDLQ] ([FailureReason], [FailedAtUtc] DESC)
    INCLUDE ([Queue], [Type])
    WITH (DATA_COMPRESSION = PAGE);
END
GO


-- ============================================================================
-- 4. STATISTICS TABLE (Fast Monitoring)
-- Provides instant O(1) dashboard metrics without scanning job tables.
-- ============================================================================
IF OBJECT_ID(N'[{SCHEMA}].[StatsSummary]', N'U') IS NULL 
BEGIN
    CREATE TABLE [{SCHEMA}].[StatsSummary](
        [Queue]           [varchar](255)   NOT NULL,
        [SucceededTotal]  [bigint]         NOT NULL DEFAULT 0,
        [FailedTotal]     [bigint]         NOT NULL DEFAULT 0,
        [RetriedTotal]    [bigint]         NOT NULL DEFAULT 0,
        [LastActivityUtc] [datetime2](7)   NULL,
        
        CONSTRAINT [PK_{SCHEMA}_StatsSummary] PRIMARY KEY CLUSTERED ([Queue] ASC)
    ) WITH (DATA_COMPRESSION = PAGE);
END
GO

-- 4a. Seed Default Statistics
IF NOT EXISTS (SELECT 1 FROM [{SCHEMA}].[StatsSummary] WHERE [Queue] = 'default')
BEGIN
    INSERT INTO [{SCHEMA}].[StatsSummary] ([Queue], [SucceededTotal], [FailedTotal], [RetriedTotal], [LastActivityUtc])
    VALUES ('default', 0, 0, 0, SYSUTCDATETIME());
END
GO


-- ============================================================================
-- 5. QUEUES CONFIGURATION (Control Plane)
-- Runtime circuit breakers and visibility settings.
-- ============================================================================
IF OBJECT_ID(N'[{SCHEMA}].[Queues]', N'U') IS NULL 
BEGIN
    CREATE TABLE [{SCHEMA}].[Queues](
        [Name]                 [varchar](255)   NOT NULL,
        [IsPaused]             [bit]            NOT NULL DEFAULT 0,
        [IsActive]             [bit]            NOT NULL DEFAULT 1,
        [ZombieTimeoutSeconds] [int]            NULL,
        [LastUpdatedUtc]       [datetime2](7)   NOT NULL,
        
        CONSTRAINT [PK_{SCHEMA}_Queues] PRIMARY KEY CLUSTERED ([Name] ASC)
    ) WITH (DATA_COMPRESSION = PAGE);
END
GO

-- 5a. Seed Default Configuration
IF NOT EXISTS (SELECT 1 FROM [{SCHEMA}].[Queues] WHERE [Name] = 'default')
BEGIN
    INSERT INTO [{SCHEMA}].[Queues] ([Name], [IsPaused], [IsActive], [ZombieTimeoutSeconds], [LastUpdatedUtc])
    VALUES ('default', 0, 1, NULL, SYSUTCDATETIME());
END
GO

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\ChokaQ.TheDeck.csproj
<Project Sdk="Microsoft.NET.Sdk.Razor">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <Nullable>enable</Nullable>
    <ImplicitUsings>enable</ImplicitUsings>
  </PropertyGroup>


  <ItemGroup>
    <SupportedPlatform Include="browser" />
  </ItemGroup>

  <ItemGroup>

    <FrameworkReference Include="Microsoft.AspNetCore.App" />
  </ItemGroup>

  <ItemGroup>
    <Folder Include="wwwroot\" />
  </ItemGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.AspNetCore.SignalR.Client" Version="10.0.1" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\ChokaQ.Abstractions\ChokaQ.Abstractions.csproj" />
    <ProjectReference Include="..\ChokaQ.Core\ChokaQ.Core.csproj" />
  </ItemGroup>

</Project>

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\ChokaQTheDeckOptions.cs
namespace ChokaQ.TheDeck;

public class ChokaQTheDeckOptions
{
    public string RoutePrefix { get; set; } = "/chokaq";
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\_Imports.razor
@using Microsoft.AspNetCore.Components.Web
@using Microsoft.AspNetCore.Components.Web.Virtualization
@using Microsoft.AspNetCore.SignalR.Client

/* -- GLOBAL USINGS FOR UI -- */
@using ChokaQ.TheDeck.UI.Layout
@using ChokaQ.TheDeck.UI.Pages
@using ChokaQ.TheDeck.UI.Components
/* Если используем Feature Folders, можно добавить и их,
   либо прописывать локально в родительских компонентах */

/* -- MODELS & LOGIC -- */
@using ChokaQ.TheDeck.Models
@using ChokaQ.Abstractions
@using ChokaQ.Abstractions.Enums

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\Extensions\ChokaQTheDeckExtensions.cs
using ChokaQ.Abstractions.Notifications;
using ChokaQ.TheDeck.Components.Layout;
using ChokaQ.TheDeck.Hubs;
using ChokaQ.TheDeck.Services;
using Microsoft.AspNetCore.Builder;
using Microsoft.Extensions.DependencyInjection;

namespace ChokaQ.TheDeck.Extensions;

public static class ChokaQTheDeckExtensions
{
    public static IServiceCollection AddChokaQTheDeck(
        this IServiceCollection services,
        Action<ChokaQTheDeckOptions>? configure = null)
    {
        var options = new ChokaQTheDeckOptions();
        configure?.Invoke(options);
        services.AddSingleton(options);

        services.AddRazorComponents()
                .AddInteractiveServerComponents();

        services.AddAntiforgery();
        services.AddSignalR();

        services.AddSingleton<IChokaQNotifier, ChokaQSignalRNotifier>();

        return services;
    }

    public static WebApplication MapChokaQTheDeck(this WebApplication app)
    {
        var options = app.Services.GetRequiredService<ChokaQTheDeckOptions>();
        var path = options.RoutePrefix;

        if (!path.StartsWith("/")) path = "/" + path;
        path = path.TrimEnd('/');

        app.UseStaticFiles();
        app.UseAntiforgery();

        app.MapHub<ChokaQHub>($"{path}/hub");

        var dashboardGroup = app.MapGroup(path);
        dashboardGroup.MapRazorComponents<TheDeckHost>()
                      .AddInteractiveServerRenderMode();

        return app;
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\Hubs\ChokaQHub.cs
using ChokaQ.Abstractions.DTOs;
using ChokaQ.Abstractions.Storage;
using ChokaQ.Abstractions.Workers;
using Microsoft.AspNetCore.SignalR;
using Microsoft.Extensions.Logging;

namespace ChokaQ.TheDeck.Hubs;

/// <summary>
/// SignalR Hub for The Deck UI.
/// Provides real-time bidirectional communication and command handling.
/// </summary>
public class ChokaQHub : Hub
{
    private readonly IWorkerManager _workerManager;
    private readonly IJobStorage _storage;
    private readonly ILogger<ChokaQHub> _logger;

    public ChokaQHub(
        IWorkerManager workerManager,
        IJobStorage storage,
        ILogger<ChokaQHub> logger)
    {
        _workerManager = workerManager;
        _storage = storage;
        _logger = logger;
    }

    public async Task CancelJob(string jobId)
    {
        _logger.LogInformation("TheDeck: CancelJob requested for {JobId}", jobId);
        await _workerManager.CancelJobAsync(jobId);
    }

    public async Task RestartJob(string jobId)
    {
        _logger.LogInformation("TheDeck: RestartJob requested for {JobId}", jobId);
        await _workerManager.RestartJobAsync(jobId);
    }

    public async Task ResurrectJob(string jobId, string? newPayload = null, int? newPriority = null)
    {
        _logger.LogInformation("TheDeck: ResurrectJob requested for {JobId}", jobId);
        var updates = new JobDataUpdateDto(newPayload, null, newPriority);
        await _storage.ResurrectAsync(jobId, updates.HasChanges ? updates : null, "TheDeck Admin");
    }

    public async Task ToggleQueue(string queueName, bool pause)
    {
        _logger.LogInformation("TheDeck: ToggleQueue {Queue} -> Paused={Pause}", queueName, pause);
        await _storage.SetQueuePausedAsync(queueName, pause);
    }

    public async Task SetPriority(string jobId, int priority)
    {
        _logger.LogInformation("TheDeck: SetPriority {JobId} -> {Priority}", jobId, priority);
        await _workerManager.SetJobPriorityAsync(jobId, priority);
    }

    public async Task UpdateQueueTimeout(string queueName, int? timeoutSeconds)
    {
        _logger.LogInformation("TheDeck: UpdateQueueTimeout {Queue} -> {Timeout}s", queueName, timeoutSeconds);
        await _storage.SetQueueZombieTimeoutAsync(queueName, timeoutSeconds);
    }

    public async Task PurgeDLQ(string[] jobIds)
    {
        _logger.LogWarning("TheDeck: PurgeDLQ requested for {Count} jobs", jobIds.Length);
        await _storage.PurgeDLQAsync(jobIds);
    }

    public async Task<bool> EditJob(string jobId, string? newPayload, string? newTags, int? newPriority)
    {
        _logger.LogInformation("TheDeck: EditJob requested for {JobId}", jobId);
        var updates = new JobDataUpdateDto(newPayload, newTags, newPriority);
        return await _storage.UpdateJobDataAsync(jobId, updates, "TheDeck Admin");
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\Models\JobViewModel.cs
using ChokaQ.Abstractions.Enums;

namespace ChokaQ.TheDeck.Models;

public class JobViewModel
{
    public string Id { get; set; } = string.Empty;
    public string Queue { get; set; } = "default";
    public string Type { get; set; } = string.Empty;
    public JobStatus Status { get; set; }
    public int Attempts { get; set; }
    public int Priority { get; set; }

    public DateTime AddedAt { get; set; }
    public TimeSpan? Duration { get; set; }
    public int Progress { get; set; } = 0;
    public string? CreatedBy { get; set; }
    public DateTime? StartedAtUtc { get; set; }

    public string Payload { get; set; } = "{}";
    public string? ErrorDetails { get; set; }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\Models\LogEntry.cs
namespace ChokaQ.TheDeck.Models;

public record LogEntry(DateTime Timestamp, string Message, string Level = "Info");

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\Services\ChokaQSignalRNotifier.cs
using ChokaQ.Abstractions.DTOs;
using ChokaQ.Abstractions.Notifications;
using ChokaQ.TheDeck.Hubs;
using Microsoft.AspNetCore.SignalR;

namespace ChokaQ.TheDeck.Services;

/// <summary>
/// SignalR implementation of IChokaQNotifier for The Deck UI updates.
/// </summary>
internal class ChokaQSignalRNotifier(IHubContext<ChokaQHub> hubContext) : IChokaQNotifier
{
    public async Task NotifyJobUpdatedAsync(JobUpdateDto update)
    {
        await hubContext.Clients.All.SendAsync("JobUpdated", update);
    }

    public async Task NotifyJobProgressAsync(string jobId, int percentage)
    {
        await hubContext.Clients.All.SendAsync("JobProgress", jobId, percentage);
    }

    public async Task NotifyJobArchivedAsync(string jobId, string queue)
    {
        await hubContext.Clients.All.SendAsync("JobArchived", jobId, queue);
    }

    public async Task NotifyJobFailedAsync(string jobId, string queue, string reason)
    {
        await hubContext.Clients.All.SendAsync("JobFailed", jobId, queue, reason);
    }

    public async Task NotifyJobResurrectedAsync(string jobId, string queue)
    {
        await hubContext.Clients.All.SendAsync("JobResurrected", jobId, queue);
    }

    public async Task NotifyJobsPurgedAsync(string[] jobIds, string source)
    {
        await hubContext.Clients.All.SendAsync("JobsPurged", jobIds, source);
    }

    public async Task NotifyQueueStateChangedAsync(string queueName, bool isPaused)
    {
        await hubContext.Clients.All.SendAsync("QueueStateChanged", queueName, isPaused);
    }

    public async Task NotifyStatsUpdatedAsync()
    {
        await hubContext.Clients.All.SendAsync("StatsUpdated");
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\UI\Components\Circuits\Circuits.razor
@using ChokaQ.Abstractions.Enums

<div class="circuits-container">
    <div class="section-title">System Health</div>

    @if (Breakers == null || !Breakers.Any())
    {
        <div class="circuits-empty">
            ALL SYSTEMS NOMINAL
        </div>
    }
    else
    {
        <div class="circuits-grid">
            @foreach (var circuit in Breakers)
            {
                <div class="circuit-item @GetCircuitClass(circuit.Status)">
                    <div class="circuit-name" title="@circuit.JobType">
                        @FormatName(circuit.JobType)
                    </div>

                    <div class="circuit-meta">
                        <span class="status-label">@GetStatusLabel(circuit.Status)</span>

                        @if (circuit.Status == CircuitStatus.Open && circuit.ResetAtUtc.HasValue)
                        {
                            <span class="timer-text">@GetTimeRemaining(circuit.ResetAtUtc.Value)</span>
                        }
                        else
                        {
                            <span style="opacity: 0.7;">@circuit.Status.ToString().ToUpper()</span>
                        }
                    </div>
                </div>
            }
        </div>
    }
</div>

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\UI\Components\Circuits\Circuits.razor.cs
using ChokaQ.Abstractions.DTOs;
using ChokaQ.Abstractions.Enums;
using Microsoft.AspNetCore.Components;

namespace ChokaQ.TheDeck.UI.Components.Circuits;

public partial class Circuits : IDisposable
{
    [Parameter]
    public IEnumerable<CircuitStatsDto> Breakers { get; set; } = Enumerable.Empty<CircuitStatsDto>();

    private System.Threading.Timer? _timer;

    protected override void OnInitialized()
    {
        // Local timer for UI countdown
        _timer = new System.Threading.Timer(_ =>
        {
            // Only refresh if there is an open circuit that needs countdown update
            if (Breakers != null && Breakers.Any(c => c.Status == CircuitStatus.Open))
            {
                InvokeAsync(StateHasChanged);
            }
        }, null, 1000, 1000);
    }

    private string GetTimeRemaining(DateTime resetAt)
    {
        var remaining = resetAt - DateTime.UtcNow;
        if (remaining.TotalSeconds <= 0) return "READY";
        return $"{remaining.TotalSeconds:F1}s";
    }

    private string FormatName(string fullName) => fullName?.Split('.').Last() ?? "Unknown";

    // CSS Class Helpers
    private string GetCircuitClass(CircuitStatus status) => status switch
    {
        CircuitStatus.Open => "circuit-open",
        CircuitStatus.HalfOpen => "circuit-half",
        _ => "circuit-closed"
    };

    private string GetStatusLabel(CircuitStatus status) => status switch
    {
        CircuitStatus.Open => "[OPEN]",
        CircuitStatus.HalfOpen => "[HALF]",
        CircuitStatus.Closed => "[OK]",
        _ => "[?]"
    };

    public void Dispose()
    {
        _timer?.Dispose();
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\UI\Components\Circuits\Circuits.razor.css
.circuits-container {
    height: 100%;
    display: flex;
    flex-direction: column;
}

.section-title {
    font-size: 0.75rem;
    font-weight: bold;
    opacity: 0.7;
    margin-bottom: 0.5rem;
    text-transform: uppercase;
    color: var(--deck-text-color);
}

.circuits-empty {
    flex: 1;
    display: flex;
    align-items: center;
    justify-content: center;
    opacity: 0.5;
    font-size: 0.85rem;
    color: var(--deck-text-color);
}

.circuits-grid {
    display: flex;
    flex-wrap: wrap;
    gap: 0.5rem;
    overflow-y: auto;
}

.circuit-item {
    background: var(--sector-bg);
    border: 1px solid var(--sector-border-color);
    padding: 0.5rem;
    min-width: 140px;
    flex: 1;
    font-family: var(--deck-font-family);
    transition: all 0.2s;
}

.circuit-name {
    font-size: 0.85rem;
    font-weight: bold;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
    color: var(--deck-text-color);
}

.circuit-meta {
    font-size: 0.75rem;
    display: flex;
    justify-content: space-between;
    margin-top: 0.2rem;
}

.status-label {
    font-weight: bold;
}

/* Status variants */
.circuit-closed {
    border-color: var(--sector-border-color);
}

    .circuit-closed .status-label {
        color: var(--deck-success);
    }

.circuit-open {
    border-color: var(--deck-danger);
    background: rgba(220, 53, 69, 0.1);
}

    .circuit-open .status-label {
        color: var(--deck-danger);
    }

.circuit-half {
    border-color: var(--deck-warning);
    background: rgba(255, 193, 7, 0.1);
}

    .circuit-half .status-label {
        color: var(--deck-warning);
    }

.timer-text {
    color: var(--deck-danger);
    font-family: monospace;
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\UI\Components\ConsoleLog\ConsoleLog.razor
<div class="console-container">
    <div class="console-header">System Console</div>

    <div class="console-list">
        @if (Logs.Count == 0)
        {
            <div class="console-empty">NO ACTIVE LOGS</div>
        }
        else
        {
            @foreach (var log in Logs)
            {
                <div class="log-line">
                    <span class="log-timestamp">@log.Timestamp.ToString("HH:mm:ss")</span>
                    <span class="log-message level-@log.Level.ToLower()">@log.Message</span>
                </div>
            }
            <div @ref="_bottomAnchor"></div>
        }
    </div>
</div>

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\UI\Components\ConsoleLog\ConsoleLog.razor.cs
using ChokaQ.TheDeck.Models;
using Microsoft.AspNetCore.Components;
using Microsoft.JSInterop;

namespace ChokaQ.TheDeck.UI.Components.ConsoleLog;

public partial class ConsoleLog
{
    [Inject]
    public required IJSRuntime JSRuntime { get; set; }

    [Parameter]
    public List<LogEntry> Logs { get; set; } = new();

    private ElementReference _bottomAnchor;
    private int _lastCount = 0;

    protected override async Task OnAfterRenderAsync(bool firstRender)
    {
        // Auto-scroll logic: triggered only when new logs arrive
        if (Logs.Count > _lastCount)
        {
            _lastCount = Logs.Count;
            try
            {
                await JSRuntime.InvokeVoidAsync("deck.scrollToBottom", _bottomAnchor);
            }
            catch
            {
                // Ignore JS disconnected errors
            }
        }
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\UI\Components\ConsoleLog\ConsoleLog.razor.css
.console-container {
    height: 100%;
    display: flex;
    flex-direction: column;
    overflow: hidden;
}

.console-header {
    font-size: 0.75rem;
    font-weight: bold;
    opacity: 0.7;
    margin-bottom: 0.5rem;
    text-transform: uppercase;
    flex-shrink: 0;
    color: var(--deck-text-color);
}

.console-list {
    flex: 1;
    overflow-y: auto;
    font-family: 'Consolas', 'Monaco', monospace; /* Fallback defined in deck.css var, but safe to enforce here */
    font-size: 0.8rem;
    padding-right: 0.5rem;
}

.console-empty {
    opacity: 0.3;
    padding: 1rem;
    text-align: center;
    color: var(--deck-text-color);
}

.log-line {
    display: flex;
    gap: 0.75rem;
    padding: 0.1rem 0;
    border-bottom: 1px solid rgba(255, 255, 255, 0.02);
}

.log-timestamp {
    color: var(--deck-text-color);
    opacity: 0.5;
    flex-shrink: 0;
    min-width: 60px;
}

.log-message {
    color: var(--deck-text-color);
    word-break: break-all;
}

/* Log Levels */
.level-info {
    color: var(--deck-info);
}

.level-warning {
    color: var(--deck-warning);
}

.level-error {
    color: var(--deck-danger);
}

.level-success {
    color: var(--deck-success);
}

.level-debug {
    color: var(--deck-muted);
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\UI\Components\HeaderLeft\HeaderLeft.razor
<div class="header-left-container">
    <div class="logo-text">
        CHO<span class="logo-accent">KA</span>Q
    </div>

    <div class="separator"></div>

    <div class="app-title">
        THE DECK
    </div>
</div>

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\UI\Components\HeaderLeft\HeaderLeft.razor.cs
using Microsoft.AspNetCore.Components;

namespace ChokaQ.TheDeck.UI.Components.HeaderLeft;

public partial class HeaderLeft
{
    // Future: Add connection status or environment name here
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\UI\Components\HeaderLeft\HeaderLeft.razor.css
.header-left-container {
    height: 100%;
    display: flex;
    align-items: center;
    gap: 1rem;
    padding-left: 0.5rem;
}

.logo-text {
    font-weight: 900;
    font-size: 1.5rem;
    letter-spacing: -1px;
    color: var(--deck-text-color);
}

.logo-accent {
    color: var(--deck-info);
}

.separator {
    height: 50%;
    width: 1px;
    background: var(--sector-border-color);
}

.app-title {
    font-family: var(--deck-font-family);
    font-size: 0.8rem;
    opacity: 0.7;
    letter-spacing: 1px;
    color: var(--deck-text-color);
    text-transform: uppercase;
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\UI\Components\HeaderRight\HeaderRight.razor
<div class="header-right-container">
    <div class="theme-control">
        <span class="theme-label">THEME_</span>
        <select class="theme-select" @onchange="OnThemeChangedAsync">
            <option value="blueprint">BLUEPRINT</option>
            <option value="carbon">CARBON</option>
        </select>
    </div>
</div>

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\UI\Components\HeaderRight\HeaderRight.razor.cs
using Microsoft.AspNetCore.Components;
using Microsoft.JSInterop;

namespace ChokaQ.TheDeck.UI.Components.HeaderRight;

public partial class HeaderRight
{
    [Inject]
    public required IJSRuntime JSRuntime { get; set; }

    private async Task OnThemeChangedAsync(ChangeEventArgs e)
    {
        var theme = e.Value?.ToString() ?? "blueprint";
        // Call the helper in deck.js
        await JSRuntime.InvokeVoidAsync("deck.setTheme", theme);
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\UI\Components\HeaderRight\HeaderRight.razor.css
.header-right-container {
    height: 100%;
    display: flex;
    align-items: center;
    justify-content: flex-end;
    gap: 2rem;
    padding-right: 0.5rem;
}

.theme-control {
    display: flex;
    align-items: center;
    gap: 0.5rem;
}

.theme-label {
    opacity: 0.7;
    font-size: 0.8em;
    color: var(--deck-text-color);
    font-family: var(--deck-font-family);
}

.theme-select {
    background: rgba(0, 0, 0, 0.2);
    color: var(--deck-text-color);
    border: 1px solid var(--sector-border-color);
    padding: 0.2rem 0.5rem;
    font-family: var(--deck-font-family);
    font-size: 0.85rem;
    text-transform: uppercase;
    cursor: pointer;
    outline: none;
    transition: border-color 0.2s;
}

    .theme-select:focus {
        border-color: var(--deck-info);
        background: rgba(0, 0, 0, 0.4);
    }

    .theme-select option {
        background-color: var(--deck-bg-color);
        color: var(--deck-text-color);
    }

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\UI\Components\JobMatrix\JobMatrix.razor
@using Microsoft.AspNetCore.Components.Web.Virtualization
@using ChokaQ.TheDeck.Models
@using ChokaQ.TheDeck.Components.Shared
@using ChokaQ.Abstractions.Enums
@using Microsoft.AspNetCore.SignalR.Client

<div style="display: flex; flex-direction: column; height: 100%;">
    <!-- Toolbar -->
    <div style="display: flex; justify-content: space-between; align-items: center; padding-bottom: 0.5rem; border-bottom: 1px solid var(--sector-border-color); margin-bottom: 0.5rem; flex-shrink: 0;">
        <div style="display: flex; gap: 0.5rem; flex: 1; max-width: 400px; align-items: center;">
             <div style="display: flex; border: 1px solid var(--sector-border-color); background: var(--sector-bg); flex: 1;">
                 <span style="padding: 0.25rem 0.5rem; border-right: 1px solid var(--sector-border-color); opacity: 0.7; font-size: 0.8rem; display: flex; align-items: center;">SEARCH</span>
                 <input type="text"
                        style="background: transparent; border: none; color: var(--deck-text-color); padding: 0.25rem; flex: 1; min-width: 200px; outline: none; font-family: var(--deck-font-family); font-size: 0.9rem;"
                        placeholder="ID, Type, Queue..."
                        @bind="_searchQuery"
                        @bind:event="oninput" />
                 @if (!string.IsNullOrEmpty(_searchQuery))
                 {
                     <span style="padding: 0.25rem 0.5rem; color: var(--deck-info); font-weight: bold; font-size: 0.8rem; border-left: 1px solid var(--sector-border-color); display: flex; align-items: center;">@FilteredJobs.Count</span>
                     <button style="background: transparent; border: none; color: var(--deck-text-color); cursor: pointer; padding: 0 0.5rem; border-left: 1px solid var(--sector-border-color);" @onclick="() => _searchQuery = string.Empty">X</button>
                 }
             </div>
        </div>
        
        <div style="display: flex; gap: 1rem; align-items: center;">
             @if (SelectedCount > 0)
             {
                 <span class="deck-badge" style="background: var(--deck-info); color: white;">@SelectedCount selected</span>
             }
             
             @if (IsConnected)
             {
                 <span style="font-size: 0.75rem; font-weight: bold; color: var(--deck-success);">ONLINE</span>
             }
             else
             {
                 <span style="font-size: 0.75rem; font-weight: bold; color: var(--deck-danger);">OFFLINE</span>
             }
             
             <button class="deck-btn" @onclick="OnClearHistory">Clear</button>
        </div>
    </div>
    
    <!-- Bulk Actions -->
    @if (SelectedCount > 0)
    {
        <div style="display: flex; align-items: center; gap: 1rem; padding: 0.5rem; background: rgba(255,255,255,0.05); border-bottom: 1px solid var(--sector-border-color); margin-bottom: 0.5rem; animation: fadeIn 0.3s; flex-shrink: 0;">
            <span style="font-size: 0.75rem; font-weight: bold; opacity: 0.7;">BULK:</span>
            <button class="deck-btn deck-btn-primary" @onclick="RestartSelected">Retry All</button>
            <button class="deck-btn deck-btn-danger" @onclick="CancelSelected">Cancel All</button>
            
            <div style="border-left: 1px solid var(--sector-border-color); padding-left: 1rem; display: flex; align-items: center; gap: 0.5rem;">
                <span style="font-size: 0.75rem; font-weight: bold; opacity: 0.7;">PRIORITY:</span>
                <input type="number" style="width: 50px; background: var(--sector-bg); border: 1px solid var(--sector-border-color); color: var(--deck-text-color); padding: 0.2rem;" @bind="_bulkPriorityValue" />
                <button class="deck-btn" style="padding: 0.2rem 0.5rem; font-size: 0.75rem;" @onclick="SetPrioritySelected">Apply</button>
            </div>
            
            <button class="deck-btn" style="margin-left: auto; border: none; background: transparent; text-decoration: underline; opacity: 0.7;" @onclick="ClearSelection">Deselect All</button>
        </div>
    }

    <!-- Table -->
    <div style="flex: 1; overflow-y: auto;">
        <table class="deck-table">
            <thead style="position: sticky; top: 0; background: var(--sector-bg); z-index: 10;">
                <tr>
                    <th style="width: 40px; text-align: center;">
                        <input type="checkbox" checked="@IsAllVisibleSelected" @onchange="ToggleSelectAll" style="cursor: pointer;" />
                    </th>
                    <th style="width: 15%">ID</th>
                    <th style="width: 10%">Queue</th>
                    <th style="width: 15%">Type</th>
                    <th style="width: 5%; text-align: center;">Pri</th>
                    <th style="width: 10%">User</th>
                    <th style="width: 10%; text-align: center;">Status</th>
                    <th style="width: 15%; text-align: center;">Progress</th>
                    <th style="width: 5%; text-align: center;">Att.</th>
                    <th style="width: 5%">Duration</th>
                    <th style="text-align: right;">Actions</th>
                </tr>
            </thead>
            <tbody>
                <Virtualize Items="@FilteredJobs" Context="job" OverscanCount="10" ItemSize="45">
                    <ItemContent>
                        <JobRow @key="job.Id"
                                Job="job"
                                IsSelected="@_selectedJobIds.Contains(job.Id)"
                                OnSelectionChanged="@(isSelected => ToggleSelection(job.Id, isSelected))"
                                OnCancelRequested="HandleCancelRequest"
                                OnRestartRequested="HandleRestartRequest"
                                OnSelected="HandleJobSelected" />
                    </ItemContent>
                    <Placeholder>
                         <tr><td colspan="11" style="text-align: center; padding: 1rem; opacity: 0.5;">Loading...</td></tr>
                    </Placeholder>
                    <EmptyContent>
                         <tr><td colspan="11" style="text-align: center; padding: 2rem; opacity: 0.5;">No jobs found.</td></tr>
                    </EmptyContent>
                </Virtualize>
            </tbody>
        </table>
    </div>
</div>

<style>
    @("@keyframes fadeIn { from { opacity: 0; transform: translateY(-5px); } to { opacity: 1; transform: translateY(0); } }")
</style>

@code {
    [Parameter] public List<JobViewModel> Jobs { get; set; } = new();
    [Parameter] public bool IsConnected { get; set; }
    [Parameter] public EventCallback OnClearHistory { get; set; }
    [Parameter] public HubConnection? HubConnection { get; set; }
    [Parameter] public JobStatus? ActiveStatusFilter { get; set; }
    
    [Parameter] public EventCallback<string> OnJobSelected { get; set; } 

    private string _searchQuery = "";
    private HashSet<string> _selectedJobIds = new();
    private int SelectedCount => _selectedJobIds.Count;
    private int _bulkPriorityValue = 10;

    private ICollection<JobViewModel> FilteredJobs
    {
        get
        {
            IEnumerable<JobViewModel> query = Jobs;

            if (ActiveStatusFilter.HasValue)
            {
                query = query.Where(x => x.Status == ActiveStatusFilter.Value);
            }

            if (!string.IsNullOrWhiteSpace(_searchQuery))
            {
                var term = _searchQuery.Trim();
                query = query.Where(x =>
                    x.Id.Contains(term, StringComparison.OrdinalIgnoreCase) ||
                    x.Type.Contains(term, StringComparison.OrdinalIgnoreCase) ||
                    x.Queue.Contains(term, StringComparison.OrdinalIgnoreCase) ||
                    (x.CreatedBy != null && x.CreatedBy.Contains(term, StringComparison.OrdinalIgnoreCase))
                );
            }

            return query.ToList();
        }
    }

    protected override void OnParametersSet()
    {
    }

    private void ToggleSelection(string jobId, bool isSelected)
    {
        if (isSelected) _selectedJobIds.Add(jobId);
        else _selectedJobIds.Remove(jobId);
    }

    private bool IsAllVisibleSelected => FilteredJobs.Any() && FilteredJobs.All(j => _selectedJobIds.Contains(j.Id));

    private void ToggleSelectAll(ChangeEventArgs e)
    {
        var isChecked = (bool)(e.Value ?? false);
        if (isChecked)
        {
            foreach (var job in FilteredJobs) _selectedJobIds.Add(job.Id);
        }
        else
        {
            _selectedJobIds.Clear();
        }
    }

    private void ClearSelection() => _selectedJobIds.Clear();

    private async Task HandleJobSelected(string jobId)
    {
        await OnJobSelected.InvokeAsync(jobId);
    }

    private async Task RestartSelected()
    {
        if (HubConnection is not null && IsConnected)
        {
            var toProcess = _selectedJobIds.ToList();
            foreach (var id in toProcess) await HubConnection.InvokeAsync("RestartJob", id);
            _selectedJobIds.Clear();
        }
    }

    private async Task CancelSelected()
    {
        if (HubConnection is not null && IsConnected)
        {
            var toProcess = _selectedJobIds.ToList();
            foreach (var id in toProcess) await HubConnection.InvokeAsync("CancelJob", id);
            _selectedJobIds.Clear();
        }
    }

    private async Task SetPrioritySelected()
    {
        if (HubConnection is not null && IsConnected)
        {
            var toProcess = _selectedJobIds.ToList();
            foreach (var id in toProcess)
            {
                await HubConnection.InvokeAsync("SetPriority", id, _bulkPriorityValue);
            }
            _selectedJobIds.Clear();
        }
    }

    private async Task HandleCancelRequest(string jobId)
    {
        if (HubConnection is not null && IsConnected)
            await HubConnection.InvokeAsync("CancelJob", jobId);
    }

    private async Task HandleRestartRequest(string jobId)
    {
        if (HubConnection is not null && IsConnected)
            await HubConnection.InvokeAsync("RestartJob", jobId);
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\UI\Components\JobMatrix\JobMatrix.razor.cs
using ChokaQ.Abstractions.Enums;
using ChokaQ.TheDeck.Models;
using Microsoft.AspNetCore.Components;
using Microsoft.AspNetCore.SignalR.Client;

namespace ChokaQ.TheDeck.Components.Modules;

public partial class JobMatrix
{
    [Parameter]
    public List<JobViewModel> Jobs { get; set; } = new();

    [Parameter]
    public bool IsConnected { get; set; }

    [Parameter]
    public EventCallback OnClearHistory { get; set; }

    [Parameter]
    public HubConnection? HubConnection { get; set; }

    [Parameter]
    public JobStatus? ActiveStatusFilter { get; set; }

    [Parameter]
    public EventCallback<string> OnJobSelected { get; set; }

    // Internal State
    private string _searchQuery = string.Empty;
    private HashSet<string> _selectedJobIds = new();
    private int _bulkPriorityValue = 10;

    /// <summary>
    /// Computes the visible job list based on status filter and search query.
    /// </summary>
    private ICollection<JobViewModel> FilteredJobs
    {
        get
        {
            IEnumerable<JobViewModel> query = Jobs;

            // 1. Filter by Status (from Stats cards)
            if (ActiveStatusFilter.HasValue)
            {
                query = query.Where(x => x.Status == ActiveStatusFilter.Value);
            }

            // 2. Filter by Search Text
            if (!string.IsNullOrWhiteSpace(_searchQuery))
            {
                var term = _searchQuery.Trim();
                query = query.Where(x =>
                    x.Id.Contains(term, StringComparison.OrdinalIgnoreCase) ||
                    x.Type.Contains(term, StringComparison.OrdinalIgnoreCase) ||
                    x.Queue.Contains(term, StringComparison.OrdinalIgnoreCase) ||
                    (x.CreatedBy != null && x.CreatedBy.Contains(term, StringComparison.OrdinalIgnoreCase))
                );
            }

            return query.ToList();
        }
    }

    private int SelectedCount => _selectedJobIds.Count;
    private bool IsAllVisibleSelected => FilteredJobs.Any() && FilteredJobs.All(j => _selectedJobIds.Contains(j.Id));

    // --- Selection Logic ---

    private void ToggleSelection(string jobId, bool isSelected)
    {
        if (isSelected) _selectedJobIds.Add(jobId);
        else _selectedJobIds.Remove(jobId);
    }

    private void ToggleSelectAll(ChangeEventArgs e)
    {
        var isChecked = (bool)(e.Value ?? false);
        if (isChecked)
        {
            foreach (var job in FilteredJobs) _selectedJobIds.Add(job.Id);
        }
        else
        {
            _selectedJobIds.Clear();
        }
    }

    private void ClearSelection() => _selectedJobIds.Clear();

    // --- Actions ---

    private async Task HandleJobSelectedAsync(string jobId)
    {
        await OnJobSelected.InvokeAsync(jobId);
    }

    private void ClearSearch()
    {
        _searchQuery = string.Empty;
    }

    // --- Bulk Actions ---

    private async Task RestartSelectedAsync()
    {
        if (HubConnection is not null && IsConnected)
        {
            var toProcess = _selectedJobIds.ToList();
            foreach (var id in toProcess) await HubConnection.InvokeAsync("RestartJob", id);
            _selectedJobIds.Clear();
        }
    }

    private async Task CancelSelectedAsync()
    {
        if (HubConnection is not null && IsConnected)
        {
            var toProcess = _selectedJobIds.ToList();
            foreach (var id in toProcess) await HubConnection.InvokeAsync("CancelJob", id);
            _selectedJobIds.Clear();
        }
    }

    private async Task SetPrioritySelectedAsync()
    {
        if (HubConnection is not null && IsConnected)
        {
            var toProcess = _selectedJobIds.ToList();
            foreach (var id in toProcess)
            {
                await HubConnection.InvokeAsync("SetPriority", id, _bulkPriorityValue);
            }
            _selectedJobIds.Clear();
        }
    }

    // --- Row Callbacks ---

    private async Task HandleCancelRequestAsync(string jobId)
    {
        if (HubConnection is not null && IsConnected)
            await HubConnection.InvokeAsync("CancelJob", jobId);
    }

    private async Task HandleRestartRequestAsync(string jobId)
    {
        if (HubConnection is not null && IsConnected)
            await HubConnection.InvokeAsync("RestartJob", jobId);
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\UI\Components\JobMatrix\JobRow\JobRow.razor
@using ChokaQ.Abstractions.Enums
@using ChokaQ.TheDeck.Models

<tr class="deck-row @(IsSelected ? "selected" : "")" @onclick="HandleRowClick" style="cursor: pointer;">
    <td @onclick:stopPropagation="true" style="text-align: center;">
        <input type="checkbox" checked="@IsSelected" @onchange="HandleCheckboxChange" style="cursor: pointer; width: 1.1rem; height: 1.1rem;" />
    </td>
    
    <td style="font-family: monospace; font-weight: bold; color: var(--deck-info); font-size: 0.85rem;" title="@Job.Id">
        @Job.Id.Substring(0, 8)...
    </td>
    
    <td>
        <span class="deck-badge" style="background: var(--sector-bg); border: 1px solid var(--sector-border-color); color: var(--deck-text-color);">
            @Job.Queue
        </span>
    </td>
    
    <td>
        <span class="deck-badge" style="background: var(--sector-border-color); color: var(--deck-text-color);">
            @Job.Type
        </span>
    </td>
    
    <td style="text-align: center; font-weight: bold; opacity: 0.7;">
        @Job.Priority
    </td>
    
    <td>
        <span style="font-size: 0.8rem; opacity: 0.7;">@(Job.CreatedBy ?? "System")</span>
    </td>
    
    <td style="text-align: center;">
        <span class="deck-badge" style="@GetStatusStyle()">@GetStatusLabel()</span>
    </td>
    
    <td style="vertical-align: middle;">
        @if (Job.Status == JobStatus.Processing)
        {
             <div class="deck-progress">
                 <div class="deck-progress-bar" style="width: @(Job.Progress)%; background: var(--deck-info);"></div>
             </div>
             <div style="font-size: 0.7rem; margin-top: 2px; text-align: center;">@Job.Progress%</div>
        }
        else if (Job.Status == JobStatus.Succeeded)
        {
             <div class="deck-progress">
                 <div class="deck-progress-bar" style="width: 100%; background: var(--deck-success);"></div>
             </div>
        }
        else
        {
            <span style="opacity: 0.3; display: block; text-align: center;">-</span>
        }
    </td>
    
    <td style="text-align: center;">
        @if (Job.Attempts > 1)
        {
            <span class="deck-badge" style="border: 1px solid var(--sector-border-color);">@Job.Attempts</span>
        }
        else
        {
             <span style="opacity: 0.5;">1</span>
        }
    </td>
    
    <td style="font-family: monospace; font-size: 0.8rem;">
        @FormatDuration(Job.Duration)
    </td>
    
    <td style="text-align: right;">
        @if (new[] { JobStatus.Processing, JobStatus.Pending, JobStatus.Fetched }.Contains(Job.Status))
        {
             <button class="deck-btn deck-btn-danger" style="padding: 0.1rem 0.5rem; font-size: 0.7rem;" @onclick="CancelJob" @onclick:stopPropagation="true">Stop</button>
        }
        @if (new[] { JobStatus.Succeeded, JobStatus.Failed, JobStatus.Cancelled }.Contains(Job.Status))
        {
             <button class="deck-btn deck-btn-primary" style="padding: 0.1rem 0.5rem; font-size: 0.7rem;" @onclick="RestartJob" @onclick:stopPropagation="true">Retry</button>
        }
    </td>
</tr>

@code {
    [Parameter] public required JobViewModel Job { get; set; }
    [Parameter] public bool IsSelected { get; set; }

    [Parameter] public EventCallback<string> OnCancelRequested { get; set; }
    [Parameter] public EventCallback<string> OnRestartRequested { get; set; }
    [Parameter] public EventCallback<string> OnSelected { get; set; }
    [Parameter] public EventCallback<bool> OnSelectionChanged { get; set; }

    private async Task CancelJob() => await OnCancelRequested.InvokeAsync(Job.Id);
    private async Task RestartJob() => await OnRestartRequested.InvokeAsync(Job.Id);
    private async Task HandleRowClick() => await OnSelected.InvokeAsync(Job.Id);

    private async Task HandleCheckboxChange(ChangeEventArgs e)
    {
        var isChecked = (bool)(e.Value ?? false);
        await OnSelectionChanged.InvokeAsync(isChecked);
    }

    private string FormatDuration(TimeSpan? duration)
    {
        if (!duration.HasValue || duration.Value == TimeSpan.Zero) return "-";
        if (duration.Value.TotalSeconds < 1) return $"{duration.Value.TotalMilliseconds:F0}ms";
        if (duration.Value.TotalMinutes < 1) return $"{duration.Value.Seconds}s {duration.Value.Milliseconds}ms";
        return $"{duration.Value.Minutes}m {duration.Value.Seconds}s";
    }

    private string GetStatusStyle() => Job.Status switch
    {
        JobStatus.Processing => "color: var(--deck-warning); border: 1px solid var(--deck-warning);",
        JobStatus.Fetched => "color: var(--deck-info); border: 1px solid var(--deck-info);",
        JobStatus.Succeeded => "color: var(--deck-success); border: 1px solid var(--deck-success);",
        JobStatus.Failed => "color: var(--deck-danger); border: 1px solid var(--deck-danger);",
        JobStatus.Cancelled => "color: var(--deck-muted); border: 1px solid var(--deck-muted);",
        _ => "color: var(--deck-text-color); border: 1px solid var(--sector-border-color);"
    };

    private string GetStatusLabel() => Job.Status.ToString().ToUpper();
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\UI\Components\OpsPanel\OpsPanel.razor
@using ChokaQ.TheDeck.Components.Shared

<div style="height: 100%; overflow-y: hidden; background: var(--sector-bg);">
    @if (_activePanel == OpsPanelType.JobInspector && _selectedJobId != null)
    {
        <JobInspector JobId="@_selectedJobId" 
                      OnClose="ClearPanel" 
                      OnRestart="HandleRequeue" 
                      OnDelete="HandleDelete" />
    }
    else
    {
        <div style="display: flex; align-items: center; justify-content: center; height: 100%; opacity: 0.5; font-family: var(--deck-font-family); color: var(--deck-text-color);">
            <span>No active panel</span>
        </div>
    }
</div>

@code {
    private OpsPanelType _activePanel = OpsPanelType.None;
    private string? _selectedJobId;

    [Parameter] public EventCallback<string> OnRequeue { get; set; }
    [Parameter] public EventCallback<string> OnDelete { get; set; }

    public void ShowJobInspector(string jobId)
    {
        _activePanel = OpsPanelType.JobInspector;
        _selectedJobId = jobId;
        StateHasChanged();
    }

    public void ClearPanel()
    {
        _activePanel = OpsPanelType.None;
        _selectedJobId = null;
        StateHasChanged();
    }

    private async Task HandleRequeue(string jobId)
    {
        await OnRequeue.InvokeAsync(jobId);
    }

    private async Task HandleDelete(string jobId)
    {
        await OnDelete.InvokeAsync(jobId);
        ClearPanel();
    }

    private enum OpsPanelType { None, JobInspector }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\UI\Components\OpsPanel\JobInspector\JobInspector.razor
@using ChokaQ.Abstractions.Enums
@using ChokaQ.Abstractions.Storage
@using ChokaQ.Abstractions.Entities
@using System.Text.Json
@inject IJobStorage JobStorage

<div style="height: 100%; display: flex; flex-direction: column;">
    <!-- Header -->
    <div style="flex-shrink: 0; display: flex; justify-content: space-between; align-items: start; margin-bottom: 1rem; border-bottom: 1px solid var(--sector-border-color); padding-bottom: 0.5rem;">
        <div>
            <div style="font-weight: bold; font-size: 1.1rem; color: var(--deck-text-color);">Job Inspector</div>
            @if (_job != null)
            {
               <div style="font-family: monospace; font-size: 0.8rem; opacity: 0.7; margin-top: 0.2rem; user-select: all;">@_job.Id</div>
            }
        </div>
        <button class="deck-btn" style="padding: 0.2rem 0.5rem;" @onclick="Close">Close</button>
    </div>

    @if (_job == null)
    {
        <div style="flex: 1; display: flex; align-items: center; justify-content: center; opacity: 0.5;">
             <span>Loading or Job not found...</span>
        </div>
    }
    else
    {
        <div style="flex: 1; overflow-y: auto; padding-right: 0.5rem;">
             <!-- Status Banner -->
             <div style="margin-bottom: 1rem; border: 1px solid var(--sector-border-color); padding: 0.5rem; border-left: 4px solid @GetStatusColor(); background: var(--sector-bg);">
                 <div style="font-size: 0.75rem; text-transform: uppercase; opacity: 0.7;">Status</div>
                 <div style="font-size: 1.2rem; font-weight: bold; color: @GetStatusColor();">@_job.Status.ToString().ToUpper()</div>
                 <div style="font-size: 0.75rem; margin-top: 0.25rem;">Source: @GetSourceBadge()</div>
             </div>

             <!-- Metadata -->
             <div style="margin-bottom: 1rem;">
                 <div style="font-size: 0.8rem; font-weight: bold; margin-bottom: 0.5rem; text-transform: uppercase; border-bottom: 1px solid var(--sector-border-color);">Metadata</div>
                 <ul class="deck-meta-list">
                     <li><span class="deck-meta-label">Type</span> <span class="deck-meta-value">@_job.Type</span></li>
                     <li><span class="deck-meta-label">Queue</span> <span class="deck-meta-value">@_job.Queue</span></li>
                     <li><span class="deck-meta-label">Priority</span> <span class="deck-meta-value">@_job.Priority</span></li>
                     <li><span class="deck-meta-label">Created By</span> <span class="deck-meta-value">@(_job.CreatedBy ?? "-")</span></li>
                 </ul>
             </div>

             <!-- Timeline -->
             <div style="margin-bottom: 1rem;">
                 <div style="font-size: 0.8rem; font-weight: bold; margin-bottom: 0.5rem; text-transform: uppercase; border-bottom: 1px solid var(--sector-border-color);">Timeline</div>
                 <ul class="deck-meta-list">
                     <li><span class="deck-meta-label">Created</span> <span class="deck-meta-value">@_job.CreatedAtUtc.ToLocalTime().ToString("G")</span></li>
                     @if (_job.StartedAtUtc.HasValue)
                     {
                         <li><span class="deck-meta-label">Started</span> <span class="deck-meta-value">@_job.StartedAtUtc.Value.ToLocalTime().ToString("G")</span></li>
                     }
                     @if (_job.FinishedAtUtc.HasValue)
                     {
                         <li><span class="deck-meta-label">Finished</span> <span class="deck-meta-value">@_job.FinishedAtUtc.Value.ToLocalTime().ToString("G")</span></li>
                     }
                     <li><span class="deck-meta-label">Attempts</span> <span class="deck-meta-value">@_job.AttemptCount</span></li>
                 </ul>
             </div>

             <!-- Exceptions -->
             @if (!string.IsNullOrEmpty(_job.ErrorDetails))
             {
                 <div style="margin-bottom: 1rem;">
                     <div style="font-size: 0.8rem; font-weight: bold; margin-bottom: 0.5rem; text-transform: uppercase; border-bottom: 1px solid var(--sector-border-color); color: var(--deck-danger);">Exception</div>
                     <div class="deck-code-block" style="border-color: var(--deck-danger); color: var(--deck-danger);">
                         @_job.ErrorDetails
                     </div>
                 </div>
             }

             <!-- Payload -->
             <div style="margin-bottom: 1rem;">
                 <div style="font-size: 0.8rem; font-weight: bold; margin-bottom: 0.5rem; text-transform: uppercase; border-bottom: 1px solid var(--sector-border-color);">Payload</div>
                 <div class="deck-code-block">
                     @PrettyPrintJson(_job.Payload)
                 </div>
             </div>
             
             <!-- Spacer -->
        </div>

        <!-- Footer Actions -->
        <div style="flex-shrink: 0; padding-top: 0.5rem; border-top: 1px solid var(--sector-border-color); display: flex; gap: 0.5rem; justify-content: flex-end;">
            @if (CanRequeue)
            {
                <button class="deck-btn deck-btn-primary" @onclick="HandleRequeue">Requeue Job</button>
            }
            <button class="deck-btn deck-btn-danger" @onclick="HandleDelete">Delete</button>
        </div>
    }
</div>

@code {
    [Parameter] public string? JobId { get; set; }
    [Parameter] public EventCallback OnClose { get; set; }
    [Parameter] public EventCallback<string> OnRestart { get; set; }
    [Parameter] public EventCallback<string> OnDelete { get; set; }

    private JobInspectorModel? _job;
    
    // Note: Requeue is technically Restart for DLQ.
    private bool CanRequeue => _job?.Source == JobSource.DLQ;

    protected override async Task OnParametersSetAsync()
    {
        if (!string.IsNullOrEmpty(JobId))
        {
            if (_job?.Id != JobId)
            {
                _job = await FindJobAsync(JobId);
            }
        }
    }

    private async Task Close() => await OnClose.InvokeAsync();

    private async Task HandleRequeue()
    {
        if (_job != null) await OnRestart.InvokeAsync(_job.Id);
    }

    private async Task HandleDelete()
    {
        if (_job != null) await OnDelete.InvokeAsync(_job.Id);
    }

    // Logic from original JobInspector.razor.cs
    private async Task<JobInspectorModel?> FindJobAsync(string jobId)
    {
        var hotJob = await JobStorage.GetJobAsync(jobId);
        if (hotJob != null) return new JobInspectorModel { Id = hotJob.Id, Queue = hotJob.Queue, Type = hotJob.Type, Payload = hotJob.Payload, Status = hotJob.Status, AttemptCount = hotJob.AttemptCount, Priority = hotJob.Priority, CreatedBy = hotJob.CreatedBy, CreatedAtUtc = hotJob.CreatedAtUtc, StartedAtUtc = hotJob.StartedAtUtc, Source = JobSource.Hot };

        var archiveJob = await JobStorage.GetArchiveJobAsync(jobId);
        if (archiveJob != null) return new JobInspectorModel { Id = archiveJob.Id, Queue = archiveJob.Queue, Type = archiveJob.Type, Payload = archiveJob.Payload, Status = JobStatus.Succeeded, AttemptCount = archiveJob.AttemptCount, CreatedBy = archiveJob.CreatedBy, CreatedAtUtc = archiveJob.CreatedAtUtc, StartedAtUtc = archiveJob.StartedAtUtc, FinishedAtUtc = archiveJob.FinishedAtUtc, Source = JobSource.Archive };

        var dlqJob = await JobStorage.GetDLQJobAsync(jobId);
        if (dlqJob != null) return new JobInspectorModel { Id = dlqJob.Id, Queue = dlqJob.Queue, Type = dlqJob.Type, Payload = dlqJob.Payload, Status = JobStatus.Failed, AttemptCount = dlqJob.AttemptCount, CreatedBy = dlqJob.CreatedBy, CreatedAtUtc = dlqJob.CreatedAtUtc, ErrorDetails = dlqJob.ErrorDetails, Source = JobSource.DLQ };

        return null;
    }

    private string GetStatusColor() => _job?.Status switch
    {
        JobStatus.Failed => "var(--deck-danger)",
        JobStatus.Succeeded => "var(--deck-success)",
        JobStatus.Processing => "var(--deck-warning)",
        JobStatus.Cancelled => "var(--deck-muted)",
        _ => "var(--deck-info)"
    };

    private string GetSourceBadge() => _job?.Source switch
    {
        JobSource.Hot => "HOT",
        JobSource.Archive => "ARCHIVE",
        JobSource.DLQ => "DLQ",
        _ => "?"
    };

    private string PrettyPrintJson(string? json)
    {
        if (string.IsNullOrWhiteSpace(json)) return "{}";
        try { var doc = JsonDocument.Parse(json); return JsonSerializer.Serialize(doc, new JsonSerializerOptions { WriteIndented = true }); }
        catch { return json; }
    }

    private class JobInspectorModel
    {
        public string Id { get; init; } = "";
        public string Queue { get; init; } = "";
        public string Type { get; init; } = "";
        public string? Payload { get; init; }
        public JobStatus Status { get; init; }
        public int AttemptCount { get; init; }
        public int Priority { get; init; }
        public string? CreatedBy { get; init; }
        public DateTime CreatedAtUtc { get; init; }
        public DateTime? StartedAtUtc { get; init; }
        public DateTime? FinishedAtUtc { get; init; }
        public string? ErrorDetails { get; init; }
        public JobSource Source { get; init; }
    }

    private enum JobSource { Hot, Archive, DLQ }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\UI\Components\Queues\Queues.razor
@using ChokaQ.Abstractions.Entities
@using ChokaQ.Abstractions.Storage
@using Microsoft.AspNetCore.SignalR.Client
@inject IJobStorage Storage
@implements IDisposable

<div style="height: 100%; overflow-y: auto;">
    @if (_isLoading)
    {
        <div style="display: flex; align-items: center; justify-content: center; height: 100%; opacity: 0.5;">
            <span>Loading queues...</span>
        </div>
    }
    else if (!_visibleQueues.Any())
    {
        <div style="display: flex; align-items: center; justify-content: center; height: 100%; opacity: 0.5;">
             <span>No queues found. Send a job to 'default' queue to see it here.</span>
        </div>
    }
    else
    {
        <table class="deck-table">
            <thead>
                <tr>
                    <th style="width: 20%">Queue</th>
                    <th style="width: 20%; text-align: center;">Jobs (Succeeded / Failed)</th>
                    <th style="width: 15%; text-align: center;">Status</th>
                    <th style="width: 15%; text-align: center;">Pause/Resume</th>
                    <th style="width: 15%; text-align: center;">Zombie (s)</th>
                    <th style="width: 15%; text-align: right;">Last Updated</th>
                    <th style="width: 5%"></th>
                </tr>
            </thead>
            <tbody>
                @foreach (var q in _visibleQueues)
                {
                    var stats = GetQueueStats(q.Name);
                    <tr>
                        <td style="font-weight: bold; font-family: monospace;">@q.Name</td>
                        <td style="text-align: center; font-family: monospace;">
                            @if (stats != null)
                            {
                                <span style="color: var(--deck-success)">@stats.SucceededTotal.ToString("N0")</span>
                                <span style="opacity: 0.5; margin: 0 0.2rem;">/</span>
                                <span style="color: var(--deck-danger)">@stats.FailedTotal.ToString("N0")</span>
                            }
                            else
                            {
                                <span style="opacity: 0.5;">0 / 0</span>
                            }
                        </td>
                        <td style="text-align: center;">
                             <span style="font-size: 0.75rem; padding: 0.1rem 0.4rem; border: 1px solid var(--sector-border-color); color: @GetStatusColor(q);">
                                 @GetQueueStatus(q)
                             </span>
                        </td>
                        <td style="text-align: center;">
                             <input type="checkbox" 
                                    checked="@(!q.IsPaused)"
                                    @onchange="@(e => ToggleQueue(q.Name, (bool)e.Value!))"
                                    style="cursor: pointer; width: 1.2rem; height: 1.2rem;" />
                        </td>
                        <td style="text-align: center;">
                            <input type="number"
                                   style="width: 70px; background: transparent; border: 1px solid var(--sector-border-color); color: var(--deck-text-color); font-family: inherit; font-size: inherit; padding: 0.1rem; text-align: center;"
                                   value="@q.ZombieTimeoutSeconds"
                                   @onchange="@(e => UpdateTimeout(q.Name, e.Value))" />
                        </td>
                        <td style="text-align: right; opacity: 0.6; font-size: 0.75rem;">
                            @q.LastUpdatedUtc.ToLocalTime().ToString("HH:mm:ss")
                        </td>
                        <td style="text-align: right;">
                            @if (!q.IsActive)
                            {
                                <button class="deck-btn" style="padding: 0.1rem 0.4rem; font-size: 0.7rem;" title="Hide inactive queue" @onclick="() => HideQueue(q.Name)">X</button>
                            }
                        </td>
                    </tr>
                }
            </tbody>
        </table>
    }
</div>

@code {
    [Parameter] public HubConnection? HubConnection { get; set; }

    private List<QueueEntity> _queues = new();
    private Dictionary<string, StatsSummaryEntity> _queueStats = new();
    private HashSet<string> _hiddenQueues = new();
    private IEnumerable<QueueEntity> _visibleQueues => _queues.Where(q => !_hiddenQueues.Contains(q.Name));
    private System.Threading.Timer? _timer;
    private bool _isLoading = true;
    private bool _isFirstLoad = true;

    protected override void OnInitialized()
    {
        _timer = new System.Threading.Timer(async _ => await Refresh(), null, 0, 2000);
    }

    protected override async Task OnAfterRenderAsync(bool firstRender)
    {
        if (firstRender && HubConnection != null)
        {
            HubConnection.On("StatsUpdated", () => InvokeAsync(async () => await Refresh()));
            
            if (HubConnection.State == HubConnectionState.Disconnected)
            {
                await HubConnection.StartAsync();
            }
        }
    }

    private async Task Refresh()
    {
        try
        {
            _queues = (await Storage.GetQueuesAsync()).ToList();
            var stats = await Storage.GetQueueStatsAsync();
            _queueStats = stats.ToDictionary(s => s.Queue ?? "", s => s);
            
            _isLoading = false;

            if (_isFirstLoad)
            {
                foreach (var q in _queues)
                {
                    if (!q.IsActive) _hiddenQueues.Add(q.Name);
                }
                _isFirstLoad = false;
            }

            foreach (var q in _queues)
            {
                if (q.IsActive && _hiddenQueues.Contains(q.Name))
                {
                    _hiddenQueues.Remove(q.Name);
                }
            }

            await InvokeAsync(StateHasChanged);
        }
        catch
        {
            _isLoading = false;
        }
    }

    private async Task ToggleQueue(string name, bool isRunning)
    {
        var pause = !isRunning;
        var q = _queues.FirstOrDefault(x => x.Name == name);
        if (q != null)
        {
            var index = _queues.IndexOf(q);
            _queues[index] = q with { IsPaused = pause };
        }

        if (HubConnection is not null)
        {
            await HubConnection.InvokeAsync("ToggleQueue", name, pause);
            await Refresh();
        }
    }

    private async Task UpdateTimeout(string name, object? value)
    {
        int? parsedValue = null;
        if (value is string strVal && int.TryParse(strVal, out int iVal)) parsedValue = Math.Max(60, iVal);
        else if (value is int intVal) parsedValue = Math.Max(60, intVal);

        var q = _queues.FirstOrDefault(x => x.Name == name);
        if (q != null)
        {
            var index = _queues.IndexOf(q);
            _queues[index] = q with { ZombieTimeoutSeconds = parsedValue };
        }

        if (HubConnection is not null)
        {
            await HubConnection.InvokeAsync("UpdateQueueTimeout", name, parsedValue);
        }
    }

    private void HideQueue(string name) => _hiddenQueues.Add(name);

    private string GetQueueStatus(QueueEntity q)
    {
        if (q.IsPaused) return "PAUSED";
        if (!q.IsActive) return "INACTIVE";
        return "ACTIVE";
    }

    private string GetStatusColor(QueueEntity q)
    {
        if (q.IsPaused) return "var(--deck-warning)";
        if (!q.IsActive) return "var(--deck-text-color)";
        return "var(--deck-success)";
    }

    private StatsSummaryEntity? GetQueueStats(string queueName) => _queueStats.GetValueOrDefault(queueName);

    public void Dispose() => _timer?.Dispose();
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\UI\Components\Settings\Settings.razor
<div class="settings-container">

    <div class="setting-row">
        <div class="setting-label">WORKERS</div>
        <input type="number"
               class="deck-input"
               min="0"
               max="100"
               @bind="DesiredWorkers" />
        <span class="setting-meta">(Active: @WorkerManager.ActiveWorkers)</span>
    </div>

    <div class="setting-row">
        <div class="setting-label">RETRIES</div>
        <select class="deck-input select-input" @bind="MaxRetries">
            @for (int i = 1; i <= 10; i++)
            {
                <option value="@i">@i</option>
            }
        </select>
    </div>

    <div class="setting-row">
        <div class="setting-label">BASE DELAY (S)</div>
        <input type="number"
               class="deck-input"
               min="1"
               max="3600"
               @bind="RetryDelaySeconds" />
    </div>

    <div class="actions-row">
        <button class="deck-btn deck-btn-primary" @onclick="ApplyChangesAsync">
            APPLY
        </button>
    </div>

</div>

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\UI\Components\Settings\Settings.razor.cs
using ChokaQ.Abstractions;
using ChokaQ.Abstractions.Workers;
using Microsoft.AspNetCore.Components;

namespace ChokaQ.TheDeck.UI.Components.Settings;

public partial class Settings
{
    [Inject]
    public required IWorkerManager WorkerManager { get; set; }

    [Parameter]
    public EventCallback OnSettingsApplied { get; set; }

    // Local state for binding inputs
    protected int DesiredWorkers { get; set; }
    protected int MaxRetries { get; set; }
    protected int RetryDelaySeconds { get; set; }

    protected override void OnInitialized()
    {
        // Sync local state with global kernel config
        DesiredWorkers = WorkerManager.TotalWorkers;
        MaxRetries = WorkerManager.MaxRetries;
        RetryDelaySeconds = WorkerManager.RetryDelaySeconds;
    }

    protected async Task ApplyChangesAsync()
    {
        // Simple validation
        if (RetryDelaySeconds < 1) RetryDelaySeconds = 1;
        if (DesiredWorkers < 0) DesiredWorkers = 0;
        if (DesiredWorkers > 100) DesiredWorkers = 100;

        // Apply to the singleton kernel
        WorkerManager.UpdateWorkerCount(DesiredWorkers);
        WorkerManager.MaxRetries = MaxRetries;
        WorkerManager.RetryDelaySeconds = RetryDelaySeconds;

        if (OnSettingsApplied.HasDelegate)
        {
            await OnSettingsApplied.InvokeAsync();
        }
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\UI\Components\Settings\Settings.razor.css
.settings-container {
    display: flex;
    flex-direction: column;
    gap: 1rem;
    height: 100%;
    justify-content: center;
}

.setting-row {
    display: flex;
    align-items: center;
    gap: 0.5rem;
}

.setting-label {
    font-weight: bold;
    font-size: 0.85rem;
    min-width: 120px;
    text-transform: uppercase;
    opacity: 0.8;
    color: var(--deck-text-color);
}

.setting-meta {
    opacity: 0.6;
    font-size: 0.8rem;
    font-family: var(--deck-font-family);
    color: var(--deck-text-color);
}

.deck-input {
    width: 70px;
    background: var(--sector-bg);
    border: 1px solid var(--sector-border-color);
    color: var(--deck-text-color);
    font-family: var(--deck-font-family);
    padding: 0.25rem;
    font-size: 0.85rem;
    outline: none;
    transition: border-color 0.2s;
}

    .deck-input:focus {
        border-color: var(--deck-info);
    }

.select-input {
    width: 60px;
}

.actions-row {
    display: flex;
    justify-content: flex-end;
    margin-top: 0.5rem;
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\UI\Components\Stats\Stats.razor
@using ChokaQ.Abstractions.Enums

<div class="stats-container">

    <div class="stats-card @(IsActive(JobStatus.Pending) ? "active" : "")"
         @onclick="() => SelectAsync(JobStatus.Pending)">
        <div class="card-label">PENDING</div>
        <div class="card-value val-muted">@Counts.Pending</div>
    </div>

    <div class="stats-card @(IsActive(JobStatus.Fetched) ? "active" : "")"
         @onclick="() => SelectAsync(JobStatus.Fetched)">
        <div class="card-label">BUFFERED</div>
        <div class="card-value val-info">@Counts.Fetched</div>
    </div>

    <div class="stats-card @(IsActive(JobStatus.Processing) ? "active" : "")"
         @onclick="() => SelectAsync(JobStatus.Processing)">
        <div class="card-label">PROCESSING</div>
        <div class="card-value val-warning">@Counts.Processing</div>
    </div>

    <div class="stats-card @(IsActive(JobStatus.Succeeded) ? "active" : "")"
         @onclick="() => SelectAsync(JobStatus.Succeeded)">
        <div class="card-label">SUCCEEDED</div>
        <div class="card-value val-success">@Counts.SucceededTotal.ToString("N0")</div>
    </div>

    <div class="stats-card @(IsActive(JobStatus.Failed) ? "active" : "")"
         @onclick="() => SelectAsync(JobStatus.Failed)">
        <div class="card-label">FAILED</div>
        <div class="card-value val-danger">@Counts.FailedTotal.ToString("N0")</div>
    </div>

    <div class="stats-card @(IsTotalActive ? "active" : "")"
         @onclick="() => SelectAsync(null)">
        <div class="card-label">TOTAL</div>
        <div class="card-value val-text">@Counts.Total.ToString("N0")</div>
    </div>

</div>

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\UI\Components\Stats\Stats.razor.cs
using ChokaQ.Abstractions.Entities;
using ChokaQ.Abstractions.Enums;
using Microsoft.AspNetCore.Components;

namespace ChokaQ.TheDeck.UI.Components.Stats;

public partial class Stats
{
    [Parameter]
    public StatsSummaryEntity Counts { get; set; } = new(null, 0, 0, 0, 0, 0, 0, 0, null);

    [Parameter]
    public JobStatus? SelectedStatus { get; set; }

    [Parameter]
    public EventCallback<JobStatus?> OnStatusSelected { get; set; }

    private bool IsActive(JobStatus status) => SelectedStatus == status;
    private bool IsTotalActive => SelectedStatus == null;

    private async Task SelectAsync(JobStatus? status)
    {
        await OnStatusSelected.InvokeAsync(status);
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\UI\Components\Stats\Stats.razor.css
.stats-container {
    display: flex;
    gap: 0.5rem;
    height: 100%;
    width: 100%;
}

.stats-card {
    flex: 1;
    background: var(--sector-bg);
    border: 1px solid var(--sector-border-color);
    padding: 0.5rem;
    cursor: pointer;
    display: flex;
    flex-direction: column;
    justify-content: center;
    align-items: center;
    transition: all 0.2s;
    min-width: 80px;
    user-select: none;
}

    .stats-card:hover {
        background: rgba(255, 255, 255, 0.05);
        border-color: var(--sector-border-highlight);
    }

    .stats-card.active {
        border-color: var(--sector-border-highlight);
        background: rgba(255, 255, 255, 0.08);
        box-shadow: inset 0 0 10px rgba(0,0,0,0.2);
    }

.card-label {
    font-size: 0.7rem;
    font-weight: bold;
    color: var(--deck-text-color);
    opacity: 0.7;
    margin-bottom: 0.25rem;
    text-transform: uppercase;
    letter-spacing: 0.5px;
}

.card-value {
    font-size: 1.4rem;
    font-weight: bold;
    font-family: var(--deck-font-family);
    line-height: 1;
}

/* Status Colors */
.val-muted {
    color: var(--deck-muted);
}

.val-info {
    color: var(--deck-info);
}

.val-warning {
    color: var(--deck-warning);
}

.val-success {
    color: var(--deck-success);
}

.val-danger {
    color: var(--deck-danger);
}

.val-text {
    color: var(--deck-text-color);
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\UI\Layout\TheDeckHost.razor
@page "/"
@using Microsoft.AspNetCore.Components.Web

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>ChokaQ - The Deck</title>

    <base href="@(Options.RoutePrefix.TrimEnd('/') + "/")" />

    <link href="/_content/ChokaQ.TheDeck/css/deck.css" rel="stylesheet" />

    <HeadOutlet />
</head>
<body>
    <ChokaQ.TheDeck.UI.Pages.TheDeck @rendermode="RenderMode.InteractiveServer" />

    <script src="/_framework/blazor.web.js"></script>
    <script src="/_content/ChokaQ.TheDeck/js/deck.js"></script>
</body>
</html>

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\UI\Layout\TheDeckHost.razor.cs
using Microsoft.AspNetCore.Components;

namespace ChokaQ.TheDeck.UI.Layout;

public partial class TheDeckHost : ComponentBase
{
    [Inject]
    public required ChokaQTheDeckOptions Options { get; set; }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\UI\Pages\TheDeck.razor
@using ChokaQ.TheDeck.UI.Components.HeaderLeft
@using ChokaQ.TheDeck.UI.Components.HeaderRight
@using ChokaQ.TheDeck.UI.Components.Queues
@using ChokaQ.TheDeck.UI.Components.Settings
@using ChokaQ.TheDeck.UI.Components.Stats
@using ChokaQ.TheDeck.UI.Components.Circuits
@using ChokaQ.TheDeck.UI.Components.JobMatrix
@using ChokaQ.TheDeck.UI.Components.OpsPanel
@using ChokaQ.TheDeck.UI.Components.ConsoleLog

<div class="deck-root">

    <div class="deck-col-main">

        <div class="deck-sector row-header">
            <HeaderLeft />
        </div>

        <div class="deck-sector row-queues">
            <Queues HubConnection="_hubConnection" />
        </div>

        <div class="deck-sector row-stats">
            <Stats Counts="_counts"
                   SelectedStatus="_activeStatusFilter"
                   OnStatusSelected="HandleStatusSelected" />
        </div>

        <div class="deck-sector row-matrix">
            <JobMatrix Jobs="_jobs"
                       IsConnected="IsConnected"
                       HubConnection="_hubConnection"
                       ActiveStatusFilter="_activeStatusFilter"
                       OnClearHistory="ClearHistory"
                       OnJobSelected="HandleJobInspectorRequested" />
        </div>

        <div class="deck-sector row-console">
            <ConsoleLog Logs="_logs" />
        </div>

    </div>

    <div class="deck-col-side">

        <div class="deck-sector row-header">
            <HeaderRight />
        </div>

        <div class="deck-sector row-settings">
            <Settings />
        </div>

        <div class="deck-sector row-circuits">
            <Circuits Breakers="_circuits" />
        </div>

        <div class="deck-sector row-ops">
            <OpsPanel @ref="_opsPanel"
                      OnRequeue="HandleRequeueRequestedAsync"
                      OnDelete="HandleDeleteRequestedAsync" />
        </div>

    </div>

</div>

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\UI\Pages\TheDeck.razor.cs
using ChokaQ.Abstractions.DTOs;
using ChokaQ.Abstractions.Entities;
using ChokaQ.Abstractions.Enums;
using ChokaQ.Abstractions.Resilience;
using ChokaQ.Abstractions.Storage;
using ChokaQ.TheDeck.Models;
using ChokaQ.TheDeck.UI.Components.OpsPanel;
using Microsoft.AspNetCore.Components;
using Microsoft.AspNetCore.SignalR.Client;
using Timer = System.Timers.Timer;

namespace ChokaQ.TheDeck.UI.Pages;

public partial class TheDeck : IAsyncDisposable
{
    // --- Injects ---
    [Inject] public required NavigationManager Navigation { get; set; }
    [Inject] public required ChokaQTheDeckOptions Options { get; set; }
    [Inject] public required IJobStorage JobStorage { get; set; }
    [Inject] public required ICircuitBreaker CircuitBreaker { get; set; }

    // --- State ---
    private HubConnection? _hubConnection;
    private List<JobViewModel> _jobs = new();
    private StatsSummaryEntity _counts = new(null, 0, 0, 0, 0, 0, 0, 0, null);
    private List<CircuitStatsDto> _circuits = new();
    private List<LogEntry> _logs = new();

    // UI References & State
    private OpsPanel? _opsPanel;
    private Timer? _uiRefreshTimer;
    private JobStatus? _activeStatusFilter;

    private bool IsConnected => _hubConnection?.State == HubConnectionState.Connected;
    private const int MaxHistoryCount = 1000;

    // --- Lifecycle ---

    protected override async Task OnInitializedAsync()
    {
        // Initial Data Load
        await LoadDataAsync();

        // Start Polling Timer (Backup for SignalR)
        _uiRefreshTimer = new Timer(2000);
        _uiRefreshTimer.AutoReset = true;
        _uiRefreshTimer.Elapsed += async (sender, e) => await LoadDataAsync();
        _uiRefreshTimer.Start();

        // Setup SignalR
        var hubPath = Options.RoutePrefix.TrimEnd('/') + "/hub";
        var hubUrl = Navigation.ToAbsoluteUri(hubPath);

        _hubConnection = new HubConnectionBuilder()
            .WithUrl(hubUrl)
            .WithAutomaticReconnect()
            .Build();

        RegisterHubHandlers();

        try
        {
            await _hubConnection.StartAsync();
            AddLog("System connected", "Success");
        }
        catch (Exception ex)
        {
            AddLog($"Connection failed: {ex.Message}", "Error");
        }
    }

    // --- Logic & Event Handlers ---

    private void RegisterHubHandlers()
    {
        if (_hubConnection == null) return;

        _hubConnection.On<JobUpdateDto>("JobUpdated", (dto) =>
        {
            InvokeAsync(() =>
            {
                UpdateOrAddJob(dto);
                StateHasChanged();
            });
        });

        _hubConnection.On<string, string>("JobArchived", (jobId, queue) =>
        {
            InvokeAsync(() =>
            {
                var job = _jobs.FirstOrDefault(j => j.Id == jobId);
                if (job != null) job.Status = JobStatus.Succeeded;
                StateHasChanged();
            });
        });

        _hubConnection.On<string, string, string>("JobFailed", (jobId, queue, reason) =>
        {
            InvokeAsync(() =>
            {
                var job = _jobs.FirstOrDefault(j => j.Id == jobId);
                if (job != null)
                {
                    job.Status = JobStatus.Failed;
                    job.ErrorDetails = reason;
                }
                AddLog($"Job {jobId[..8]} failed", "Error");
                StateHasChanged();
            });
        });

        _hubConnection.On("StatsUpdated", () =>
        {
            InvokeAsync(async () =>
            {
                _counts = await JobStorage.GetSummaryStatsAsync();
                StateHasChanged();
            });
        });

        _hubConnection.On<string, int>("JobProgress", (jobId, percentage) =>
        {
            InvokeAsync(() =>
            {
                var job = _jobs.FirstOrDefault(j => j.Id == jobId);
                if (job != null)
                {
                    job.Progress = percentage;
                    StateHasChanged();
                }
            });
        });
    }

    private void UpdateOrAddJob(JobUpdateDto dto)
    {
        var existing = _jobs.FirstOrDefault(j => j.Id == dto.JobId);
        if (existing != null)
        {
            existing.Status = dto.Status;
            existing.Attempts = dto.AttemptCount;
            existing.Duration = dto.DurationMs.HasValue ? TimeSpan.FromMilliseconds(dto.DurationMs.Value) : null;
            existing.StartedAtUtc = dto.StartedAtUtc?.ToLocalTime();
            existing.Queue = dto.Queue;
            existing.Priority = dto.Priority;

            if (existing.Status == JobStatus.Failed)
                AddLog($"Job {dto.JobId[..8]} failed", "Error");
        }
        else
        {
            _jobs.Insert(0, new JobViewModel
            {
                Id = dto.JobId,
                Queue = dto.Queue,
                Type = dto.Type,
                Status = dto.Status,
                Attempts = dto.AttemptCount,
                Priority = dto.Priority,
                AddedAt = DateTime.Now,
                CreatedBy = dto.CreatedBy,
                StartedAtUtc = dto.StartedAtUtc?.ToLocalTime()
            });

            AddLog($"Job {dto.JobId[..8]} enqueued", "Info");

            if (_jobs.Count > MaxHistoryCount) _jobs.RemoveAt(_jobs.Count - 1);
        }
    }

    private async Task LoadDataAsync()
    {
        try
        {
            _counts = await JobStorage.GetSummaryStatsAsync();
            _circuits = CircuitBreaker.GetCircuitStats().ToList();

            // Note: In a real polling scenario, you might want to merge lists instead of replacing 
            // to avoid UI flicker, but for now replacement is safer for consistency.
            var hotJobs = await JobStorage.GetActiveJobsAsync(MaxHistoryCount);
            var viewModels = hotJobs.Select(job => new JobViewModel
            {
                Id = job.Id,
                Queue = job.Queue,
                Type = job.Type,
                Status = job.Status,
                Priority = job.Priority,
                Attempts = job.AttemptCount,
                AddedAt = job.CreatedAtUtc.ToLocalTime(),
                Duration = job.StartedAtUtc.HasValue ? DateTime.UtcNow - job.StartedAtUtc.Value : null,
                CreatedBy = job.CreatedBy,
                StartedAtUtc = job.StartedAtUtc?.ToLocalTime(),
                Payload = job.Payload ?? "{}"
            }).ToList();

            await InvokeAsync(() =>
            {
                _jobs = viewModels;
                StateHasChanged();
            });
        }
        catch { /* Ignore polling errors */ }
    }

    private void HandleStatusSelected(JobStatus? status)
    {
        _activeStatusFilter = status;
        StateHasChanged();
    }

    private void HandleJobInspectorRequested(string jobId)
    {
        _opsPanel?.ShowJobInspector(jobId);
    }

    private async Task HandleRequeueRequestedAsync(string jobId)
    {
        if (_hubConnection != null) await _hubConnection.InvokeAsync("RestartJob", jobId);
    }

    private async Task HandleDeleteRequestedAsync(string jobId)
    {
        // OpsPanel handles the closing, we just need to refresh if needed
        // Assuming deletion is actually handled by OpsPanel calling storage/hub directly?
        // Or if we need to call Hub:
        // if (_hubConnection != null) await _hubConnection.InvokeAsync("PurgeDLQ", new[] { jobId });
        // Let's assume OpsPanel logic handles the 'Delete' action via its own callback logic or we pass it here.
        // For now, just clear locally.
        _opsPanel?.ClearPanel();
    }

    private void ClearHistory()
    {
        _jobs.Clear();
        StateHasChanged();
    }

    private void AddLog(string message, string level)
    {
        _logs.Add(new LogEntry(DateTime.Now, message, level));
        if (_logs.Count > 500) _logs.RemoveAt(0);
        StateHasChanged();
    }

    public async ValueTask DisposeAsync()
    {
        if (_uiRefreshTimer is not null)
        {
            _uiRefreshTimer.Stop();
            _uiRefreshTimer.Dispose();
        }
        if (_hubConnection is not null) await _hubConnection.DisposeAsync();
        GC.SuppressFinalize(this);
    }
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\UI\Pages\TheDeck.razor.css
/* Main Layout Container */
.deck-root {
    display: flex;
    flex-direction: row;
    height: 100vh;
    width: 100vw;
    padding: 1.5rem;
    gap: 1rem;
    box-sizing: border-box;
    background-color: var(--deck-bg-color);
    background-image: var(--deck-bg-image);
    background-size: var(--deck-bg-size);
    font-family: var(--deck-font-family);
    color: var(--deck-text-color);
    overflow: hidden;
}

/* Left Column (Main Work Area) */
.deck-col-main {
    flex: 1;
    display: flex;
    flex-direction: column;
    gap: 1rem;
    min-width: 0; /* Prevent flex overflow */
}

/* Right Column (Side Panel) */
.deck-col-side {
    width: 25%;
    min-width: 320px;
    max-width: 400px;
    display: flex;
    flex-direction: column;
    gap: 1rem;
}

/* --- SECTORS (Panels) --- */
/* Common glassmorphism/panel style */
.deck-sector {
    background-color: var(--sector-bg);
    border: 1px solid var(--sector-border-color);
    box-shadow: var(--sector-shadow);
    backdrop-filter: var(--sector-backdrop);
    padding: 1rem;
    box-sizing: border-box;
    display: flex;
    flex-direction: column;
}

/* Specific Row Heights */

/* Header (Logo & Theme) */
.row-header {
    height: 4rem;
    flex-shrink: 0;
    border-color: var(--sector-border-highlight);
}

/* Queues & Settings */
.row-queues, .row-settings {
    height: 16rem;
    flex-shrink: 0;
}

/* Stats & Circuits */
.row-stats, .row-circuits {
    height: 7rem;
    flex-shrink: 0;
}

/* Job Matrix & Ops Panel (Fill remaining space) */
.row-matrix, .row-ops {
    flex: 1;
    min-height: 0; /* Important for inner scrolling */
    overflow: hidden;
}

/* Console (Fixed at bottom left) */
.row-console {
    height: 12rem;
    flex-shrink: 0;
    background-color: var(--console-bg);
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\wwwroot\css\deck.css
/* ==========================================
   THE DECK - MAIN STYLES
   ========================================== */

/* Import Skins */
@import url('skins/blueprint.css');
@import url('skins/carbon.css');

/* ==========================================
   GLOBAL STYLES
   ========================================== */

html,
body {
    margin: 0;
    padding: 0;
    height: 100vh;
    overflow: hidden;

    /* Theme Application */
    background-color: var(--deck-bg-color);
    background-image: var(--deck-bg-image);
    background-size: var(--deck-bg-size);

    /* Typography */
    font-family: var(--deck-font-family);
    color: var(--deck-text-color);
}

/* Root Container */
.deck-root {
    display: flex;
    flex-direction: row;
    height: 100vh;
    width: 100vw;

    padding: 2rem;
    gap: 1rem;
    box-sizing: border-box;
}

/* Left Column (Main) */
.deck-col-main {
    flex: 1;
    display: flex;
    flex-direction: column;
    gap: 1rem;
}

/* Right Column (Sidebar/Tools) */
.deck-col-side {
    width: 25%;
    min-width: 300px;
    display: flex;
    flex-direction: column;
    gap: 1rem;
}

/* ==========================================
   SECTOR STYLING
   ========================================== */

/* Common style for all sectors */
.deck-sector,
.deck-row-header,
.deck-row-queues,
.deck-row-settings,
.deck-row-stats,
.deck-row-circuits,
.deck-row-matrix,
.deck-row-ops,
.deck-row-console {
    background-color: var(--sector-bg);
    border: 1px solid var(--sector-border-color);
    box-shadow: var(--sector-shadow);
    backdrop-filter: var(--sector-backdrop);
    padding: 1rem;
    box-sizing: border-box;
}

/* Row 1: Headers */
.deck-row-header {
    height: 4rem;
    flex-shrink: 0;
    border: 1px solid var(--sector-border-highlight);
}

/* Row 2: Queues & Settings */
.deck-row-queues,
.deck-row-settings {
    height: 16rem;
    flex-shrink: 0;
}

/* Row 3: Stats & Circuits */
.deck-row-stats,
.deck-row-circuits {
    height: 7rem;
    flex-shrink: 0;
}

/* Row 4: Matrix & Ops */
.deck-row-matrix,
.deck-row-ops {
    flex: 1;
    overflow-y: auto;
}

/* Row 5: ConsoleLog */
.deck-row-console {
    height: 10rem;
    flex-shrink: 0;
    background-color: var(--console-bg);
}

/* ==========================================
   COMPONENT STYLES
   ========================================== */

.header-right-container {
    height: 100%;
    display: flex;
    align-items: center;
    justify-content: flex-end;
    gap: 2rem;
}

.theme-selector {
    display: flex;
    align-items: center;
    gap: 0.5rem;
}

.theme-selector .label {
    opacity: 0.7;
    font-size: 0.8em;
}

.theme-selector select {
    background: rgba(0, 0, 0, 0.3);
    color: var(--deck-text-color);
    border: 1px solid var(--sector-border-color);
    padding: 0.2rem 0.5rem;
    font-family: var(--deck-font-family);
    font-size: 0.9em;
    text-transform: uppercase;
    cursor: pointer;
}

.theme-selector select:focus {
    outline: none;
    border-color: var(--sector-border-highlight);
    background: rgba(0, 0, 0, 0.5);
}

/* ==========================================
   SHARED COMPONENT STYLES
   ========================================== */

/* Buttons */
.deck-btn {
    background: var(--sector-bg);
    border: 1px solid var(--sector-border-color);
    color: var(--deck-text-color);
    padding: 0.4rem 1rem;
    font-family: var(--deck-font-family);
    font-size: 0.85rem;
    cursor: pointer;
    transition: border-color 0.2s;
}

.deck-btn:hover {
    border-color: var(--sector-border-highlight);
}

.deck-btn-primary {
    border-color: var(--sector-border-highlight);
}

.deck-btn-danger {
    border-color: #ff4444;
    color: #ff4444;
}

/* Tables */
.deck-table {
    width: 100%;
    border-collapse: collapse;
    font-size: 0.85rem;
    font-family: var(--deck-font-family);
    color: var(--deck-text-color);
}

.deck-table th {
    background: rgba(0, 0, 0, 0.1);
    border-bottom: 2px solid var(--sector-border-color);
    padding: 0.5rem;
    text-align: left;
    font-weight: bold;
    text-transform: uppercase;
    font-size: 0.75rem;
    opacity: 0.8;
}

.deck-table td {
    border-bottom: 1px solid var(--sector-border-color);
    padding: 0.5rem;
    vertical-align: middle;
}

.deck-table tr:hover {
    background: rgba(255, 255, 255, 0.05);
}

.deck-table tr.selected {
    background: rgba(255, 255, 255, 0.1);
}

/* Badges */
.deck-badge {
    display: inline-block;
    padding: 0.15rem 0.4rem;
    font-size: 0.75rem;
    font-weight: bold;
    border-radius: 2px;
    border: 1px solid transparent;
    text-transform: uppercase;
}

/* Progress */
.deck-progress {
    height: 4px;
    background: var(--sector-border-color);
    width: 100%;
    margin-top: 0.25rem;
    position: relative;
}

.deck-progress-bar {
    height: 100%;
    transition: width 0.3s;
}

/* Shared Meta Lists */
.deck-meta-list {
    list-style: none;
    padding: 0;
    margin: 0;
}

.deck-meta-list li {
    display: flex;
    justify-content: space-between;
    padding: 0.25rem 0;
    border-bottom: 1px solid var(--sector-border-color);
    font-size: 0.85rem;
}

.deck-meta-label {
    font-weight: bold;
    color: var(--deck-text-color);
    opacity: 0.7;
}

.deck-meta-value {
    font-family: var(--deck-font-family);
    color: var(--deck-text-color);
}

/* Shared Code Blocks */
.deck-code-block {
    background: var(--console-bg);
    border: 1px solid var(--sector-border-color);
    padding: 0.5rem;
    font-family: var(--deck-font-family);
    font-size: 0.8rem;
    overflow-x: auto;
    white-space: pre-wrap;
    word-break: break-all;
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\wwwroot\css\skins\blueprint.css
/* ==========================================
   THEME: BLUEPRINT (Default)
   ========================================== */

:root,
[data-theme="blueprint"] {
    --deck-bg-color: #003366;
    --deck-bg-image:
        linear-gradient(rgba(255, 255, 255, 0.1) 1px, transparent 1px),
        linear-gradient(90deg, rgba(255, 255, 255, 0.1) 1px, transparent 1px);
    --deck-bg-size: 50px 50px;

    --deck-font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
    --deck-text-color: #ffffff;

    --sector-bg: rgba(255, 255, 255, 0.02);
    --sector-border-color: rgba(255, 255, 255, 0.3);
    --sector-border-highlight: rgba(255, 255, 255, 0.8);
    --sector-shadow: 0 0 5px rgba(0, 0, 0, 0.2);
    --sector-backdrop: blur(1px);

    --console-bg: rgba(0, 0, 0, 0.2);

    /* Status Colors */
    --deck-success: #28a745;
    --deck-warning: #ffc107;
    --deck-danger: #dc3545;
    --deck-info: #17a2b8;
    --deck-muted: rgba(255, 255, 255, 0.5);
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\wwwroot\css\skins\carbon.css
/* ==========================================
   THEME: CARBON
   ========================================== */

[data-theme="carbon"] {
    --deck-bg-color: #161616;
    --deck-bg-image: none;
    --deck-bg-size: auto;

    --deck-font-family: 'Inter', -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
    --deck-text-color: #f4f4f4;

    --sector-bg: #262626;
    --sector-border-color: #393939;
    --sector-border-highlight: #ffffff;
    --sector-shadow: none;
    --sector-backdrop: none;

    --console-bg: #161616;

    /* Status Colors */
    --deck-success: #42be65;
    --deck-warning: #f1c21b;
    --deck-danger: #fa4d56;
    --deck-info: #4589ff;
    --deck-muted: #8d8d8d;
}

<<< END OF FILE

--------------------------------------------------------------------------------

>>> FILE: ChokaQ\src\ChokaQ.TheDeck\wwwroot\js\deck.js
window.deck = {
    scrollToBottom: (element) => {
        if (element) {
            element.scrollIntoView({ behavior: 'smooth', block: 'end' });
        }
    },
    setTheme: (theme) => {
        document.documentElement.setAttribute('data-theme', theme);
    }
};

<<< END OF FILE

--------------------------------------------------------------------------------

